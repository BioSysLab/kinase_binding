{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.callbacks import History, ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "from data_analysis import calculate_metrics, load_weights_and_evaluate\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, roc_auc_score, auc, average_precision_score\n",
    "#import scikitplot as skplt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from NGF.preprocessing import tensorise_smiles\n",
    "from custom_layers.model_creator import encode_smiles, stage_creator\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, concatenate,Flatten\n",
    "from keras.models import Model, load_model\n",
    "import dill\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "import xgboost as xgb\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance(feature, squared):\n",
    "    \"\"\"Computes the pairwise distance matrix with numerical stability.\n",
    "\n",
    "    output[i, j] = || feature[i, :] - feature[j, :] ||_2\n",
    "\n",
    "    Args:\n",
    "      feature: 2-D Tensor of size [number of data, feature dimension].\n",
    "      squared: Boolean, whether or not to square the pairwise distances.\n",
    "\n",
    "    Returns:\n",
    "      pairwise_distances: 2-D Tensor of size [number of data, number of data].\n",
    "    \"\"\"\n",
    "    pairwise_distances_squared = math_ops.add(\n",
    "        math_ops.reduce_sum(math_ops.square(feature), axis=[1], keepdims=True),\n",
    "        math_ops.reduce_sum(\n",
    "            math_ops.square(array_ops.transpose(feature)),\n",
    "            axis=[0],\n",
    "            keepdims=True)) - 2.0 * math_ops.matmul(feature,\n",
    "                                                    array_ops.transpose(feature))\n",
    "\n",
    "    # Deal with numerical inaccuracies. Set small negatives to zero.\n",
    "    pairwise_distances_squared = math_ops.maximum(pairwise_distances_squared, 0.0)\n",
    "    # Get the mask where the zero distances are at.\n",
    "    error_mask = math_ops.less_equal(pairwise_distances_squared, 0.0)\n",
    "\n",
    "    # Optionally take the sqrt.\n",
    "    if squared:\n",
    "        pairwise_distances = pairwise_distances_squared\n",
    "    else:\n",
    "        pairwise_distances = math_ops.sqrt(\n",
    "            pairwise_distances_squared + math_ops.to_float(error_mask) * 1e-16)\n",
    "\n",
    "    # Undo conditionally adding 1e-16.\n",
    "    pairwise_distances = math_ops.multiply(\n",
    "        pairwise_distances, math_ops.to_float(math_ops.logical_not(error_mask)))\n",
    "\n",
    "    num_data = array_ops.shape(feature)[0]\n",
    "    # Explicitly set diagonals to zero.\n",
    "    mask_offdiagonals = array_ops.ones_like(pairwise_distances) - array_ops.diag(\n",
    "        array_ops.ones([num_data]))\n",
    "    pairwise_distances = math_ops.multiply(pairwise_distances, mask_offdiagonals)\n",
    "    return pairwise_distances\n",
    "\n",
    "def masked_maximum(data, mask, dim=1):\n",
    "    \"\"\"Computes the axis wise maximum over chosen elements.\n",
    "\n",
    "    Args:\n",
    "      data: 2-D float `Tensor` of size [n, m].\n",
    "      mask: 2-D Boolean `Tensor` of size [n, m].\n",
    "      dim: The dimension over which to compute the maximum.\n",
    "\n",
    "    Returns:\n",
    "      masked_maximums: N-D `Tensor`.\n",
    "        The maximized dimension is of size 1 after the operation.\n",
    "    \"\"\"\n",
    "    axis_minimums = math_ops.reduce_min(data, dim, keepdims=True)\n",
    "    masked_maximums = math_ops.reduce_max(\n",
    "        math_ops.multiply(data - axis_minimums, mask), dim,\n",
    "        keepdims=True) + axis_minimums\n",
    "    return masked_maximums\n",
    "\n",
    "def masked_minimum(data, mask, dim=1):\n",
    "    \"\"\"Computes the axis wise minimum over chosen elements.\n",
    "\n",
    "    Args:\n",
    "      data: 2-D float `Tensor` of size [n, m].\n",
    "      mask: 2-D Boolean `Tensor` of size [n, m].\n",
    "      dim: The dimension over which to compute the minimum.\n",
    "\n",
    "    Returns:\n",
    "      masked_minimums: N-D `Tensor`.\n",
    "        The minimized dimension is of size 1 after the operation.\n",
    "    \"\"\"\n",
    "    axis_maximums = math_ops.reduce_max(data, dim, keepdims=True)\n",
    "    masked_minimums = math_ops.reduce_min(\n",
    "        math_ops.multiply(data - axis_maximums, mask), dim,\n",
    "        keepdims=True) + axis_maximums\n",
    "    return masked_minimums\n",
    "def triplet_loss_adapted_from_tf(y_true, y_pred):\n",
    "    del y_true\n",
    "    margin = 0.1\n",
    "    labels = y_pred[:, :1]\n",
    "    labels = tf.cast(labels, dtype='int32')\n",
    "    embeddings = y_pred[:, 1:]\n",
    "    \n",
    "    ### Code from Tensorflow function [tf.contrib.losses.metric_learning.triplet_semihard_loss] starts here:\n",
    "    \n",
    "    # Reshape [batch_size] label tensor to a [batch_size, 1] label tensor.\n",
    "    # lshape=array_ops.shape(labels)\n",
    "    # assert lshape.shape == 1\n",
    "    # labels = array_ops.reshape(labels, [lshape[0], 1])\n",
    "\n",
    "    # Build pairwise squared distance matrix.\n",
    "    pdist_matrix = pairwise_distance(embeddings, squared=False)\n",
    "    # Build pairwise binary adjacency matrix.\n",
    "    adjacency = math_ops.equal(labels, array_ops.transpose(labels))\n",
    "    # Invert so we can select negatives only.\n",
    "    adjacency_not = math_ops.logical_not(adjacency)\n",
    "\n",
    "    # global batch_size  \n",
    "    batch_size = array_ops.size(labels) # was 'array_ops.size(labels)'\n",
    "\n",
    "    # Compute the mask.\n",
    "    pdist_matrix_tile = array_ops.tile(pdist_matrix, [batch_size, 1])\n",
    "    mask = math_ops.logical_and(\n",
    "        array_ops.tile(adjacency_not, [batch_size, 1]),\n",
    "        math_ops.greater(\n",
    "            pdist_matrix_tile, array_ops.reshape(\n",
    "                array_ops.transpose(pdist_matrix), [-1, 1])))\n",
    "    mask_final = array_ops.reshape(\n",
    "        math_ops.greater(\n",
    "            math_ops.reduce_sum(\n",
    "                math_ops.cast(mask, dtype=dtypes.float32), 1, keepdims=True),\n",
    "            0.0), [batch_size, batch_size])\n",
    "    mask_final = array_ops.transpose(mask_final)\n",
    "\n",
    "    adjacency_not = math_ops.cast(adjacency_not, dtype=dtypes.float32)\n",
    "    mask = math_ops.cast(mask, dtype=dtypes.float32)\n",
    "\n",
    "    # negatives_outside: smallest D_an where D_an > D_ap.\n",
    "    negatives_outside = array_ops.reshape(\n",
    "        masked_minimum(pdist_matrix_tile, mask), [batch_size, batch_size])\n",
    "    negatives_outside = array_ops.transpose(negatives_outside)\n",
    "\n",
    "    # negatives_inside: largest D_an.\n",
    "    negatives_inside = array_ops.tile(\n",
    "        masked_maximum(pdist_matrix, adjacency_not), [1, batch_size])\n",
    "    semi_hard_negatives = array_ops.where(\n",
    "        mask_final, negatives_outside, negatives_inside)\n",
    "\n",
    "    loss_mat = math_ops.add(margin, pdist_matrix - semi_hard_negatives)\n",
    "\n",
    "    mask_positives = math_ops.cast(\n",
    "        adjacency, dtype=dtypes.float32) - array_ops.diag(\n",
    "        array_ops.ones([batch_size]))\n",
    "\n",
    "    # In lifted-struct, the authors multiply 0.5 for upper triangular\n",
    "    #   in semihard, they take all positive pairs except the diagonal.\n",
    "    num_positives = math_ops.reduce_sum(mask_positives)\n",
    "\n",
    "    semi_hard_triplet_loss_distance = math_ops.truediv(\n",
    "        math_ops.reduce_sum(\n",
    "            math_ops.maximum(\n",
    "                math_ops.multiply(loss_mat, mask_positives), 0.0)),\n",
    "        num_positives,\n",
    "        name='triplet_semihard_loss')\n",
    "    \n",
    "    ### Code from Tensorflow function semi-hard triplet loss ENDS here.\n",
    "    return semi_hard_triplet_loss_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1 = 'p38'\n",
    "base_path_1 = f'C:/Users/tomas/Documents/GitHub/kinase_binding'\n",
    "\n",
    "data_fpath_1 = base_path_1+f'/data/{target_1}/data.csv'\n",
    "df_p38=pd.read_csv(data_fpath_1).set_index('biolab_index')\n",
    "\n",
    "with open(base_path_1+f'/data/{target_1}/train_val_folds.pkl', \"rb\") as in_f:\n",
    "    train_val_folds_p38 = dill.load(in_f)\n",
    "\n",
    "with open(base_path_1+f'/data/{target_1}/train_test_folds.pkl', \"rb\") as in_f:\n",
    "    train_test_folds_p38 = dill.load(in_f)\n",
    "    \n",
    "target_2 = 'akt1'\n",
    "base_path_2 = f'C:/Users/tomas/Documents/GitHub/kinase_binding'\n",
    "\n",
    "data_fpath_2 = base_path_2+f'/data/{target_2}/data.csv'\n",
    "df_akt1 = pd.read_csv(data_fpath_2).set_index('biolab_index')\n",
    "\n",
    "with open(base_path_2+f'/data/{target_2}/train_val_folds.pkl', \"rb\") as in_f:\n",
    "    train_val_folds_akt1 = dill.load(in_f)\n",
    "with open(base_path_2+f'/data/{target_2}/train_test_folds.pkl', \"rb\") as in_f:\n",
    "    train_test_folds_akt1 = dill.load(in_f)\n",
    "    \n",
    "target_3 = 'pi3k'\n",
    "base_path_3 = f'C:/Users/tomas/Documents/GitHub/kinase_binding'\n",
    "\n",
    "data_fpath_3 = base_path_3+f'/data/{target_3}/data.csv'\n",
    "df_pi3k = pd.read_csv(data_fpath_3).set_index('biolab_index')\n",
    "\n",
    "with open(base_path_3+f'/data/{target_3}/train_val_folds.pkl', \"rb\") as in_f:\n",
    "    train_val_folds_pi3k = dill.load(in_f)\n",
    "with open(base_path_3+f'/data/{target_3}/train_test_folds.pkl', \"rb\") as in_f:\n",
    "    train_test_folds_pi3k = dill.load(in_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_p38 = [#df_p38.loc[train_val_folds_p38[0][0]],\n",
    "                # df_p38.loc[train_val_folds_p38[1][0]],\n",
    "                # df_p38.loc[train_val_folds_p38[2][0]],\n",
    "                # df_p38.loc[train_val_folds_p38[3][0]],\n",
    "                # df_p38.loc[train_val_folds_p38[4][0]],\n",
    "                # df_p38.loc[train_val_folds_p38[5][0]],\n",
    "                df_p38.loc[train_test_folds_p38[0]]\n",
    "                 ]\n",
    "validation_p38 = [ #df_p38.loc[train_val_folds_p38[0][1]],\n",
    "                   #df_p38.loc[train_val_folds_p38[1][1]],\n",
    "                   #df_p38.loc[train_val_folds_p38[2][1]],\n",
    "                   #df_p38.loc[train_val_folds_p38[3][1]],\n",
    "                   #df_p38.loc[train_val_folds_p38[4][1]],\n",
    "                   #df_p38.loc[train_val_folds_p38[5][1]],\n",
    "                   df_p38.loc[train_test_folds_p38[1]]\n",
    "                   ]\n",
    "\n",
    "training_akt1 = [#df_akt1.loc[train_val_folds_akt1[0][0]],\n",
    "                 #df_akt1.loc[train_val_folds_akt1[1][0]],\n",
    "                 #df_akt1.loc[train_val_folds_akt1[2][0]],\n",
    "                 #df_akt1.loc[train_val_folds_akt1[3][0]],\n",
    "                 #df_akt1.loc[train_val_folds_akt1[4][0]],\n",
    "                 #df_akt1.loc[train_val_folds_akt1[5][0]],\n",
    "                 df_akt1.loc[train_test_folds_akt1[0]]\n",
    "                 ]\n",
    "validation_akt1 = [#df_akt1.loc[train_val_folds_akt1[0][1]],\n",
    "                   #df_akt1.loc[train_val_folds_akt1[1][1]],\n",
    "                   #df_akt1.loc[train_val_folds_akt1[2][1]],\n",
    "                   #df_akt1.loc[train_val_folds_akt1[3][1]],\n",
    "                   #df_akt1.loc[train_val_folds_akt1[4][1]],\n",
    "                   #df_akt1.loc[train_val_folds_akt1[5][1]],\n",
    "                   df_akt1.loc[train_test_folds_akt1[1]]\n",
    "                   ]\n",
    "\n",
    "training_pi3k = [#df_pi3k.loc[train_val_folds_pi3k[0][0]],\n",
    "                 #df_pi3k.loc[train_val_folds_pi3k[1][0]],\n",
    "                 #df_pi3k.loc[train_val_folds_pi3k[2][0]],\n",
    "                 #df_pi3k.loc[train_val_folds_pi3k[3][0]],\n",
    "                 #df_pi3k.loc[train_val_folds_pi3k[4][0]],\n",
    "                 #df_pi3k.loc[train_val_folds_pi3k[5][0]],\n",
    "                 df_pi3k.loc[train_test_folds_pi3k[0]]\n",
    "                 ]\n",
    "validation_pi3k = [#df_pi3k.loc[train_val_folds_pi3k[0][1]],\n",
    "                   #df_pi3k.loc[train_val_folds_pi3k[1][1]],\n",
    "                   #df_pi3k.loc[train_val_folds_pi3k[2][1]],\n",
    "                   #df_pi3k.loc[train_val_folds_pi3k[3][1]],\n",
    "                   #df_pi3k.loc[train_val_folds_pi3k[4][1]],\n",
    "                   #df_pi3k.loc[train_val_folds_pi3k[5][1]],\n",
    "                   df_pi3k.loc[train_test_folds_pi3k[1]]\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_generator_mining(bs,df_p1,df_p2,df_p3,\n",
    "                         Y_dummy_p1,Y_dummy_p2,Y_dummy_p3,\n",
    "                         smiles_list_p1,smiles_list_p2,smiles_list_p3,\n",
    "                         Y_p1,Y_p2,Y_p3,\n",
    "                         atoms_p1,bonds_p1,edges_p1,\n",
    "                         atoms_p2,bonds_p2,edges_p2,\n",
    "                         atoms_p3,bonds_p3,edges_p3,mode = 'train',aug = None):\n",
    "    \n",
    "    counter_1=int(0)\n",
    "    counter_2=int(0)\n",
    "    counter_3=int(0)\n",
    "    #Keep looping indefinetely\n",
    "    df_p1 = df_p1.reset_index(drop=True)\n",
    "    df_p2 = df_p2.reset_index(drop=True)\n",
    "    df_p3 = df_p3.reset_index(drop=True)\n",
    "    Y_p1 = np.array(list(Y_p1))\n",
    "    Y_p2 = np.array(list(Y_p2))\n",
    "    Y_p3 = np.array(list(Y_p3))\n",
    "    while True:\n",
    "        \n",
    "        #Initialize batches of inputs and outputs\n",
    "        ind1 = []\n",
    "        ind2 = []\n",
    "        ind3 = []\n",
    "        \n",
    "        d_p1=[]\n",
    "        d_p2=[]\n",
    "        d_p3=[]\n",
    "        \n",
    "        #Keep looping until we reach batch size\n",
    "        while len(ind3)<=bs: #doesn't matter if it is smi1 or smi2 since they have the same len\n",
    "            if counter_3==len(df_p3):\n",
    "                counter_3=int(0)\n",
    "                df_p3 = df_p3.sample(frac=1).reset_index(drop=True)\n",
    "            \n",
    "            smi_p3 = df_p3['rdkit'][counter_3]\n",
    "            ind3.append(smiles_list_p3.index(smi_p3))\n",
    "            d_p3.append(Y_dummy_p3[counter_3])\n",
    "            counter_3+=1\n",
    "            while len(ind1)<=bs:\n",
    "                if counter_1==len(df_p1):\n",
    "                    counter_1=int(0)\n",
    "                    df_p1 = df_p1.sample(frac=1).reset_index(drop=True)\n",
    "                \n",
    "                smi_p1 = df_p1['rdkit'][counter_1]\n",
    "                ind1.append(smiles_list_p1.index(smi_p1))\n",
    "                d_p1.append(Y_dummy_p1[counter_1])\n",
    "                counter_1+=1\n",
    "                \n",
    "                \n",
    "                while len(ind2)<=bs:\n",
    "            # check to see if you reached the end of the frame\n",
    "                    if counter_2==len(df_p2):\n",
    "                        counter_2=int(0)\n",
    "                        df_p2 = df_p2.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "                    smi_p2 = df_p2['rdkit'][counter_2]\n",
    "                    ind2.append(smiles_list_p2.index(smi_p2))\n",
    "                    d_p2.append(Y_dummy_p2[counter_2])\n",
    "                    counter_2+=1\n",
    "                # if we are evaluating we should now break from our \n",
    "                # loop to ensure we don't continue to fill up the batch from samples at the beginning of the file\n",
    "                \n",
    "                   \n",
    "            \n",
    "            \n",
    "\n",
    "            #smi_p1 = df_p1['rdkit'][counter]\n",
    "            #smi_p2 = df_p2['rdkit'][counter]\n",
    "            #smi_p3 = df_p3['rdkit'][counter]\n",
    "            #ind1.append(smiles_list_p1.index(smi_p1))\n",
    "            #ind2.append(smiles_list_p2.index(smi_p2))\n",
    "            #ind3.append(smiles_list_p3.index(smi_p3))\n",
    "            #d_p1.append(Y_dummy_p1[counter])\n",
    "            #d_p2.append(Y_dummy_p2[counter])\n",
    "            #d_p3.append(Y_dummy_p3[counter])\n",
    "            #counter+=1\n",
    "            \n",
    "        atoms_target_1 = np.array(atoms_p1[ind1],dtype = 'float32')\n",
    "        bonds_target_1 = np.array(bonds_p1[ind1],dtype = 'float32')\n",
    "        edges_target_1 = np.array(edges_p1[ind1],dtype = 'int32')\n",
    "        labels_target_1 = Y_p1[ind1]\n",
    "        \n",
    "        atoms_target_2 = np.array(atoms_p2[ind2],dtype = 'float32')\n",
    "        bonds_target_2 = np.array(bonds_p2[ind2],dtype = 'float32')\n",
    "        edges_target_2 = np.array(edges_p2[ind2],dtype = 'int32')\n",
    "        labels_target_2 = Y_p2[ind2]\n",
    "        \n",
    "        atoms_target_3 = np.array(atoms_p3[ind3],dtype = 'float32')\n",
    "        bonds_target_3 = np.array(bonds_p3[ind3],dtype = 'float32')\n",
    "        edges_target_3 = np.array(edges_p3[ind3],dtype = 'int32')\n",
    "        labels_target_3 = Y_p3[ind3]\n",
    "        \n",
    "        yield ({'atom_inputs_1':atoms_target_1,\n",
    "                'bond_inputs_1':bonds_target_1,\n",
    "                'edge_inputs_1':edges_target_1,\n",
    "                'labels_inputs_1':labels_target_1,\n",
    "                'atom_inputs_2':atoms_target_2,\n",
    "                'bond_inputs_2':bonds_target_2,\n",
    "                'edge_inputs_2':edges_target_2,\n",
    "                'labels_inputs_2':labels_target_2,\n",
    "                'atom_inputs_3':atoms_target_3,\n",
    "                'bond_inputs_3':bonds_target_3,\n",
    "                'edge_inputs_3':edges_target_3,\n",
    "                'labels_inputs_3':labels_target_3},{'Protein_1':np.array(d_p1,dtype = 'float32'),\n",
    "                                                    'Protein_2':np.array(d_p2,dtype = 'float32'),\n",
    "                                                    'Protein_3':np.array(d_p3,dtype = 'float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(encoder_params):\n",
    "        model_enc_1 = stage_creator(encoder_params, 1, conv=True)[0]\n",
    "        model_enc_2 = stage_creator(encoder_params, 2, conv=True)[0]\n",
    "        model_enc_3 = stage_creator(encoder_params, 3, conv=True)[0]\n",
    "\n",
    "        model_enc_fp_1 = stage_creator(encoder_params, 1, conv=False)[1]\n",
    "        model_enc_fp_2 = stage_creator(encoder_params, 2, conv=False)[1]\n",
    "        model_enc_fp_3 = stage_creator(encoder_params, 3, conv=False)[1]\n",
    "\n",
    "        atoms, bonds, edges = encode_smiles(encoder_params[\"max_atoms\"],\n",
    "                                            encoder_params[\"num_atom_features\"],\n",
    "                                            encoder_params[\"max_degree\"],\n",
    "                                            encoder_params[\"num_bond_features\"])\n",
    "\n",
    "        graph_conv_1 = model_enc_1([atoms, bonds, edges])\n",
    "        graph_conv_2 = model_enc_2([graph_conv_1, bonds, edges])\n",
    "        graph_conv_3 = model_enc_3([graph_conv_2, bonds, edges])\n",
    "\n",
    "        fingerprint_1 = model_enc_fp_1([graph_conv_1, bonds, edges])\n",
    "        fingerprint_1 = Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0], s[2]))(fingerprint_1)\n",
    "\n",
    "        fingerprint_2 = model_enc_fp_2([graph_conv_2, bonds, edges])\n",
    "        fingerprint_2 = Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0], s[2]))(fingerprint_2)\n",
    "\n",
    "        fingerprint_3 = model_enc_fp_3([graph_conv_3, bonds, edges])\n",
    "        fingerprint_3 = Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0], s[2]))(fingerprint_3)\n",
    "\n",
    "        final_fingerprint = keras.layers.add([fingerprint_1, fingerprint_2, fingerprint_3])\n",
    "\n",
    "        return Model([atoms, bonds, edges], [final_fingerprint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_params, encoder, verbose=False):\n",
    "        atoms_1 = Input(name='atom_inputs_1',\n",
    "                      shape=(model_params['max_atoms'], model_params['num_atom_features']), dtype='float32')\n",
    "        bonds_1 = Input(name='bond_inputs_1', shape=(\n",
    "            model_params['max_atoms'], model_params['max_degree'], model_params['num_bond_features']),\n",
    "                      dtype='float32')\n",
    "        edges_1 = Input(name='edge_inputs_1', shape=(model_params['max_atoms'], model_params['max_degree']),\n",
    "                      dtype='int32')\n",
    "        encode_drug_1 = encoder([atoms_1, bonds_1, edges_1])\n",
    "        \n",
    "        atoms_2 = Input(name='atom_inputs_2',\n",
    "                      shape=(model_params['max_atoms'], model_params['num_atom_features']), dtype='float32')\n",
    "        bonds_2 = Input(name='bond_inputs_2', shape=(\n",
    "            model_params['max_atoms'], model_params['max_degree'], model_params['num_bond_features']),\n",
    "                      dtype='float32')\n",
    "        edges_2 = Input(name='edge_inputs_2', shape=(model_params['max_atoms'], model_params['max_degree']),\n",
    "                      dtype='int32')\n",
    "        encode_drug_2 = encoder([atoms_2, bonds_2, edges_2])\n",
    "        \n",
    "        atoms_3 = Input(name='atom_inputs_3',\n",
    "                      shape=(model_params['max_atoms'], model_params['num_atom_features']), dtype='float32')\n",
    "        bonds_3 = Input(name='bond_inputs_3', shape=(\n",
    "            model_params['max_atoms'], model_params['max_degree'], model_params['num_bond_features']),\n",
    "                      dtype='float32')\n",
    "        edges_3 = Input(name='edge_inputs_3', shape=(model_params['max_atoms'], model_params['max_degree']),\n",
    "                      dtype='int32')\n",
    "        encode_drug_3 = encoder([atoms_3, bonds_3, edges_3])\n",
    "        \n",
    "        conc = keras.layers.Concatenate(axis = -1)([encode_drug_1,encode_drug_2,encode_drug_3])\n",
    "        # Fully connected\n",
    "        FC1 = Dense(model_params[\"dense_size\"][0], activation='relu',kernel_initializer='random_normal')(conc)\n",
    "        FC2 = Dropout(model_params[\"dropout_rate\"][0])(FC1)\n",
    "        FC2 = Dense(model_params[\"dense_size\"][1], activation='relu',kernel_initializer='random_normal')(FC2)\n",
    "        FC2 = Dropout(model_params[\"dropout_rate\"][1])(FC2)\n",
    "        FC2 = Dense(model_params[\"dense_size\"][2], activation = None,kernel_initializer='random_normal')(FC2)\n",
    "        \n",
    "        \n",
    "        embeddings_conc = Lambda(lambda x: K.l2_normalize(x,axis=1),name = 'Embeddings_Concatenated')(FC2)\n",
    "        embeddings_1 = crop(1,0,int(model_params['dense_size'][2]/3),name = 'Target_1')(embeddings_conc) #0 to 255(256)\n",
    "        embeddings_2 = crop(1,int(model_params['dense_size'][2]/3),2*int(model_params['dense_size'][2]/3),name = 'Target_2')(embeddings_conc) #256 to 511(256)\n",
    "        embeddings_3 = crop(1,2*int(model_params['dense_size'][2]/3),3*int(model_params['dense_size'][2]/3),name = 'Target_3')(embeddings_conc)\n",
    "        \n",
    "        gcn_model = Model(inputs=[atoms_1, bonds_1, edges_1,\n",
    "                                  atoms_2, bonds_2, edges_2,\n",
    "                                  atoms_3, bonds_3, edges_3], \n",
    "                                  outputs = [embeddings_1,\n",
    "                                             embeddings_2,\n",
    "                                             embeddings_3]\n",
    "                         )\n",
    "\n",
    "\n",
    "        if verbose:\n",
    "            #print('encoder')\n",
    "            #encoder.summary()\n",
    "            print('GCN_model')\n",
    "            gcn_model.summary()\n",
    "        \n",
    "            \n",
    "        return gcn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mining(model_params,gcn_model):\n",
    "        #First Target\n",
    "        atoms_1 = Input(name='atom_inputs_1',shape=(model_params['max_atoms'], \n",
    "                                                    model_params['num_atom_features']), \n",
    "                                                    dtype='float32')\n",
    "        bonds_1 = Input(name='bond_inputs_1', shape=(model_params['max_atoms'], \n",
    "                                                     model_params['max_degree'], \n",
    "                                                     model_params['num_bond_features']),\n",
    "                                                     dtype='float32')\n",
    "        edges_1 = Input(name='edge_inputs_1', shape=(model_params['max_atoms'], \n",
    "                                                     model_params['max_degree']),\n",
    "                                                     dtype='int32')\n",
    "        \n",
    "        labels_1 = Input(name = 'labels_inputs_1',shape = (1,),dtype = 'float32')\n",
    "        \n",
    "        #Second Target\n",
    "        atoms_2 = Input(name='atom_inputs_2',shape=(model_params['max_atoms'], \n",
    "                                                    model_params['num_atom_features']), \n",
    "                                                    dtype='float32')\n",
    "        bonds_2 = Input(name='bond_inputs_2', shape=(model_params['max_atoms'], \n",
    "                                                     model_params['max_degree'], \n",
    "                                                     model_params['num_bond_features']),\n",
    "                                                     dtype='float32')\n",
    "        edges_2 = Input(name='edge_inputs_2', shape=(model_params['max_atoms'], \n",
    "                                                     model_params['max_degree']),\n",
    "                                                     dtype='int32')\n",
    "        \n",
    "        labels_2 = Input(name = 'labels_inputs_2',shape = (1,),dtype = 'float32')\n",
    "        \n",
    "        #Third Target\n",
    "        atoms_3 = Input(name='atom_inputs_3',shape=(model_params['max_atoms'], \n",
    "                                                    model_params['num_atom_features']), \n",
    "                                                    dtype='float32')\n",
    "        bonds_3 = Input(name='bond_inputs_3', shape=(model_params['max_atoms'], \n",
    "                                                     model_params['max_degree'], \n",
    "                                                     model_params['num_bond_features']),\n",
    "                                                     dtype='float32')\n",
    "        edges_3 = Input(name='edge_inputs_3', shape=(model_params['max_atoms'], model_params['max_degree']),\n",
    "                      dtype='int32')\n",
    "        \n",
    "        labels_3 = Input(name = 'labels_inputs_3',shape = (1,),dtype = 'float32')\n",
    "        encoded_1,encoded_2,encoded_3 = gcn_model([atoms_1,bonds_1,edges_1,\n",
    "                                                   atoms_2,bonds_2,edges_2,\n",
    "                                                   atoms_3,bonds_3,edges_3])\n",
    "        \n",
    "        labels_plus_embeddings_1 = concatenate([labels_1, encoded_1],name = 'Protein_1')\n",
    "        labels_plus_embeddings_2 = concatenate([labels_2, encoded_2],name = 'Protein_2')\n",
    "        labels_plus_embeddings_3 = concatenate([labels_3, encoded_3],name = 'Protein_3')\n",
    "        \n",
    "        mining_net = Model(inputs = [atoms_1,bonds_1,edges_1,labels_1,\n",
    "                                     atoms_2,bonds_2,edges_2,labels_2,\n",
    "                                     atoms_3,bonds_3,edges_3,labels_3],\n",
    "                           outputs = [labels_plus_embeddings_1,\n",
    "                                      labels_plus_embeddings_2,\n",
    "                                      labels_plus_embeddings_3])\n",
    "        adam = keras.optimizers.Adam(lr = model_params[\"lr\"], \n",
    "                                     beta_1=0.9, \n",
    "                                     beta_2=0.999, \n",
    "                                     decay=0.0, \n",
    "                                     amsgrad=False)\n",
    "    \n",
    "    \n",
    "        mining_net.compile(optimizer=adam , loss = {'Protein_1' : triplet_loss_adapted_from_tf,\n",
    "                                                    'Protein_2' : triplet_loss_adapted_from_tf,\n",
    "                                                    'Protein_3' : triplet_loss_adapted_from_tf})\n",
    "        mining_net.summary()\n",
    "        return mining_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_gcn_input(input_data):\n",
    "        x_atoms_cold, x_bonds_cold, x_edges_cold = tensorise_smiles(input_data['rdkit'],\n",
    "                                                                    max_degree=model_params['max_degree'],\n",
    "                                                                    max_atoms=model_params['max_atoms'])\n",
    "        return [x_atoms_cold, x_bonds_cold, x_edges_cold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss',patience=8, min_delta=0)\n",
    "rlr = ReduceLROnPlateau(monitor='loss',factor=0.5, patience=4, verbose=1, min_lr=0.0000001)\n",
    "model_params = {\n",
    "        \"num_layers\" : 3,\n",
    "        \"max_atoms\" : 70,\n",
    "        \"num_atom_features\" : 62,\n",
    "        \"num_atom_features_original\" : 62,\n",
    "        \"num_bond_features\" : 6,\n",
    "        \"max_degree\" : 5,\n",
    "        \"conv_width\" : [int(56), int(88), int(136)],\n",
    "        \"fp_length\" : [int(152.0), int(152.0), int(152.0)],\n",
    "        \"activ_enc\" : \"selu\",\n",
    "        \"activ_dec\" : \"selu\",\n",
    "        \"learning_rates\" : [0.001,0.001,0.001],\n",
    "        \"learning_rates_fp\": [0.005,0.005,0.005],\n",
    "        \"losses_conv\" : {\n",
    "                    \"neighbor_output\": \"mean_squared_error\",\n",
    "                    \"self_output\": \"mean_squared_error\",\n",
    "                    },\n",
    "        \"lossWeights\" : {\"neighbor_output\": 1.0, \"self_output\": 1.0},\n",
    "        \"metrics\" : \"mse\",\n",
    "        \"loss_fp\" : \"mean_squared_error\",\n",
    "        \"enc_layer_names\" : [\"enc_1\", \"enc_2\", \"enc_3\"],\n",
    "        'callbacks' : [es,rlr],\n",
    "        'adam_decay': 0.0005329142291371636,\n",
    "        'beta': 5,\n",
    "        'p': 0.004465204118126482,\n",
    "        'dense_size' : [int(354), int(306), int(258)], \n",
    "        'dropout_rate' : [0.27225175676555935, 0.27225175676555935],\n",
    "        'lr' : 0.0008110012706176706,\n",
    "        'batch_size' : int(128),\n",
    "        'n_epochs' : int(30),\n",
    "        'margin' : 1\n",
    "        }\n",
    "xgb_hyper = {\n",
    "        \"colsample_bylevel\" : 0.4371082812232264,\n",
    "        \"colsample_bytree\" : 0.4179415558635843,\n",
    "        \"gamma\" : 0.919836526180396,\n",
    "        \"eta\" : 0.41409388868400826,\n",
    "        \"max_delta_step\" : int(2),\n",
    "        \"max_depth\" : int(7),\n",
    "        \"min_child_weight\" : int(20),\n",
    "        \"alpha\" : 0.15030685758880047,\n",
    "        \"lambda\" : 12.306130216692438,\n",
    "        \"subsample\" : 0.6038298323514097,\n",
    "        \"max_bin\" : int(48.0),\n",
    "        \"eval_metric\":'auc',\n",
    "        \"objective\":'binary:logistic',\n",
    "        \"booster\":'gbtree'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(dimension, start, end,name):\n",
    "    # Crops (or slices) a Tensor on a given dimension from start to end\n",
    "    # example : to crop tensor x[:, :, 5:10]\n",
    "    # call slice(2, 5, 10) as you want to crop on the second dimension\n",
    "    def func(x):\n",
    "        if dimension == 0:\n",
    "            return x[start: end]\n",
    "        if dimension == 1:\n",
    "            return x[:, start: end]\n",
    "        if dimension == 2:\n",
    "            return x[:, :, start: end]\n",
    "        if dimension == 3:\n",
    "            return x[:, :, :, start: end]\n",
    "        if dimension == 4:\n",
    "            return x[:, :, :, :, start: end]\n",
    "    return Lambda(func,name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "atom_inputs_1 (InputLayer)      (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_1 (InputLayer)      (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_1 (InputLayer)      (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_inputs_2 (InputLayer)      (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_2 (InputLayer)      (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_2 (InputLayer)      (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_inputs_3 (InputLayer)      (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_3 (InputLayer)      (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_3 (InputLayer)      (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "labels_inputs_1 (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_11 (Model)                [(None, 86), (None,  532278      atom_inputs_1[0][0]              \n",
      "                                                                 bond_inputs_1[0][0]              \n",
      "                                                                 edge_inputs_1[0][0]              \n",
      "                                                                 atom_inputs_2[0][0]              \n",
      "                                                                 bond_inputs_2[0][0]              \n",
      "                                                                 edge_inputs_2[0][0]              \n",
      "                                                                 atom_inputs_3[0][0]              \n",
      "                                                                 bond_inputs_3[0][0]              \n",
      "                                                                 edge_inputs_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "labels_inputs_2 (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "labels_inputs_3 (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Protein_1 (Concatenate)         (None, 87)           0           labels_inputs_1[0][0]            \n",
      "                                                                 model_11[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Protein_2 (Concatenate)         (None, 87)           0           labels_inputs_2[0][0]            \n",
      "                                                                 model_11[1][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "Protein_3 (Concatenate)         (None, 87)           0           labels_inputs_3[0][0]            \n",
      "                                                                 model_11[1][2]                   \n",
      "==================================================================================================\n",
      "Total params: 532,278\n",
      "Trainable params: 530,806\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "127/127 [==============================] - 20s 154ms/step - loss: 0.2718 - Protein_1_loss: 0.0913 - Protein_2_loss: 0.0908 - Protein_3_loss: 0.0897\n",
      "Epoch 2/30\n",
      "127/127 [==============================] - 11s 84ms/step - loss: 0.2537 - Protein_1_loss: 0.0888 - Protein_2_loss: 0.0789 - Protein_3_loss: 0.0860\n",
      "Epoch 3/30\n",
      "127/127 [==============================] - 11s 85ms/step - loss: 0.2427 - Protein_1_loss: 0.0872 - Protein_2_loss: 0.0704 - Protein_3_loss: 0.0852\n",
      "Epoch 4/30\n",
      "127/127 [==============================] - 11s 85ms/step - loss: 0.2370 - Protein_1_loss: 0.0864 - Protein_2_loss: 0.0657 - Protein_3_loss: 0.08493s - loss:\n",
      "Epoch 5/30\n",
      "127/127 [==============================] - 11s 84ms/step - loss: 0.2300 - Protein_1_loss: 0.0851 - Protein_2_loss: 0.0614 - Protein_3_loss: 0.0835\n",
      "Epoch 6/30\n",
      "127/127 [==============================] - 11s 86ms/step - loss: 0.2256 - Protein_1_loss: 0.0844 - Protein_2_loss: 0.0581 - Protein_3_loss: 0.0831\n",
      "Epoch 7/30\n",
      "127/127 [==============================] - 11s 85ms/step - loss: 0.2191 - Protein_1_loss: 0.0853 - Protein_2_loss: 0.0524 - Protein_3_loss: 0.0815\n",
      "Epoch 8/30\n",
      "127/127 [==============================] - 11s 86ms/step - loss: 0.2169 - Protein_1_loss: 0.0836 - Protein_2_loss: 0.0499 - Protein_3_loss: 0.0835\n",
      "Epoch 9/30\n",
      "127/127 [==============================] - 11s 86ms/step - loss: 0.2157 - Protein_1_loss: 0.0838 - Protein_2_loss: 0.0478 - Protein_3_loss: 0.0842\n",
      "Epoch 10/30\n",
      "127/127 [==============================] - 11s 88ms/step - loss: 0.2105 - Protein_1_loss: 0.0833 - Protein_2_loss: 0.0435 - Protein_3_loss: 0.0836\n",
      "Epoch 11/30\n",
      "127/127 [==============================] - 12s 94ms/step - loss: 0.2089 - Protein_1_loss: 0.0833 - Protein_2_loss: 0.0418 - Protein_3_loss: 0.08381s - loss: 0.2088 - Protein_1_loss: 0.0835 - Protein\n",
      "Epoch 12/30\n",
      "127/127 [==============================] - 12s 93ms/step - loss: 0.2045 - Protein_1_loss: 0.0834 - Protein_2_loss: 0.0390 - Protein_3_loss: 0.0821\n",
      "Epoch 13/30\n",
      "127/127 [==============================] - 11s 90ms/step - loss: 0.2021 - Protein_1_loss: 0.0830 - Protein_2_loss: 0.0394 - Protein_3_loss: 0.0797\n",
      "Epoch 14/30\n",
      "127/127 [==============================] - 11s 89ms/step - loss: 0.1940 - Protein_1_loss: 0.0842 - Protein_2_loss: 0.0351 - Protein_3_loss: 0.0747\n",
      "Epoch 15/30\n",
      "127/127 [==============================] - 11s 91ms/step - loss: 0.1937 - Protein_1_loss: 0.0838 - Protein_2_loss: 0.0356 - Protein_3_loss: 0.0743\n",
      "Epoch 16/30\n",
      "127/127 [==============================] - 12s 91ms/step - loss: 0.1851 - Protein_1_loss: 0.0834 - Protein_2_loss: 0.0322 - Protein_3_loss: 0.06958s - l\n",
      "Epoch 17/30\n",
      "127/127 [==============================] - 11s 90ms/step - loss: 0.1807 - Protein_1_loss: 0.0832 - Protein_2_loss: 0.0314 - Protein_3_loss: 0.0660\n",
      "Epoch 18/30\n",
      "127/127 [==============================] - 11s 88ms/step - loss: 0.1783 - Protein_1_loss: 0.0832 - Protein_2_loss: 0.0311 - Protein_3_loss: 0.0639\n",
      "Epoch 19/30\n",
      "127/127 [==============================] - 11s 89ms/step - loss: 0.1720 - Protein_1_loss: 0.0833 - Protein_2_loss: 0.0286 - Protein_3_loss: 0.0601\n",
      "Epoch 20/30\n",
      "127/127 [==============================] - 11s 90ms/step - loss: 0.1696 - Protein_1_loss: 0.0828 - Protein_2_loss: 0.0277 - Protein_3_loss: 0.0592\n",
      "Epoch 21/30\n",
      "127/127 [==============================] - 11s 89ms/step - loss: 0.1675 - Protein_1_loss: 0.0831 - Protein_2_loss: 0.0281 - Protein_3_loss: 0.0563\n",
      "Epoch 22/30\n",
      "127/127 [==============================] - 11s 90ms/step - loss: 0.1672 - Protein_1_loss: 0.0835 - Protein_2_loss: 0.0273 - Protein_3_loss: 0.0564\n",
      "Epoch 23/30\n",
      "127/127 [==============================] - 12s 92ms/step - loss: 0.1633 - Protein_1_loss: 0.0840 - Protein_2_loss: 0.0269 - Protein_3_loss: 0.0524\n",
      "Epoch 24/30\n",
      "127/127 [==============================] - 11s 89ms/step - loss: 0.1599 - Protein_1_loss: 0.0835 - Protein_2_loss: 0.0254 - Protein_3_loss: 0.0510\n",
      "Epoch 25/30\n",
      "127/127 [==============================] - 11s 89ms/step - loss: 0.1507 - Protein_1_loss: 0.0827 - Protein_2_loss: 0.0211 - Protein_3_loss: 0.0469\n",
      "Epoch 26/30\n",
      "127/127 [==============================] - 11s 88ms/step - loss: 0.1518 - Protein_1_loss: 0.0828 - Protein_2_loss: 0.0231 - Protein_3_loss: 0.0459\n",
      "Epoch 27/30\n",
      "127/127 [==============================] - 11s 88ms/step - loss: 0.1497 - Protein_1_loss: 0.0825 - Protein_2_loss: 0.0220 - Protein_3_loss: 0.0452\n",
      "Epoch 28/30\n",
      "127/127 [==============================] - 11s 90ms/step - loss: 0.1512 - Protein_1_loss: 0.0826 - Protein_2_loss: 0.0222 - Protein_3_loss: 0.0464\n",
      "Epoch 29/30\n",
      "127/127 [==============================] - 11s 89ms/step - loss: 0.1454 - Protein_1_loss: 0.0826 - Protein_2_loss: 0.0208 - Protein_3_loss: 0.0420\n",
      "Epoch 30/30\n",
      "127/127 [==============================] - 11s 90ms/step - loss: 0.1472 - Protein_1_loss: 0.0826 - Protein_2_loss: 0.0220 - Protein_3_loss: 0.0427\n",
      "[0]\ttrain-auc:0.62072\teval-auc:0.52737\n",
      "[1]\ttrain-auc:0.64551\teval-auc:0.50547\n",
      "[2]\ttrain-auc:0.65259\teval-auc:0.51917\n",
      "[3]\ttrain-auc:0.66205\teval-auc:0.50704\n",
      "[4]\ttrain-auc:0.67271\teval-auc:0.51636\n",
      "[5]\ttrain-auc:0.68316\teval-auc:0.51609\n",
      "[6]\ttrain-auc:0.68645\teval-auc:0.52545\n",
      "[7]\ttrain-auc:0.69139\teval-auc:0.53161\n",
      "[8]\ttrain-auc:0.69580\teval-auc:0.53630\n",
      "[9]\ttrain-auc:0.70027\teval-auc:0.52275\n",
      "[10]\ttrain-auc:0.70670\teval-auc:0.52336\n",
      "[11]\ttrain-auc:0.71135\teval-auc:0.52791\n",
      "[12]\ttrain-auc:0.71814\teval-auc:0.53527\n",
      "[13]\ttrain-auc:0.72413\teval-auc:0.53914\n",
      "[14]\ttrain-auc:0.72781\teval-auc:0.53409\n",
      "[15]\ttrain-auc:0.73120\teval-auc:0.53233\n",
      "[16]\ttrain-auc:0.73549\teval-auc:0.53081\n",
      "[17]\ttrain-auc:0.73871\teval-auc:0.53328\n",
      "[18]\ttrain-auc:0.74422\teval-auc:0.52721\n",
      "[19]\ttrain-auc:0.74868\teval-auc:0.53219\n",
      "[20]\ttrain-auc:0.75417\teval-auc:0.53382\n",
      "[21]\ttrain-auc:0.75760\teval-auc:0.52975\n",
      "[22]\ttrain-auc:0.76110\teval-auc:0.53052\n",
      "[23]\ttrain-auc:0.76627\teval-auc:0.52727\n",
      "[24]\ttrain-auc:0.76707\teval-auc:0.52824\n",
      "[25]\ttrain-auc:0.77028\teval-auc:0.52846\n",
      "[26]\ttrain-auc:0.77263\teval-auc:0.52952\n",
      "[27]\ttrain-auc:0.77486\teval-auc:0.53691\n",
      "[28]\ttrain-auc:0.77474\teval-auc:0.53996\n",
      "[29]\ttrain-auc:0.77645\teval-auc:0.53744\n",
      "[30]\ttrain-auc:0.78033\teval-auc:0.53606\n",
      "[31]\ttrain-auc:0.78344\teval-auc:0.54277\n",
      "[32]\ttrain-auc:0.78810\teval-auc:0.54290\n",
      "[33]\ttrain-auc:0.79064\teval-auc:0.53790\n",
      "[34]\ttrain-auc:0.79609\teval-auc:0.54561\n",
      "[35]\ttrain-auc:0.79731\teval-auc:0.54740\n",
      "[36]\ttrain-auc:0.79693\teval-auc:0.54492\n",
      "[37]\ttrain-auc:0.80045\teval-auc:0.54191\n",
      "[38]\ttrain-auc:0.80178\teval-auc:0.54225\n",
      "[39]\ttrain-auc:0.80318\teval-auc:0.53826\n",
      "[40]\ttrain-auc:0.80624\teval-auc:0.53792\n",
      "[41]\ttrain-auc:0.81028\teval-auc:0.54186\n",
      "[42]\ttrain-auc:0.80899\teval-auc:0.53968\n",
      "[43]\ttrain-auc:0.81291\teval-auc:0.54326\n",
      "[44]\ttrain-auc:0.81541\teval-auc:0.53564\n",
      "[45]\ttrain-auc:0.81585\teval-auc:0.53635\n",
      "[46]\ttrain-auc:0.81936\teval-auc:0.53498\n",
      "[47]\ttrain-auc:0.82570\teval-auc:0.53894\n",
      "[48]\ttrain-auc:0.82593\teval-auc:0.53744\n",
      "[49]\ttrain-auc:0.82588\teval-auc:0.53248\n",
      "[50]\ttrain-auc:0.82790\teval-auc:0.52941\n",
      "[51]\ttrain-auc:0.82984\teval-auc:0.52740\n",
      "[52]\ttrain-auc:0.83382\teval-auc:0.52845\n",
      "[53]\ttrain-auc:0.83739\teval-auc:0.52977\n",
      "[54]\ttrain-auc:0.84011\teval-auc:0.54149\n",
      "[55]\ttrain-auc:0.84036\teval-auc:0.54855\n",
      "[56]\ttrain-auc:0.83909\teval-auc:0.54717\n",
      "[57]\ttrain-auc:0.83954\teval-auc:0.54248\n",
      "[58]\ttrain-auc:0.84145\teval-auc:0.54530\n",
      "[59]\ttrain-auc:0.84564\teval-auc:0.54504\n",
      "[60]\ttrain-auc:0.84631\teval-auc:0.54784\n",
      "[61]\ttrain-auc:0.84838\teval-auc:0.54406\n",
      "[62]\ttrain-auc:0.85192\teval-auc:0.54397\n",
      "[63]\ttrain-auc:0.85242\teval-auc:0.54482\n",
      "[64]\ttrain-auc:0.85359\teval-auc:0.54292\n",
      "[65]\ttrain-auc:0.85465\teval-auc:0.54321\n",
      "[66]\ttrain-auc:0.85468\teval-auc:0.54321\n",
      "[67]\ttrain-auc:0.85792\teval-auc:0.53780\n",
      "[68]\ttrain-auc:0.85981\teval-auc:0.54709\n",
      "[69]\ttrain-auc:0.86014\teval-auc:0.54686\n",
      "[70]\ttrain-auc:0.86282\teval-auc:0.54429\n",
      "[71]\ttrain-auc:0.86580\teval-auc:0.54662\n",
      "[72]\ttrain-auc:0.86790\teval-auc:0.54050\n",
      "[73]\ttrain-auc:0.87062\teval-auc:0.54031\n",
      "[74]\ttrain-auc:0.87093\teval-auc:0.54052\n",
      "[75]\ttrain-auc:0.86951\teval-auc:0.53967\n",
      "[76]\ttrain-auc:0.87068\teval-auc:0.54158\n",
      "[77]\ttrain-auc:0.87327\teval-auc:0.53946\n",
      "[78]\ttrain-auc:0.87407\teval-auc:0.53738\n",
      "[79]\ttrain-auc:0.87546\teval-auc:0.53753\n",
      "[80]\ttrain-auc:0.87665\teval-auc:0.53575\n",
      "[81]\ttrain-auc:0.87824\teval-auc:0.53514\n",
      "[82]\ttrain-auc:0.88135\teval-auc:0.53204\n",
      "[83]\ttrain-auc:0.88031\teval-auc:0.53083\n",
      "[84]\ttrain-auc:0.88132\teval-auc:0.53546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85]\ttrain-auc:0.88061\teval-auc:0.53604\n",
      "[86]\ttrain-auc:0.88068\teval-auc:0.53328\n",
      "[87]\ttrain-auc:0.88263\teval-auc:0.53542\n",
      "[88]\ttrain-auc:0.88371\teval-auc:0.53625\n",
      "[89]\ttrain-auc:0.88516\teval-auc:0.53348\n",
      "[90]\ttrain-auc:0.88710\teval-auc:0.53744\n",
      "[91]\ttrain-auc:0.88770\teval-auc:0.53711\n",
      "[92]\ttrain-auc:0.89047\teval-auc:0.53550\n",
      "[93]\ttrain-auc:0.89099\teval-auc:0.53083\n",
      "[94]\ttrain-auc:0.89285\teval-auc:0.52848\n",
      "[95]\ttrain-auc:0.89413\teval-auc:0.52558\n",
      "[96]\ttrain-auc:0.89772\teval-auc:0.52854\n",
      "[97]\ttrain-auc:0.89690\teval-auc:0.52882\n",
      "[98]\ttrain-auc:0.89869\teval-auc:0.53492\n",
      "[99]\ttrain-auc:0.89905\teval-auc:0.53709\n",
      "[100]\ttrain-auc:0.90034\teval-auc:0.53410\n",
      "[101]\ttrain-auc:0.90113\teval-auc:0.53210\n",
      "[102]\ttrain-auc:0.90322\teval-auc:0.52748\n",
      "[103]\ttrain-auc:0.90291\teval-auc:0.52321\n",
      "[104]\ttrain-auc:0.90217\teval-auc:0.52709\n",
      "[105]\ttrain-auc:0.90310\teval-auc:0.52152\n",
      "[106]\ttrain-auc:0.90416\teval-auc:0.52441\n",
      "[107]\ttrain-auc:0.90474\teval-auc:0.52025\n",
      "[108]\ttrain-auc:0.90644\teval-auc:0.52048\n",
      "[109]\ttrain-auc:0.90685\teval-auc:0.52112\n",
      "[110]\ttrain-auc:0.90906\teval-auc:0.52067\n",
      "[111]\ttrain-auc:0.90970\teval-auc:0.52183\n",
      "[112]\ttrain-auc:0.90804\teval-auc:0.51904\n",
      "[113]\ttrain-auc:0.90853\teval-auc:0.52041\n",
      "[114]\ttrain-auc:0.90865\teval-auc:0.52511\n",
      "[115]\ttrain-auc:0.91062\teval-auc:0.52817\n",
      "[116]\ttrain-auc:0.91174\teval-auc:0.53076\n",
      "[117]\ttrain-auc:0.91253\teval-auc:0.52697\n",
      "[118]\ttrain-auc:0.91311\teval-auc:0.52016\n",
      "[119]\ttrain-auc:0.91677\teval-auc:0.51884\n",
      "[120]\ttrain-auc:0.91737\teval-auc:0.51980\n",
      "[121]\ttrain-auc:0.91739\teval-auc:0.52102\n",
      "[122]\ttrain-auc:0.91862\teval-auc:0.51977\n",
      "[123]\ttrain-auc:0.91787\teval-auc:0.52173\n",
      "[124]\ttrain-auc:0.91741\teval-auc:0.52367\n",
      "[125]\ttrain-auc:0.91875\teval-auc:0.52618\n",
      "[126]\ttrain-auc:0.91779\teval-auc:0.52239\n",
      "[127]\ttrain-auc:0.91829\teval-auc:0.52102\n",
      "[128]\ttrain-auc:0.91950\teval-auc:0.52503\n",
      "[129]\ttrain-auc:0.92203\teval-auc:0.52793\n",
      "[130]\ttrain-auc:0.92339\teval-auc:0.52389\n",
      "[131]\ttrain-auc:0.92302\teval-auc:0.52481\n",
      "[132]\ttrain-auc:0.92472\teval-auc:0.52368\n",
      "[133]\ttrain-auc:0.92326\teval-auc:0.52217\n",
      "[134]\ttrain-auc:0.92374\teval-auc:0.51504\n",
      "[135]\ttrain-auc:0.92452\teval-auc:0.51684\n",
      "[136]\ttrain-auc:0.92548\teval-auc:0.52321\n",
      "[137]\ttrain-auc:0.92525\teval-auc:0.51999\n",
      "[138]\ttrain-auc:0.92644\teval-auc:0.52140\n",
      "[139]\ttrain-auc:0.92749\teval-auc:0.52383\n",
      "[140]\ttrain-auc:0.92940\teval-auc:0.52331\n",
      "[141]\ttrain-auc:0.93039\teval-auc:0.52543\n",
      "[142]\ttrain-auc:0.93106\teval-auc:0.52391\n",
      "[143]\ttrain-auc:0.93258\teval-auc:0.52376\n",
      "[144]\ttrain-auc:0.93176\teval-auc:0.52647\n",
      "[145]\ttrain-auc:0.93268\teval-auc:0.52515\n",
      "[146]\ttrain-auc:0.93297\teval-auc:0.52329\n",
      "[147]\ttrain-auc:0.93364\teval-auc:0.52032\n",
      "[148]\ttrain-auc:0.93383\teval-auc:0.52331\n",
      "[149]\ttrain-auc:0.93421\teval-auc:0.52151\n",
      "[150]\ttrain-auc:0.93527\teval-auc:0.52193\n",
      "[151]\ttrain-auc:0.93764\teval-auc:0.52009\n",
      "[152]\ttrain-auc:0.93757\teval-auc:0.51950\n",
      "[153]\ttrain-auc:0.93858\teval-auc:0.52049\n",
      "[154]\ttrain-auc:0.93807\teval-auc:0.51607\n",
      "[155]\ttrain-auc:0.93892\teval-auc:0.51811\n",
      "[156]\ttrain-auc:0.93900\teval-auc:0.51983\n",
      "[157]\ttrain-auc:0.93730\teval-auc:0.52157\n",
      "[158]\ttrain-auc:0.93929\teval-auc:0.51912\n",
      "[159]\ttrain-auc:0.93956\teval-auc:0.52098\n",
      "[160]\ttrain-auc:0.93981\teval-auc:0.51993\n",
      "[161]\ttrain-auc:0.94052\teval-auc:0.51937\n",
      "[162]\ttrain-auc:0.94100\teval-auc:0.52383\n",
      "[163]\ttrain-auc:0.94176\teval-auc:0.52568\n",
      "[164]\ttrain-auc:0.94144\teval-auc:0.52447\n",
      "[165]\ttrain-auc:0.94184\teval-auc:0.52297\n",
      "[166]\ttrain-auc:0.94282\teval-auc:0.52096\n",
      "[167]\ttrain-auc:0.94320\teval-auc:0.52045\n",
      "[168]\ttrain-auc:0.94239\teval-auc:0.51980\n",
      "[169]\ttrain-auc:0.94244\teval-auc:0.52357\n",
      "[170]\ttrain-auc:0.94294\teval-auc:0.52590\n",
      "[171]\ttrain-auc:0.94334\teval-auc:0.52328\n",
      "[172]\ttrain-auc:0.94377\teval-auc:0.52114\n",
      "[173]\ttrain-auc:0.94373\teval-auc:0.52225\n",
      "[174]\ttrain-auc:0.94512\teval-auc:0.52500\n",
      "[175]\ttrain-auc:0.94630\teval-auc:0.52816\n",
      "[176]\ttrain-auc:0.94600\teval-auc:0.52605\n",
      "[177]\ttrain-auc:0.94805\teval-auc:0.52415\n",
      "[178]\ttrain-auc:0.94841\teval-auc:0.52631\n",
      "[179]\ttrain-auc:0.94802\teval-auc:0.52830\n",
      "[180]\ttrain-auc:0.94838\teval-auc:0.52647\n",
      "[181]\ttrain-auc:0.94835\teval-auc:0.52404\n",
      "[182]\ttrain-auc:0.94931\teval-auc:0.52136\n",
      "[183]\ttrain-auc:0.95061\teval-auc:0.52378\n",
      "[184]\ttrain-auc:0.95103\teval-auc:0.52352\n",
      "[185]\ttrain-auc:0.95119\teval-auc:0.52572\n",
      "[186]\ttrain-auc:0.95240\teval-auc:0.52592\n",
      "[187]\ttrain-auc:0.95276\teval-auc:0.52362\n",
      "[188]\ttrain-auc:0.95085\teval-auc:0.52286\n",
      "[189]\ttrain-auc:0.95263\teval-auc:0.51911\n",
      "[190]\ttrain-auc:0.95408\teval-auc:0.51911\n",
      "[191]\ttrain-auc:0.95417\teval-auc:0.51875\n",
      "[192]\ttrain-auc:0.95522\teval-auc:0.52220\n",
      "[193]\ttrain-auc:0.95484\teval-auc:0.52286\n",
      "[194]\ttrain-auc:0.95505\teval-auc:0.52088\n",
      "[195]\ttrain-auc:0.95643\teval-auc:0.51779\n",
      "[196]\ttrain-auc:0.95757\teval-auc:0.51673\n",
      "[197]\ttrain-auc:0.95785\teval-auc:0.51289\n",
      "[198]\ttrain-auc:0.95892\teval-auc:0.51462\n",
      "[199]\ttrain-auc:0.95899\teval-auc:0.51748\n",
      "[200]\ttrain-auc:0.95840\teval-auc:0.51674\n",
      "[201]\ttrain-auc:0.95850\teval-auc:0.51402\n",
      "[202]\ttrain-auc:0.95869\teval-auc:0.51603\n",
      "[203]\ttrain-auc:0.95838\teval-auc:0.51771\n",
      "[204]\ttrain-auc:0.95810\teval-auc:0.51953\n",
      "[205]\ttrain-auc:0.95882\teval-auc:0.52439\n",
      "[206]\ttrain-auc:0.95868\teval-auc:0.52452\n",
      "[207]\ttrain-auc:0.95989\teval-auc:0.52497\n",
      "[208]\ttrain-auc:0.96088\teval-auc:0.52627\n",
      "[209]\ttrain-auc:0.96150\teval-auc:0.52737\n",
      "[210]\ttrain-auc:0.96113\teval-auc:0.52717\n",
      "[211]\ttrain-auc:0.96119\teval-auc:0.53030\n",
      "[212]\ttrain-auc:0.96086\teval-auc:0.53295\n",
      "[213]\ttrain-auc:0.96169\teval-auc:0.53205\n",
      "[214]\ttrain-auc:0.96206\teval-auc:0.53258\n",
      "[215]\ttrain-auc:0.96182\teval-auc:0.53352\n",
      "[216]\ttrain-auc:0.96229\teval-auc:0.53215\n",
      "[217]\ttrain-auc:0.96107\teval-auc:0.53249\n",
      "[218]\ttrain-auc:0.96258\teval-auc:0.53390\n",
      "[219]\ttrain-auc:0.96439\teval-auc:0.53305\n",
      "[220]\ttrain-auc:0.96456\teval-auc:0.53431\n",
      "[221]\ttrain-auc:0.96559\teval-auc:0.53743\n",
      "[222]\ttrain-auc:0.96510\teval-auc:0.53390\n",
      "[223]\ttrain-auc:0.96455\teval-auc:0.53480\n",
      "[224]\ttrain-auc:0.96532\teval-auc:0.53489\n",
      "[225]\ttrain-auc:0.96406\teval-auc:0.53724\n",
      "[226]\ttrain-auc:0.96484\teval-auc:0.53474\n",
      "[227]\ttrain-auc:0.96515\teval-auc:0.53548\n",
      "[228]\ttrain-auc:0.96580\teval-auc:0.53759\n",
      "[229]\ttrain-auc:0.96584\teval-auc:0.53865\n",
      "[230]\ttrain-auc:0.96618\teval-auc:0.53641\n",
      "[231]\ttrain-auc:0.96636\teval-auc:0.53355\n",
      "[232]\ttrain-auc:0.96596\teval-auc:0.53144\n",
      "[233]\ttrain-auc:0.96681\teval-auc:0.52986\n",
      "[234]\ttrain-auc:0.96718\teval-auc:0.53054\n",
      "[235]\ttrain-auc:0.96733\teval-auc:0.53274\n",
      "[236]\ttrain-auc:0.96610\teval-auc:0.53371\n",
      "[237]\ttrain-auc:0.96658\teval-auc:0.53329\n",
      "[238]\ttrain-auc:0.96712\teval-auc:0.53577\n",
      "[239]\ttrain-auc:0.96787\teval-auc:0.53522\n",
      "[240]\ttrain-auc:0.96801\teval-auc:0.53793\n",
      "[241]\ttrain-auc:0.96756\teval-auc:0.53664\n",
      "[242]\ttrain-auc:0.96662\teval-auc:0.53635\n",
      "[243]\ttrain-auc:0.96808\teval-auc:0.53648\n",
      "[244]\ttrain-auc:0.96871\teval-auc:0.53482\n",
      "[245]\ttrain-auc:0.96891\teval-auc:0.53711\n",
      "[246]\ttrain-auc:0.96917\teval-auc:0.53864\n",
      "[247]\ttrain-auc:0.96928\teval-auc:0.53637\n",
      "[248]\ttrain-auc:0.96943\teval-auc:0.53627\n",
      "[249]\ttrain-auc:0.96950\teval-auc:0.53101\n",
      "[250]\ttrain-auc:0.96923\teval-auc:0.53261\n",
      "[251]\ttrain-auc:0.96962\teval-auc:0.53279\n",
      "[252]\ttrain-auc:0.97046\teval-auc:0.53381\n",
      "[253]\ttrain-auc:0.97089\teval-auc:0.53258\n",
      "[254]\ttrain-auc:0.97164\teval-auc:0.53344\n",
      "[255]\ttrain-auc:0.97219\teval-auc:0.53555\n",
      "[256]\ttrain-auc:0.97228\teval-auc:0.53484\n",
      "[257]\ttrain-auc:0.97214\teval-auc:0.53299\n",
      "[258]\ttrain-auc:0.97260\teval-auc:0.53522\n",
      "[259]\ttrain-auc:0.97294\teval-auc:0.53376\n",
      "[260]\ttrain-auc:0.97408\teval-auc:0.53687\n",
      "[261]\ttrain-auc:0.97354\teval-auc:0.53464\n",
      "[262]\ttrain-auc:0.97325\teval-auc:0.52975\n",
      "[263]\ttrain-auc:0.97448\teval-auc:0.53279\n",
      "[264]\ttrain-auc:0.97384\teval-auc:0.53017\n",
      "[265]\ttrain-auc:0.97319\teval-auc:0.52853\n",
      "[266]\ttrain-auc:0.97281\teval-auc:0.53046\n",
      "[267]\ttrain-auc:0.97295\teval-auc:0.52883\n",
      "[268]\ttrain-auc:0.97391\teval-auc:0.53097\n",
      "[269]\ttrain-auc:0.97385\teval-auc:0.53038\n",
      "[270]\ttrain-auc:0.97389\teval-auc:0.53028\n",
      "[271]\ttrain-auc:0.97331\teval-auc:0.52888\n",
      "[272]\ttrain-auc:0.97408\teval-auc:0.52994\n",
      "[273]\ttrain-auc:0.97392\teval-auc:0.52931\n",
      "[274]\ttrain-auc:0.97381\teval-auc:0.53299\n",
      "[275]\ttrain-auc:0.97423\teval-auc:0.53445\n",
      "[276]\ttrain-auc:0.97470\teval-auc:0.53299\n",
      "[277]\ttrain-auc:0.97403\teval-auc:0.53175\n",
      "[278]\ttrain-auc:0.97406\teval-auc:0.53260\n",
      "[279]\ttrain-auc:0.97471\teval-auc:0.53489\n",
      "[280]\ttrain-auc:0.97542\teval-auc:0.53574\n",
      "[281]\ttrain-auc:0.97549\teval-auc:0.53704\n",
      "[282]\ttrain-auc:0.97605\teval-auc:0.53751\n",
      "[283]\ttrain-auc:0.97604\teval-auc:0.53498\n",
      "[284]\ttrain-auc:0.97594\teval-auc:0.53683\n",
      "[285]\ttrain-auc:0.97579\teval-auc:0.53511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[286]\ttrain-auc:0.97570\teval-auc:0.53624\n",
      "[287]\ttrain-auc:0.97627\teval-auc:0.53780\n",
      "[288]\ttrain-auc:0.97565\teval-auc:0.53612\n",
      "[289]\ttrain-auc:0.97627\teval-auc:0.53474\n",
      "[290]\ttrain-auc:0.97651\teval-auc:0.53596\n",
      "[291]\ttrain-auc:0.97663\teval-auc:0.53592\n",
      "[292]\ttrain-auc:0.97621\teval-auc:0.53563\n",
      "[293]\ttrain-auc:0.97668\teval-auc:0.53796\n",
      "[294]\ttrain-auc:0.97679\teval-auc:0.53839\n",
      "[295]\ttrain-auc:0.97723\teval-auc:0.53582\n",
      "[296]\ttrain-auc:0.97718\teval-auc:0.53405\n",
      "[297]\ttrain-auc:0.97698\teval-auc:0.53303\n",
      "[298]\ttrain-auc:0.97740\teval-auc:0.53120\n",
      "[299]\ttrain-auc:0.97749\teval-auc:0.52954\n",
      "[0]\ttrain-auc:0.97023\teval-auc:0.82672\n",
      "[1]\ttrain-auc:0.97716\teval-auc:0.82856\n",
      "[2]\ttrain-auc:0.97757\teval-auc:0.83230\n",
      "[3]\ttrain-auc:0.98020\teval-auc:0.83825\n",
      "[4]\ttrain-auc:0.98058\teval-auc:0.84009\n",
      "[5]\ttrain-auc:0.98113\teval-auc:0.84862\n",
      "[6]\ttrain-auc:0.98162\teval-auc:0.84848\n",
      "[7]\ttrain-auc:0.98154\teval-auc:0.85070\n",
      "[8]\ttrain-auc:0.98218\teval-auc:0.84880\n",
      "[9]\ttrain-auc:0.98234\teval-auc:0.85079\n",
      "[10]\ttrain-auc:0.98231\teval-auc:0.85005\n",
      "[11]\ttrain-auc:0.98242\teval-auc:0.85032\n",
      "[12]\ttrain-auc:0.98329\teval-auc:0.84918\n",
      "[13]\ttrain-auc:0.98332\teval-auc:0.84961\n",
      "[14]\ttrain-auc:0.98331\teval-auc:0.84961\n",
      "[15]\ttrain-auc:0.98345\teval-auc:0.84850\n",
      "[16]\ttrain-auc:0.98351\teval-auc:0.84798\n",
      "[17]\ttrain-auc:0.98354\teval-auc:0.84957\n",
      "[18]\ttrain-auc:0.98317\teval-auc:0.85215\n",
      "[19]\ttrain-auc:0.98330\teval-auc:0.85225\n",
      "[20]\ttrain-auc:0.98321\teval-auc:0.85415\n",
      "[21]\ttrain-auc:0.98342\teval-auc:0.85399\n",
      "[22]\ttrain-auc:0.98339\teval-auc:0.85313\n",
      "[23]\ttrain-auc:0.98358\teval-auc:0.85290\n",
      "[24]\ttrain-auc:0.98363\teval-auc:0.85202\n",
      "[25]\ttrain-auc:0.98359\teval-auc:0.85197\n",
      "[26]\ttrain-auc:0.98362\teval-auc:0.85202\n",
      "[27]\ttrain-auc:0.98385\teval-auc:0.85438\n",
      "[28]\ttrain-auc:0.98381\teval-auc:0.85315\n",
      "[29]\ttrain-auc:0.98439\teval-auc:0.85188\n",
      "[30]\ttrain-auc:0.98437\teval-auc:0.85243\n",
      "[31]\ttrain-auc:0.98493\teval-auc:0.85134\n",
      "[32]\ttrain-auc:0.98490\teval-auc:0.85157\n",
      "[33]\ttrain-auc:0.98481\teval-auc:0.85229\n",
      "[34]\ttrain-auc:0.98510\teval-auc:0.85020\n",
      "[35]\ttrain-auc:0.98575\teval-auc:0.85315\n",
      "[36]\ttrain-auc:0.98583\teval-auc:0.85288\n",
      "[37]\ttrain-auc:0.98589\teval-auc:0.85324\n",
      "[38]\ttrain-auc:0.98596\teval-auc:0.85261\n",
      "[39]\ttrain-auc:0.98588\teval-auc:0.85320\n",
      "[40]\ttrain-auc:0.98609\teval-auc:0.85490\n",
      "[41]\ttrain-auc:0.98623\teval-auc:0.85445\n",
      "[42]\ttrain-auc:0.98651\teval-auc:0.85458\n",
      "[43]\ttrain-auc:0.98647\teval-auc:0.85422\n",
      "[44]\ttrain-auc:0.98663\teval-auc:0.85399\n",
      "[45]\ttrain-auc:0.98664\teval-auc:0.85449\n",
      "[46]\ttrain-auc:0.98684\teval-auc:0.85299\n",
      "[47]\ttrain-auc:0.98693\teval-auc:0.85272\n",
      "[48]\ttrain-auc:0.98686\teval-auc:0.85381\n",
      "[49]\ttrain-auc:0.98706\teval-auc:0.85431\n",
      "[50]\ttrain-auc:0.98730\teval-auc:0.85272\n",
      "[51]\ttrain-auc:0.98729\teval-auc:0.85259\n",
      "[52]\ttrain-auc:0.98733\teval-auc:0.85259\n",
      "[53]\ttrain-auc:0.98718\teval-auc:0.85263\n",
      "[54]\ttrain-auc:0.98726\teval-auc:0.85256\n",
      "[55]\ttrain-auc:0.98717\teval-auc:0.85352\n",
      "[56]\ttrain-auc:0.98744\teval-auc:0.85379\n",
      "[57]\ttrain-auc:0.98731\teval-auc:0.85329\n",
      "[58]\ttrain-auc:0.98724\teval-auc:0.85343\n",
      "[59]\ttrain-auc:0.98736\teval-auc:0.85270\n",
      "[60]\ttrain-auc:0.98744\teval-auc:0.85247\n",
      "[61]\ttrain-auc:0.98741\teval-auc:0.85218\n",
      "[62]\ttrain-auc:0.98734\teval-auc:0.85213\n",
      "[63]\ttrain-auc:0.98729\teval-auc:0.85195\n",
      "[64]\ttrain-auc:0.98734\teval-auc:0.85331\n",
      "[65]\ttrain-auc:0.98748\teval-auc:0.85331\n",
      "[66]\ttrain-auc:0.98752\teval-auc:0.85220\n",
      "[67]\ttrain-auc:0.98759\teval-auc:0.85306\n",
      "[68]\ttrain-auc:0.98777\teval-auc:0.85238\n",
      "[69]\ttrain-auc:0.98774\teval-auc:0.85229\n",
      "[70]\ttrain-auc:0.98785\teval-auc:0.85202\n",
      "[71]\ttrain-auc:0.98801\teval-auc:0.85075\n",
      "[72]\ttrain-auc:0.98808\teval-auc:0.85073\n",
      "[73]\ttrain-auc:0.98806\teval-auc:0.84975\n",
      "[74]\ttrain-auc:0.98806\teval-auc:0.85011\n",
      "[75]\ttrain-auc:0.98821\teval-auc:0.85295\n",
      "[76]\ttrain-auc:0.98843\teval-auc:0.85299\n",
      "[77]\ttrain-auc:0.98859\teval-auc:0.85272\n",
      "[78]\ttrain-auc:0.98858\teval-auc:0.85449\n",
      "[79]\ttrain-auc:0.98854\teval-auc:0.85445\n",
      "[80]\ttrain-auc:0.98869\teval-auc:0.85408\n",
      "[81]\ttrain-auc:0.98879\teval-auc:0.85363\n",
      "[82]\ttrain-auc:0.98872\teval-auc:0.85367\n",
      "[83]\ttrain-auc:0.98870\teval-auc:0.85395\n",
      "[84]\ttrain-auc:0.98873\teval-auc:0.85486\n",
      "[85]\ttrain-auc:0.98883\teval-auc:0.85481\n",
      "[86]\ttrain-auc:0.98880\teval-auc:0.85381\n",
      "[87]\ttrain-auc:0.98880\teval-auc:0.85574\n",
      "[88]\ttrain-auc:0.98883\teval-auc:0.85624\n",
      "[89]\ttrain-auc:0.98888\teval-auc:0.85565\n",
      "[90]\ttrain-auc:0.98883\teval-auc:0.85556\n",
      "[91]\ttrain-auc:0.98878\teval-auc:0.85588\n",
      "[92]\ttrain-auc:0.98873\teval-auc:0.85551\n",
      "[93]\ttrain-auc:0.98867\teval-auc:0.85588\n",
      "[94]\ttrain-auc:0.98876\teval-auc:0.85579\n",
      "[95]\ttrain-auc:0.98881\teval-auc:0.85581\n",
      "[96]\ttrain-auc:0.98874\teval-auc:0.85476\n",
      "[97]\ttrain-auc:0.98882\teval-auc:0.85408\n",
      "[98]\ttrain-auc:0.98890\teval-auc:0.85381\n",
      "[99]\ttrain-auc:0.98894\teval-auc:0.85354\n",
      "[100]\ttrain-auc:0.98891\teval-auc:0.85299\n",
      "[101]\ttrain-auc:0.98884\teval-auc:0.85345\n",
      "[102]\ttrain-auc:0.98889\teval-auc:0.85363\n",
      "[103]\ttrain-auc:0.98898\teval-auc:0.85472\n",
      "[104]\ttrain-auc:0.98906\teval-auc:0.85404\n",
      "[105]\ttrain-auc:0.98912\teval-auc:0.85363\n",
      "[106]\ttrain-auc:0.98917\teval-auc:0.85449\n",
      "[107]\ttrain-auc:0.98916\teval-auc:0.85563\n",
      "[108]\ttrain-auc:0.98929\teval-auc:0.85540\n",
      "[109]\ttrain-auc:0.98937\teval-auc:0.85522\n",
      "[110]\ttrain-auc:0.98951\teval-auc:0.85204\n",
      "[111]\ttrain-auc:0.98947\teval-auc:0.85250\n",
      "[112]\ttrain-auc:0.98947\teval-auc:0.85204\n",
      "[113]\ttrain-auc:0.98947\teval-auc:0.85259\n",
      "[114]\ttrain-auc:0.98947\teval-auc:0.85259\n",
      "[115]\ttrain-auc:0.98947\teval-auc:0.85259\n",
      "[116]\ttrain-auc:0.98951\teval-auc:0.85209\n",
      "[117]\ttrain-auc:0.98945\teval-auc:0.85227\n",
      "[118]\ttrain-auc:0.98957\teval-auc:0.85077\n",
      "[119]\ttrain-auc:0.98948\teval-auc:0.85168\n",
      "[120]\ttrain-auc:0.98948\teval-auc:0.85168\n",
      "[121]\ttrain-auc:0.98958\teval-auc:0.84973\n",
      "[122]\ttrain-auc:0.98958\teval-auc:0.84973\n",
      "[123]\ttrain-auc:0.98965\teval-auc:0.84946\n",
      "[124]\ttrain-auc:0.98965\teval-auc:0.84946\n",
      "[125]\ttrain-auc:0.98971\teval-auc:0.84927\n",
      "[126]\ttrain-auc:0.98971\teval-auc:0.84927\n",
      "[127]\ttrain-auc:0.98969\teval-auc:0.85027\n",
      "[128]\ttrain-auc:0.98982\teval-auc:0.84941\n",
      "[129]\ttrain-auc:0.98988\teval-auc:0.85000\n",
      "[130]\ttrain-auc:0.98994\teval-auc:0.84864\n",
      "[131]\ttrain-auc:0.98991\teval-auc:0.84932\n",
      "[132]\ttrain-auc:0.98991\teval-auc:0.84996\n",
      "[133]\ttrain-auc:0.98989\teval-auc:0.85014\n",
      "[134]\ttrain-auc:0.98982\teval-auc:0.85032\n",
      "[135]\ttrain-auc:0.98974\teval-auc:0.85073\n",
      "[136]\ttrain-auc:0.98981\teval-auc:0.85023\n",
      "[137]\ttrain-auc:0.98981\teval-auc:0.85023\n",
      "[138]\ttrain-auc:0.98985\teval-auc:0.85054\n",
      "[139]\ttrain-auc:0.98984\teval-auc:0.85218\n",
      "[140]\ttrain-auc:0.98985\teval-auc:0.85250\n",
      "[141]\ttrain-auc:0.99000\teval-auc:0.85218\n",
      "[142]\ttrain-auc:0.99008\teval-auc:0.85186\n",
      "[143]\ttrain-auc:0.99018\teval-auc:0.85172\n",
      "[144]\ttrain-auc:0.99022\teval-auc:0.85132\n",
      "[145]\ttrain-auc:0.99022\teval-auc:0.85132\n",
      "[146]\ttrain-auc:0.99028\teval-auc:0.85068\n",
      "[147]\ttrain-auc:0.99018\teval-auc:0.85127\n",
      "[148]\ttrain-auc:0.99019\teval-auc:0.85011\n",
      "[149]\ttrain-auc:0.99024\teval-auc:0.84980\n",
      "[150]\ttrain-auc:0.99024\teval-auc:0.84980\n",
      "[151]\ttrain-auc:0.99019\teval-auc:0.85052\n",
      "[152]\ttrain-auc:0.99015\teval-auc:0.85093\n",
      "[153]\ttrain-auc:0.99015\teval-auc:0.85093\n",
      "[154]\ttrain-auc:0.99015\teval-auc:0.85138\n",
      "[155]\ttrain-auc:0.99017\teval-auc:0.85098\n",
      "[156]\ttrain-auc:0.99017\teval-auc:0.85098\n",
      "[157]\ttrain-auc:0.99018\teval-auc:0.85084\n",
      "[158]\ttrain-auc:0.99027\teval-auc:0.85075\n",
      "[159]\ttrain-auc:0.99037\teval-auc:0.85002\n",
      "[160]\ttrain-auc:0.99032\teval-auc:0.85043\n",
      "[161]\ttrain-auc:0.99038\teval-auc:0.85048\n",
      "[162]\ttrain-auc:0.99053\teval-auc:0.84980\n",
      "[163]\ttrain-auc:0.99051\teval-auc:0.85025\n",
      "[164]\ttrain-auc:0.99057\teval-auc:0.85016\n",
      "[165]\ttrain-auc:0.99057\teval-auc:0.85016\n",
      "[166]\ttrain-auc:0.99059\teval-auc:0.84957\n",
      "[167]\ttrain-auc:0.99059\teval-auc:0.84957\n",
      "[168]\ttrain-auc:0.99052\teval-auc:0.84957\n",
      "[169]\ttrain-auc:0.99052\teval-auc:0.84957\n",
      "[170]\ttrain-auc:0.99061\teval-auc:0.84796\n",
      "[171]\ttrain-auc:0.99061\teval-auc:0.84796\n",
      "[172]\ttrain-auc:0.99065\teval-auc:0.84728\n",
      "[173]\ttrain-auc:0.99065\teval-auc:0.84728\n",
      "[174]\ttrain-auc:0.99062\teval-auc:0.84764\n",
      "[175]\ttrain-auc:0.99056\teval-auc:0.84741\n",
      "[176]\ttrain-auc:0.99056\teval-auc:0.84887\n",
      "[177]\ttrain-auc:0.99047\teval-auc:0.84996\n",
      "[178]\ttrain-auc:0.99046\teval-auc:0.84905\n",
      "[179]\ttrain-auc:0.99046\teval-auc:0.84905\n",
      "[180]\ttrain-auc:0.99057\teval-auc:0.84859\n",
      "[181]\ttrain-auc:0.99057\teval-auc:0.84859\n",
      "[182]\ttrain-auc:0.99057\teval-auc:0.84859\n",
      "[183]\ttrain-auc:0.99054\teval-auc:0.84891\n",
      "[184]\ttrain-auc:0.99054\teval-auc:0.84891\n",
      "[185]\ttrain-auc:0.99062\teval-auc:0.84877\n",
      "[186]\ttrain-auc:0.99048\teval-auc:0.84918\n",
      "[187]\ttrain-auc:0.99044\teval-auc:0.84927\n",
      "[188]\ttrain-auc:0.99052\teval-auc:0.84896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[189]\ttrain-auc:0.99054\teval-auc:0.84823\n",
      "[190]\ttrain-auc:0.99066\teval-auc:0.84778\n",
      "[191]\ttrain-auc:0.99069\teval-auc:0.84719\n",
      "[192]\ttrain-auc:0.99068\teval-auc:0.84723\n",
      "[193]\ttrain-auc:0.99072\teval-auc:0.84696\n",
      "[194]\ttrain-auc:0.99064\teval-auc:0.84728\n",
      "[195]\ttrain-auc:0.99064\teval-auc:0.84728\n",
      "[196]\ttrain-auc:0.99072\teval-auc:0.84696\n",
      "[197]\ttrain-auc:0.99086\teval-auc:0.84660\n",
      "[198]\ttrain-auc:0.99088\teval-auc:0.84673\n",
      "[199]\ttrain-auc:0.99093\teval-auc:0.84714\n",
      "[200]\ttrain-auc:0.99093\teval-auc:0.84714\n",
      "[201]\ttrain-auc:0.99093\teval-auc:0.84714\n",
      "[202]\ttrain-auc:0.99093\teval-auc:0.84787\n",
      "[203]\ttrain-auc:0.99093\teval-auc:0.84787\n",
      "[204]\ttrain-auc:0.99086\teval-auc:0.84873\n",
      "[205]\ttrain-auc:0.99086\teval-auc:0.84873\n",
      "[206]\ttrain-auc:0.99086\teval-auc:0.84873\n",
      "[207]\ttrain-auc:0.99087\teval-auc:0.84964\n",
      "[208]\ttrain-auc:0.99095\teval-auc:0.84937\n",
      "[209]\ttrain-auc:0.99095\teval-auc:0.84937\n",
      "[210]\ttrain-auc:0.99095\teval-auc:0.84937\n",
      "[211]\ttrain-auc:0.99105\teval-auc:0.84873\n",
      "[212]\ttrain-auc:0.99108\teval-auc:0.84846\n",
      "[213]\ttrain-auc:0.99109\teval-auc:0.84932\n",
      "[214]\ttrain-auc:0.99109\teval-auc:0.84932\n",
      "[215]\ttrain-auc:0.99116\teval-auc:0.84905\n",
      "[216]\ttrain-auc:0.99116\teval-auc:0.84905\n",
      "[217]\ttrain-auc:0.99117\teval-auc:0.84809\n",
      "[218]\ttrain-auc:0.99115\teval-auc:0.84857\n",
      "[219]\ttrain-auc:0.99121\teval-auc:0.84844\n",
      "[220]\ttrain-auc:0.99117\teval-auc:0.84877\n",
      "[221]\ttrain-auc:0.99112\teval-auc:0.84900\n",
      "[222]\ttrain-auc:0.99117\teval-auc:0.84900\n",
      "[223]\ttrain-auc:0.99117\teval-auc:0.84900\n",
      "[224]\ttrain-auc:0.99115\teval-auc:0.84896\n",
      "[225]\ttrain-auc:0.99121\teval-auc:0.84868\n",
      "[226]\ttrain-auc:0.99121\teval-auc:0.84868\n",
      "[227]\ttrain-auc:0.99121\teval-auc:0.84868\n",
      "[228]\ttrain-auc:0.99126\teval-auc:0.84737\n",
      "[229]\ttrain-auc:0.99124\teval-auc:0.84701\n",
      "[230]\ttrain-auc:0.99121\teval-auc:0.84728\n",
      "[231]\ttrain-auc:0.99126\teval-auc:0.84678\n",
      "[232]\ttrain-auc:0.99130\teval-auc:0.84642\n",
      "[233]\ttrain-auc:0.99130\teval-auc:0.84642\n",
      "[234]\ttrain-auc:0.99141\teval-auc:0.84651\n",
      "[235]\ttrain-auc:0.99146\teval-auc:0.84691\n",
      "[236]\ttrain-auc:0.99157\teval-auc:0.84759\n",
      "[237]\ttrain-auc:0.99153\teval-auc:0.84741\n",
      "[238]\ttrain-auc:0.99146\teval-auc:0.84778\n",
      "[239]\ttrain-auc:0.99139\teval-auc:0.84800\n",
      "[240]\ttrain-auc:0.99147\teval-auc:0.84664\n",
      "[241]\ttrain-auc:0.99140\teval-auc:0.84669\n",
      "[242]\ttrain-auc:0.99147\teval-auc:0.84691\n",
      "[243]\ttrain-auc:0.99136\teval-auc:0.84701\n",
      "[244]\ttrain-auc:0.99144\teval-auc:0.84728\n",
      "[245]\ttrain-auc:0.99162\teval-auc:0.84682\n",
      "[246]\ttrain-auc:0.99156\teval-auc:0.84764\n",
      "[247]\ttrain-auc:0.99161\teval-auc:0.84723\n",
      "[248]\ttrain-auc:0.99168\teval-auc:0.84719\n",
      "[249]\ttrain-auc:0.99168\teval-auc:0.84719\n",
      "[250]\ttrain-auc:0.99174\teval-auc:0.84651\n",
      "[251]\ttrain-auc:0.99173\teval-auc:0.84710\n",
      "[252]\ttrain-auc:0.99173\teval-auc:0.84710\n",
      "[253]\ttrain-auc:0.99169\teval-auc:0.84755\n",
      "[254]\ttrain-auc:0.99179\teval-auc:0.84741\n",
      "[255]\ttrain-auc:0.99186\teval-auc:0.84809\n",
      "[256]\ttrain-auc:0.99200\teval-auc:0.84805\n",
      "[257]\ttrain-auc:0.99193\teval-auc:0.84809\n",
      "[258]\ttrain-auc:0.99184\teval-auc:0.84796\n",
      "[259]\ttrain-auc:0.99194\teval-auc:0.84732\n",
      "[260]\ttrain-auc:0.99194\teval-auc:0.84732\n",
      "[261]\ttrain-auc:0.99194\teval-auc:0.84732\n",
      "[262]\ttrain-auc:0.99194\teval-auc:0.84732\n",
      "[263]\ttrain-auc:0.99197\teval-auc:0.84696\n",
      "[264]\ttrain-auc:0.99197\teval-auc:0.84696\n",
      "[265]\ttrain-auc:0.99197\teval-auc:0.84696\n",
      "[266]\ttrain-auc:0.99197\teval-auc:0.84696\n",
      "[267]\ttrain-auc:0.99189\teval-auc:0.84719\n",
      "[268]\ttrain-auc:0.99189\teval-auc:0.84719\n",
      "[269]\ttrain-auc:0.99188\teval-auc:0.84791\n",
      "[270]\ttrain-auc:0.99197\teval-auc:0.84737\n",
      "[271]\ttrain-auc:0.99200\teval-auc:0.84805\n",
      "[272]\ttrain-auc:0.99197\teval-auc:0.84891\n",
      "[273]\ttrain-auc:0.99197\teval-auc:0.84891\n",
      "[274]\ttrain-auc:0.99194\teval-auc:0.84927\n",
      "[275]\ttrain-auc:0.99194\teval-auc:0.84927\n",
      "[276]\ttrain-auc:0.99205\teval-auc:0.84882\n",
      "[277]\ttrain-auc:0.99201\teval-auc:0.84909\n",
      "[278]\ttrain-auc:0.99201\teval-auc:0.84909\n",
      "[279]\ttrain-auc:0.99201\teval-auc:0.84909\n",
      "[280]\ttrain-auc:0.99197\teval-auc:0.84918\n",
      "[281]\ttrain-auc:0.99197\teval-auc:0.84918\n",
      "[282]\ttrain-auc:0.99206\teval-auc:0.84839\n",
      "[283]\ttrain-auc:0.99218\teval-auc:0.84762\n",
      "[284]\ttrain-auc:0.99220\teval-auc:0.84834\n",
      "[285]\ttrain-auc:0.99220\teval-auc:0.84834\n",
      "[286]\ttrain-auc:0.99216\teval-auc:0.84880\n",
      "[287]\ttrain-auc:0.99216\teval-auc:0.84880\n",
      "[288]\ttrain-auc:0.99208\teval-auc:0.84966\n",
      "[289]\ttrain-auc:0.99208\teval-auc:0.84966\n",
      "[290]\ttrain-auc:0.99208\teval-auc:0.84966\n",
      "[291]\ttrain-auc:0.99208\teval-auc:0.84966\n",
      "[292]\ttrain-auc:0.99215\teval-auc:0.84934\n",
      "[293]\ttrain-auc:0.99213\teval-auc:0.84980\n",
      "[294]\ttrain-auc:0.99213\teval-auc:0.84980\n",
      "[295]\ttrain-auc:0.99210\teval-auc:0.84989\n",
      "[296]\ttrain-auc:0.99219\teval-auc:0.84984\n",
      "[297]\ttrain-auc:0.99210\teval-auc:0.85061\n",
      "[298]\ttrain-auc:0.99210\teval-auc:0.85061\n",
      "[299]\ttrain-auc:0.99221\teval-auc:0.85093\n",
      "[0]\ttrain-auc:0.94382\teval-auc:0.82522\n",
      "[1]\ttrain-auc:0.95768\teval-auc:0.83978\n",
      "[2]\ttrain-auc:0.96185\teval-auc:0.84799\n",
      "[3]\ttrain-auc:0.96312\teval-auc:0.84755\n",
      "[4]\ttrain-auc:0.96555\teval-auc:0.84812\n",
      "[5]\ttrain-auc:0.96594\teval-auc:0.84918\n",
      "[6]\ttrain-auc:0.96702\teval-auc:0.85018\n",
      "[7]\ttrain-auc:0.96792\teval-auc:0.84890\n",
      "[8]\ttrain-auc:0.96815\teval-auc:0.84897\n",
      "[9]\ttrain-auc:0.96865\teval-auc:0.84880\n",
      "[10]\ttrain-auc:0.96867\teval-auc:0.84859\n",
      "[11]\ttrain-auc:0.96938\teval-auc:0.85120\n",
      "[12]\ttrain-auc:0.97026\teval-auc:0.85257\n",
      "[13]\ttrain-auc:0.97076\teval-auc:0.85278\n",
      "[14]\ttrain-auc:0.97099\teval-auc:0.85288\n",
      "[15]\ttrain-auc:0.97122\teval-auc:0.85286\n",
      "[16]\ttrain-auc:0.97156\teval-auc:0.85262\n",
      "[17]\ttrain-auc:0.97191\teval-auc:0.85268\n",
      "[18]\ttrain-auc:0.97206\teval-auc:0.85236\n",
      "[19]\ttrain-auc:0.97249\teval-auc:0.85133\n",
      "[20]\ttrain-auc:0.97260\teval-auc:0.85271\n",
      "[21]\ttrain-auc:0.97273\teval-auc:0.85251\n",
      "[22]\ttrain-auc:0.97301\teval-auc:0.85248\n",
      "[23]\ttrain-auc:0.97309\teval-auc:0.85183\n",
      "[24]\ttrain-auc:0.97343\teval-auc:0.85224\n",
      "[25]\ttrain-auc:0.97383\teval-auc:0.85156\n",
      "[26]\ttrain-auc:0.97390\teval-auc:0.85092\n",
      "[27]\ttrain-auc:0.97426\teval-auc:0.84980\n",
      "[28]\ttrain-auc:0.97433\teval-auc:0.85071\n",
      "[29]\ttrain-auc:0.97465\teval-auc:0.85063\n",
      "[30]\ttrain-auc:0.97487\teval-auc:0.85137\n",
      "[31]\ttrain-auc:0.97498\teval-auc:0.85177\n",
      "[32]\ttrain-auc:0.97511\teval-auc:0.85280\n",
      "[33]\ttrain-auc:0.97541\teval-auc:0.85140\n",
      "[34]\ttrain-auc:0.97545\teval-auc:0.85178\n",
      "[35]\ttrain-auc:0.97578\teval-auc:0.85162\n",
      "[36]\ttrain-auc:0.97594\teval-auc:0.84997\n",
      "[37]\ttrain-auc:0.97616\teval-auc:0.85051\n",
      "[38]\ttrain-auc:0.97646\teval-auc:0.85054\n",
      "[39]\ttrain-auc:0.97643\teval-auc:0.85092\n",
      "[40]\ttrain-auc:0.97663\teval-auc:0.85096\n",
      "[41]\ttrain-auc:0.97682\teval-auc:0.85121\n",
      "[42]\ttrain-auc:0.97700\teval-auc:0.85063\n",
      "[43]\ttrain-auc:0.97734\teval-auc:0.85099\n",
      "[44]\ttrain-auc:0.97728\teval-auc:0.85123\n",
      "[45]\ttrain-auc:0.97742\teval-auc:0.85089\n",
      "[46]\ttrain-auc:0.97744\teval-auc:0.85071\n",
      "[47]\ttrain-auc:0.97766\teval-auc:0.85038\n",
      "[48]\ttrain-auc:0.97773\teval-auc:0.84981\n",
      "[49]\ttrain-auc:0.97791\teval-auc:0.85038\n",
      "[50]\ttrain-auc:0.97825\teval-auc:0.85118\n",
      "[51]\ttrain-auc:0.97838\teval-auc:0.85003\n",
      "[52]\ttrain-auc:0.97860\teval-auc:0.84969\n",
      "[53]\ttrain-auc:0.97885\teval-auc:0.84970\n",
      "[54]\ttrain-auc:0.97897\teval-auc:0.85001\n",
      "[55]\ttrain-auc:0.97909\teval-auc:0.85029\n",
      "[56]\ttrain-auc:0.97910\teval-auc:0.85056\n",
      "[57]\ttrain-auc:0.97936\teval-auc:0.85084\n",
      "[58]\ttrain-auc:0.97953\teval-auc:0.85087\n",
      "[59]\ttrain-auc:0.97941\teval-auc:0.85038\n",
      "[60]\ttrain-auc:0.97967\teval-auc:0.85034\n",
      "[61]\ttrain-auc:0.97987\teval-auc:0.85067\n",
      "[62]\ttrain-auc:0.97978\teval-auc:0.85108\n",
      "[63]\ttrain-auc:0.97994\teval-auc:0.85144\n",
      "[64]\ttrain-auc:0.97995\teval-auc:0.85015\n",
      "[65]\ttrain-auc:0.97990\teval-auc:0.85040\n",
      "[66]\ttrain-auc:0.98007\teval-auc:0.84969\n",
      "[67]\ttrain-auc:0.98025\teval-auc:0.85082\n",
      "[68]\ttrain-auc:0.98036\teval-auc:0.85014\n",
      "[69]\ttrain-auc:0.98033\teval-auc:0.85038\n",
      "[70]\ttrain-auc:0.98056\teval-auc:0.85046\n",
      "[71]\ttrain-auc:0.98068\teval-auc:0.85023\n",
      "[72]\ttrain-auc:0.98094\teval-auc:0.85028\n",
      "[73]\ttrain-auc:0.98110\teval-auc:0.85064\n",
      "[74]\ttrain-auc:0.98095\teval-auc:0.85054\n",
      "[75]\ttrain-auc:0.98118\teval-auc:0.85054\n",
      "[76]\ttrain-auc:0.98129\teval-auc:0.85086\n",
      "[77]\ttrain-auc:0.98129\teval-auc:0.85045\n",
      "[78]\ttrain-auc:0.98143\teval-auc:0.85068\n",
      "[79]\ttrain-auc:0.98136\teval-auc:0.85140\n",
      "[80]\ttrain-auc:0.98145\teval-auc:0.85071\n",
      "[81]\ttrain-auc:0.98175\teval-auc:0.85049\n",
      "[82]\ttrain-auc:0.98192\teval-auc:0.84949\n",
      "[83]\ttrain-auc:0.98193\teval-auc:0.84867\n",
      "[84]\ttrain-auc:0.98192\teval-auc:0.84823\n",
      "[85]\ttrain-auc:0.98204\teval-auc:0.84830\n",
      "[86]\ttrain-auc:0.98232\teval-auc:0.84894\n",
      "[87]\ttrain-auc:0.98242\teval-auc:0.84915\n",
      "[88]\ttrain-auc:0.98257\teval-auc:0.84938\n",
      "[89]\ttrain-auc:0.98273\teval-auc:0.84915\n",
      "[90]\ttrain-auc:0.98280\teval-auc:0.84805\n",
      "[91]\ttrain-auc:0.98288\teval-auc:0.84850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92]\ttrain-auc:0.98302\teval-auc:0.84847\n",
      "[93]\ttrain-auc:0.98298\teval-auc:0.84861\n",
      "[94]\ttrain-auc:0.98294\teval-auc:0.84778\n",
      "[95]\ttrain-auc:0.98317\teval-auc:0.84805\n",
      "[96]\ttrain-auc:0.98326\teval-auc:0.84772\n",
      "[97]\ttrain-auc:0.98338\teval-auc:0.84717\n",
      "[98]\ttrain-auc:0.98362\teval-auc:0.84648\n",
      "[99]\ttrain-auc:0.98377\teval-auc:0.84590\n",
      "[100]\ttrain-auc:0.98389\teval-auc:0.84576\n",
      "[101]\ttrain-auc:0.98403\teval-auc:0.84623\n",
      "[102]\ttrain-auc:0.98386\teval-auc:0.84608\n",
      "[103]\ttrain-auc:0.98391\teval-auc:0.84602\n",
      "[104]\ttrain-auc:0.98396\teval-auc:0.84593\n",
      "[105]\ttrain-auc:0.98396\teval-auc:0.84594\n",
      "[106]\ttrain-auc:0.98393\teval-auc:0.84736\n",
      "[107]\ttrain-auc:0.98393\teval-auc:0.84757\n",
      "[108]\ttrain-auc:0.98415\teval-auc:0.84762\n",
      "[109]\ttrain-auc:0.98433\teval-auc:0.84729\n",
      "[110]\ttrain-auc:0.98447\teval-auc:0.84830\n",
      "[111]\ttrain-auc:0.98455\teval-auc:0.84863\n",
      "[112]\ttrain-auc:0.98463\teval-auc:0.85049\n",
      "[113]\ttrain-auc:0.98476\teval-auc:0.84936\n",
      "[114]\ttrain-auc:0.98468\teval-auc:0.84944\n",
      "[115]\ttrain-auc:0.98460\teval-auc:0.84977\n",
      "[116]\ttrain-auc:0.98471\teval-auc:0.85031\n",
      "[117]\ttrain-auc:0.98492\teval-auc:0.84984\n",
      "[118]\ttrain-auc:0.98506\teval-auc:0.84831\n",
      "[119]\ttrain-auc:0.98526\teval-auc:0.84816\n",
      "[120]\ttrain-auc:0.98540\teval-auc:0.84814\n",
      "[121]\ttrain-auc:0.98553\teval-auc:0.84823\n",
      "[122]\ttrain-auc:0.98552\teval-auc:0.84838\n",
      "[123]\ttrain-auc:0.98566\teval-auc:0.84838\n",
      "[124]\ttrain-auc:0.98597\teval-auc:0.84878\n",
      "[125]\ttrain-auc:0.98598\teval-auc:0.84852\n",
      "[126]\ttrain-auc:0.98611\teval-auc:0.84812\n",
      "[127]\ttrain-auc:0.98616\teval-auc:0.84826\n",
      "[128]\ttrain-auc:0.98623\teval-auc:0.84799\n",
      "[129]\ttrain-auc:0.98616\teval-auc:0.84890\n",
      "[130]\ttrain-auc:0.98630\teval-auc:0.84730\n",
      "[131]\ttrain-auc:0.98633\teval-auc:0.84691\n",
      "[132]\ttrain-auc:0.98649\teval-auc:0.84771\n",
      "[133]\ttrain-auc:0.98664\teval-auc:0.84718\n",
      "[134]\ttrain-auc:0.98663\teval-auc:0.84659\n",
      "[135]\ttrain-auc:0.98672\teval-auc:0.84622\n",
      "[136]\ttrain-auc:0.98684\teval-auc:0.84661\n",
      "[137]\ttrain-auc:0.98690\teval-auc:0.84675\n",
      "[138]\ttrain-auc:0.98692\teval-auc:0.84685\n",
      "[139]\ttrain-auc:0.98694\teval-auc:0.84675\n",
      "[140]\ttrain-auc:0.98713\teval-auc:0.84710\n",
      "[141]\ttrain-auc:0.98718\teval-auc:0.84615\n",
      "[142]\ttrain-auc:0.98729\teval-auc:0.84620\n",
      "[143]\ttrain-auc:0.98735\teval-auc:0.84564\n",
      "[144]\ttrain-auc:0.98731\teval-auc:0.84579\n",
      "[145]\ttrain-auc:0.98745\teval-auc:0.84581\n",
      "[146]\ttrain-auc:0.98719\teval-auc:0.84639\n",
      "[147]\ttrain-auc:0.98730\teval-auc:0.84568\n",
      "[148]\ttrain-auc:0.98711\teval-auc:0.84589\n",
      "[149]\ttrain-auc:0.98746\teval-auc:0.84630\n",
      "[150]\ttrain-auc:0.98757\teval-auc:0.84697\n",
      "[151]\ttrain-auc:0.98753\teval-auc:0.84685\n",
      "[152]\ttrain-auc:0.98754\teval-auc:0.84605\n",
      "[153]\ttrain-auc:0.98772\teval-auc:0.84677\n",
      "[154]\ttrain-auc:0.98769\teval-auc:0.84718\n",
      "[155]\ttrain-auc:0.98775\teval-auc:0.84774\n",
      "[156]\ttrain-auc:0.98771\teval-auc:0.84733\n",
      "[157]\ttrain-auc:0.98782\teval-auc:0.84787\n",
      "[158]\ttrain-auc:0.98798\teval-auc:0.84816\n",
      "[159]\ttrain-auc:0.98804\teval-auc:0.84750\n",
      "[160]\ttrain-auc:0.98818\teval-auc:0.84782\n",
      "[161]\ttrain-auc:0.98821\teval-auc:0.84680\n",
      "[162]\ttrain-auc:0.98814\teval-auc:0.84641\n",
      "[163]\ttrain-auc:0.98811\teval-auc:0.84557\n",
      "[164]\ttrain-auc:0.98823\teval-auc:0.84603\n",
      "[165]\ttrain-auc:0.98841\teval-auc:0.84589\n",
      "[166]\ttrain-auc:0.98843\teval-auc:0.84603\n",
      "[167]\ttrain-auc:0.98852\teval-auc:0.84794\n",
      "[168]\ttrain-auc:0.98852\teval-auc:0.84752\n",
      "[169]\ttrain-auc:0.98853\teval-auc:0.84625\n",
      "[170]\ttrain-auc:0.98857\teval-auc:0.84491\n",
      "[171]\ttrain-auc:0.98862\teval-auc:0.84487\n",
      "[172]\ttrain-auc:0.98854\teval-auc:0.84477\n",
      "[173]\ttrain-auc:0.98857\teval-auc:0.84385\n",
      "[174]\ttrain-auc:0.98876\teval-auc:0.84391\n",
      "[175]\ttrain-auc:0.98884\teval-auc:0.84410\n",
      "[176]\ttrain-auc:0.98900\teval-auc:0.84383\n",
      "[177]\ttrain-auc:0.98906\teval-auc:0.84328\n",
      "[178]\ttrain-auc:0.98912\teval-auc:0.84306\n",
      "[179]\ttrain-auc:0.98924\teval-auc:0.84374\n",
      "[180]\ttrain-auc:0.98923\teval-auc:0.84352\n",
      "[181]\ttrain-auc:0.98898\teval-auc:0.84286\n",
      "[182]\ttrain-auc:0.98911\teval-auc:0.84283\n",
      "[183]\ttrain-auc:0.98921\teval-auc:0.84212\n",
      "[184]\ttrain-auc:0.98915\teval-auc:0.84120\n",
      "[185]\ttrain-auc:0.98936\teval-auc:0.84093\n",
      "[186]\ttrain-auc:0.98932\teval-auc:0.84203\n",
      "[187]\ttrain-auc:0.98955\teval-auc:0.84077\n",
      "[188]\ttrain-auc:0.98972\teval-auc:0.84186\n",
      "[189]\ttrain-auc:0.98962\teval-auc:0.84242\n",
      "[190]\ttrain-auc:0.98954\teval-auc:0.84310\n",
      "[191]\ttrain-auc:0.98956\teval-auc:0.84276\n",
      "[192]\ttrain-auc:0.98960\teval-auc:0.84124\n",
      "[193]\ttrain-auc:0.98960\teval-auc:0.84151\n",
      "[194]\ttrain-auc:0.98965\teval-auc:0.84138\n",
      "[195]\ttrain-auc:0.98977\teval-auc:0.84167\n",
      "[196]\ttrain-auc:0.98963\teval-auc:0.84173\n",
      "[197]\ttrain-auc:0.98968\teval-auc:0.84140\n",
      "[198]\ttrain-auc:0.98963\teval-auc:0.84099\n",
      "[199]\ttrain-auc:0.98960\teval-auc:0.84029\n",
      "[200]\ttrain-auc:0.98969\teval-auc:0.83978\n",
      "[201]\ttrain-auc:0.98970\teval-auc:0.84058\n",
      "[202]\ttrain-auc:0.98979\teval-auc:0.84046\n",
      "[203]\ttrain-auc:0.98995\teval-auc:0.84082\n",
      "[204]\ttrain-auc:0.98983\teval-auc:0.84162\n",
      "[205]\ttrain-auc:0.98986\teval-auc:0.84134\n",
      "[206]\ttrain-auc:0.99001\teval-auc:0.84278\n",
      "[207]\ttrain-auc:0.99001\teval-auc:0.84284\n",
      "[208]\ttrain-auc:0.99018\teval-auc:0.84262\n",
      "[209]\ttrain-auc:0.99031\teval-auc:0.84261\n",
      "[210]\ttrain-auc:0.99032\teval-auc:0.84203\n",
      "[211]\ttrain-auc:0.99033\teval-auc:0.84255\n",
      "[212]\ttrain-auc:0.99046\teval-auc:0.84239\n",
      "[213]\ttrain-auc:0.99033\teval-auc:0.84305\n",
      "[214]\ttrain-auc:0.99042\teval-auc:0.84269\n",
      "[215]\ttrain-auc:0.99048\teval-auc:0.84251\n",
      "[216]\ttrain-auc:0.99059\teval-auc:0.84218\n",
      "[217]\ttrain-auc:0.99075\teval-auc:0.84228\n",
      "[218]\ttrain-auc:0.99074\teval-auc:0.84217\n",
      "[219]\ttrain-auc:0.99056\teval-auc:0.84220\n",
      "[220]\ttrain-auc:0.99063\teval-auc:0.84167\n",
      "[221]\ttrain-auc:0.99067\teval-auc:0.84110\n",
      "[222]\ttrain-auc:0.99061\teval-auc:0.84093\n",
      "[223]\ttrain-auc:0.99064\teval-auc:0.84148\n",
      "[224]\ttrain-auc:0.99077\teval-auc:0.84156\n",
      "[225]\ttrain-auc:0.99086\teval-auc:0.84123\n",
      "[226]\ttrain-auc:0.99069\teval-auc:0.84140\n",
      "[227]\ttrain-auc:0.99084\teval-auc:0.84162\n",
      "[228]\ttrain-auc:0.99080\teval-auc:0.84214\n",
      "[229]\ttrain-auc:0.99077\teval-auc:0.84215\n",
      "[230]\ttrain-auc:0.99066\teval-auc:0.84245\n",
      "[231]\ttrain-auc:0.99082\teval-auc:0.84239\n",
      "[232]\ttrain-auc:0.99105\teval-auc:0.84242\n",
      "[233]\ttrain-auc:0.99106\teval-auc:0.84220\n",
      "[234]\ttrain-auc:0.99115\teval-auc:0.84220\n",
      "[235]\ttrain-auc:0.99130\teval-auc:0.84171\n",
      "[236]\ttrain-auc:0.99140\teval-auc:0.84217\n",
      "[237]\ttrain-auc:0.99138\teval-auc:0.84253\n",
      "[238]\ttrain-auc:0.99142\teval-auc:0.84218\n",
      "[239]\ttrain-auc:0.99148\teval-auc:0.84181\n",
      "[240]\ttrain-auc:0.99138\teval-auc:0.84195\n",
      "[241]\ttrain-auc:0.99133\teval-auc:0.84229\n",
      "[242]\ttrain-auc:0.99134\teval-auc:0.84192\n",
      "[243]\ttrain-auc:0.99146\teval-auc:0.84239\n",
      "[244]\ttrain-auc:0.99142\teval-auc:0.84261\n",
      "[245]\ttrain-auc:0.99149\teval-auc:0.84209\n",
      "[246]\ttrain-auc:0.99154\teval-auc:0.84233\n",
      "[247]\ttrain-auc:0.99149\teval-auc:0.84247\n",
      "[248]\ttrain-auc:0.99151\teval-auc:0.84176\n",
      "[249]\ttrain-auc:0.99147\teval-auc:0.84192\n",
      "[250]\ttrain-auc:0.99157\teval-auc:0.84170\n",
      "[251]\ttrain-auc:0.99179\teval-auc:0.84121\n",
      "[252]\ttrain-auc:0.99165\teval-auc:0.84135\n",
      "[253]\ttrain-auc:0.99166\teval-auc:0.84049\n",
      "[254]\ttrain-auc:0.99167\teval-auc:0.84054\n",
      "[255]\ttrain-auc:0.99178\teval-auc:0.84046\n",
      "[256]\ttrain-auc:0.99173\teval-auc:0.84025\n",
      "[257]\ttrain-auc:0.99169\teval-auc:0.83950\n",
      "[258]\ttrain-auc:0.99190\teval-auc:0.84036\n",
      "[259]\ttrain-auc:0.99208\teval-auc:0.83972\n",
      "[260]\ttrain-auc:0.99211\teval-auc:0.84021\n",
      "[261]\ttrain-auc:0.99206\teval-auc:0.84016\n",
      "[262]\ttrain-auc:0.99199\teval-auc:0.83966\n",
      "[263]\ttrain-auc:0.99208\teval-auc:0.83955\n",
      "[264]\ttrain-auc:0.99215\teval-auc:0.83964\n",
      "[265]\ttrain-auc:0.99216\teval-auc:0.83983\n",
      "[266]\ttrain-auc:0.99228\teval-auc:0.83989\n",
      "[267]\ttrain-auc:0.99250\teval-auc:0.84035\n",
      "[268]\ttrain-auc:0.99253\teval-auc:0.84060\n",
      "[269]\ttrain-auc:0.99260\teval-auc:0.84058\n",
      "[270]\ttrain-auc:0.99249\teval-auc:0.84123\n",
      "[271]\ttrain-auc:0.99262\teval-auc:0.84068\n",
      "[272]\ttrain-auc:0.99256\teval-auc:0.84032\n",
      "[273]\ttrain-auc:0.99263\teval-auc:0.83981\n",
      "[274]\ttrain-auc:0.99257\teval-auc:0.83923\n",
      "[275]\ttrain-auc:0.99264\teval-auc:0.83956\n",
      "[276]\ttrain-auc:0.99270\teval-auc:0.84014\n",
      "[277]\ttrain-auc:0.99258\teval-auc:0.84068\n",
      "[278]\ttrain-auc:0.99261\teval-auc:0.84044\n",
      "[279]\ttrain-auc:0.99239\teval-auc:0.84062\n",
      "[280]\ttrain-auc:0.99241\teval-auc:0.84030\n",
      "[281]\ttrain-auc:0.99249\teval-auc:0.84033\n",
      "[282]\ttrain-auc:0.99253\teval-auc:0.84046\n",
      "[283]\ttrain-auc:0.99267\teval-auc:0.84008\n",
      "[284]\ttrain-auc:0.99266\teval-auc:0.83977\n",
      "[285]\ttrain-auc:0.99270\teval-auc:0.83977\n",
      "[286]\ttrain-auc:0.99269\teval-auc:0.84047\n",
      "[287]\ttrain-auc:0.99276\teval-auc:0.84022\n",
      "[288]\ttrain-auc:0.99281\teval-auc:0.84025\n",
      "[289]\ttrain-auc:0.99283\teval-auc:0.83966\n",
      "[290]\ttrain-auc:0.99275\teval-auc:0.83983\n",
      "[291]\ttrain-auc:0.99281\teval-auc:0.83903\n",
      "[292]\ttrain-auc:0.99281\teval-auc:0.83862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[293]\ttrain-auc:0.99297\teval-auc:0.83825\n",
      "[294]\ttrain-auc:0.99301\teval-auc:0.83835\n",
      "[295]\ttrain-auc:0.99288\teval-auc:0.83870\n",
      "[296]\ttrain-auc:0.99291\teval-auc:0.83782\n",
      "[297]\ttrain-auc:0.99282\teval-auc:0.83771\n",
      "[298]\ttrain-auc:0.99293\teval-auc:0.83760\n",
      "[299]\ttrain-auc:0.99287\teval-auc:0.83793\n"
     ]
    }
   ],
   "source": [
    "train_p1 = {}\n",
    "train_p2 = {}\n",
    "train_p3 = {}\n",
    "val_p1 = {}\n",
    "val_p2 = {}\n",
    "val_p3 = {}\n",
    "es2 = EarlyStopping(monitor='loss',patience=15, min_delta=0)\n",
    "rlr2 = ReduceLROnPlateau(monitor='loss',factor=0.5, patience=2, verbose=1, min_lr=0.000000001)\n",
    "for i in range(len(training_p38)):\n",
    "    \n",
    "        #First Target\n",
    "        X_atoms_cold_p38,X_bonds_cold_p38,X_edges_cold_p38 = dataframe_to_gcn_input(validation_p38[i])\n",
    "        Y_cold_p38 = validation_p38[i].Binary\n",
    "        Y_dummy_cold_p38 = np.empty((X_atoms_cold_p38.shape[0],int(model_params['dense_size'][2]/3)+1))\n",
    "        X_atoms_train_p38, X_bonds_train_p38, X_edges_train_p38 = dataframe_to_gcn_input(training_p38[i])\n",
    "        Y_p38 = training_p38[i].Binary\n",
    "        Y_dummy_train_p38 = np.empty((X_atoms_train_p38.shape[0],int(model_params['dense_size'][2]/3)+1))\n",
    "        smiles_list_p38 = list(training_p38[i]['rdkit'])\n",
    "        \n",
    "        #Second Target\n",
    "        X_atoms_cold_akt1, X_bonds_cold_akt1, X_edges_cold_akt1 = dataframe_to_gcn_input(validation_akt1[i])\n",
    "        Y_cold_akt1 = validation_akt1[i].Binary\n",
    "        Y_dummy_cold_akt1 = np.empty((X_atoms_cold_akt1.shape[0],int(model_params['dense_size'][2]/3)+1))\n",
    "        X_atoms_train_akt1, X_bonds_train_akt1, X_edges_train_akt1 = dataframe_to_gcn_input(training_akt1[i])\n",
    "        Y_akt1 = training_akt1[i].Binary\n",
    "        Y_dummy_train_akt1 = np.empty((X_atoms_train_akt1.shape[0],int(model_params['dense_size'][2]/3)+1))\n",
    "        smiles_list_akt1 = list(training_akt1[i]['rdkit'])\n",
    "        \n",
    "        #Third Target\n",
    "        X_atoms_cold_pi3k,X_bonds_cold_pi3k,X_edges_cold_pi3k = dataframe_to_gcn_input(validation_pi3k[i])\n",
    "        Y_cold_pi3k = validation_pi3k[i].Binary\n",
    "        Y_dummy_cold_pi3k = np.empty((X_atoms_cold_pi3k.shape[0],int(model_params['dense_size'][2]/3)+1))\n",
    "        X_atoms_train_pi3k, X_bonds_train_pi3k, X_edges_train_pi3k = dataframe_to_gcn_input(training_pi3k[i])\n",
    "        Y_pi3k = training_pi3k[i].Binary\n",
    "        Y_dummy_train_pi3k = np.empty((X_atoms_train_pi3k.shape[0],int(model_params['dense_size'][2]/3)+1))\n",
    "        smiles_list_pi3k = list(training_pi3k[i]['rdkit'])\n",
    "        \n",
    "        gcn_encoder = build_encoder(model_params)\n",
    "        gcn_model = build_model(model_params,gcn_encoder)\n",
    "        gcn_mining = build_mining(model_params,gcn_model)\n",
    "        train_GEN = csv_generator_mining(model_params['batch_size'],training_p38[i],training_akt1[i],training_pi3k[i],\n",
    "                                  Y_dummy_train_p38,Y_dummy_train_akt1,Y_dummy_train_pi3k,\n",
    "                                  smiles_list_p38,smiles_list_akt1,smiles_list_pi3k,\n",
    "                                  Y_p38,Y_akt1,Y_pi3k,\n",
    "                                  X_atoms_train_p38, X_bonds_train_p38, X_edges_train_p38,\n",
    "                                  X_atoms_train_akt1, X_bonds_train_akt1, X_edges_train_akt1,\n",
    "                                  X_atoms_train_pi3k, X_bonds_train_pi3k, X_edges_train_pi3k)\n",
    "        NUM_TRAIN = np.sum([len(training_p38[i]),len(training_akt1[i]),len(training_pi3k[i])])\n",
    "        gcn_mining.fit_generator(train_GEN,\n",
    "                      steps_per_epoch = ceil(2*NUM_TRAIN/model_params['batch_size']),\n",
    "                      epochs = model_params['n_epochs'],\n",
    "                      shuffle = True,\n",
    "                      validation_data = None,\n",
    "                      callbacks = [es2,rlr2])\n",
    "        emb_train_1,t1,t2 = gcn_model.predict([X_atoms_train_p38,X_bonds_train_p38,X_edges_train_p38,\n",
    "                                        X_atoms_train_p38,X_bonds_train_p38,X_edges_train_p38,\n",
    "                                        X_atoms_train_p38,X_bonds_train_p38,X_edges_train_p38])\n",
    "        t1,emb_train_2,t2 = gcn_model.predict([X_atoms_train_akt1,X_bonds_train_akt1,X_edges_train_akt1,\n",
    "                                        X_atoms_train_akt1,X_bonds_train_akt1,X_edges_train_akt1,\n",
    "                                        X_atoms_train_akt1,X_bonds_train_akt1,X_edges_train_akt1])\n",
    "        t1,t2,emb_train_3 = gcn_model.predict([X_atoms_train_pi3k,X_bonds_train_pi3k,X_edges_train_pi3k,\n",
    "                                        X_atoms_train_pi3k,X_bonds_train_pi3k,X_edges_train_pi3k,\n",
    "                                        X_atoms_train_pi3k,X_bonds_train_pi3k,X_edges_train_pi3k])\n",
    "\n",
    "\n",
    "        emb_val_1,t1,t2 = gcn_model.predict([X_atoms_cold_p38,X_bonds_cold_p38,X_edges_cold_p38,\n",
    "                                            X_atoms_cold_p38,X_bonds_cold_p38,X_edges_cold_p38,\n",
    "                                            X_atoms_cold_p38,X_bonds_cold_p38,X_edges_cold_p38])\n",
    "        t1,emb_val_2,t2 = gcn_model.predict([X_atoms_cold_akt1,X_bonds_cold_akt1,X_edges_cold_akt1,\n",
    "                                            X_atoms_cold_akt1,X_bonds_cold_akt1,X_edges_cold_akt1,\n",
    "                                            X_atoms_cold_akt1,X_bonds_cold_akt1,X_edges_cold_akt1])\n",
    "        t1,t2,emb_val_3 = gcn_model.predict([X_atoms_cold_pi3k,X_bonds_cold_pi3k,X_edges_cold_pi3k,\n",
    "                                            X_atoms_cold_pi3k,X_bonds_cold_pi3k,X_edges_cold_pi3k,\n",
    "                                            X_atoms_cold_pi3k,X_bonds_cold_pi3k,X_edges_cold_pi3k])\n",
    "        \n",
    "        del t1,t2, gcn_mining,gcn_encoder,gcn_model,X_atoms_cold_p38,X_bonds_cold_p38,X_edges_cold_p38\n",
    "        del X_atoms_train_p38, X_bonds_train_p38, X_edges_train_p38,X_atoms_cold_pi3k,X_bonds_cold_pi3k,X_edges_cold_pi3k\n",
    "        del X_atoms_train_pi3k, X_bonds_train_pi3k, X_edges_train_pi3k,X_atoms_cold_akt1, X_bonds_cold_akt1, X_edges_cold_akt1\n",
    "        del X_atoms_train_akt1, X_bonds_train_akt1, X_edges_train_akt1,train_GEN\n",
    "        \n",
    "        #First\n",
    "        dmatrix_train_1 = xgb.DMatrix(data = emb_train_1,label = Y_p38)\n",
    "        dmatrix_cold_1  = xgb.DMatrix(data = emb_val_1,label = Y_cold_p38)\n",
    "        evalist_1 = [(dmatrix_train_1,'train'),(dmatrix_cold_1,'eval')]\n",
    "        xgb_model_1 = xgb.train(xgb_hyper,dmatrix_train_1,300,evalist_1,verbose_eval=True)\n",
    "        xgb_pred_cold_1 = xgb_model_1.predict(dmatrix_cold_1)\n",
    "        xgb_pred_train_1 = xgb_model_1.predict(dmatrix_train_1)\n",
    "        \n",
    "        #Second\n",
    "        dmatrix_train_2 = xgb.DMatrix(data = emb_train_2,label = Y_akt1)\n",
    "        dmatrix_cold_2  = xgb.DMatrix(data = emb_val_2,label = Y_cold_akt1)\n",
    "        evalist_2 = [(dmatrix_train_2,'train'),(dmatrix_cold_2,'eval')]\n",
    "        xgb_model_2 = xgb.train(xgb_hyper,dmatrix_train_2,300,evalist_2,verbose_eval=True)\n",
    "        xgb_pred_cold_2 = xgb_model_2.predict(dmatrix_cold_2)\n",
    "        xgb_pred_train_2 = xgb_model_2.predict(dmatrix_train_2)\n",
    "        \n",
    "        #Third\n",
    "        dmatrix_train_3 = xgb.DMatrix(data = emb_train_3,label = Y_pi3k)\n",
    "        dmatrix_cold_3  = xgb.DMatrix(data = emb_val_3,label = Y_cold_pi3k)\n",
    "        evalist_3 = [(dmatrix_train_3,'train'),(dmatrix_cold_3,'eval')]\n",
    "        xgb_model_3 = xgb.train(xgb_hyper,dmatrix_train_3,300,evalist_3,verbose_eval=True)\n",
    "        xgb_pred_cold_3 = xgb_model_3.predict(dmatrix_cold_3)\n",
    "        xgb_pred_train_3 = xgb_model_3.predict(dmatrix_train_3)\n",
    "        \n",
    "        val_p1['Test'] = calculate_metrics(np.array(Y_cold_p38),xgb_pred_cold_1)\n",
    "        val_p2['Test'] = calculate_metrics(np.array(Y_cold_akt1),xgb_pred_cold_2)\n",
    "        val_p3['Test'] = calculate_metrics(np.array(Y_cold_pi3k),xgb_pred_cold_3)\n",
    "            \n",
    "        train_p1['Test'] = calculate_metrics(np.array(Y_p38),xgb_pred_train_1)\n",
    "        train_p2['Test'] = calculate_metrics(np.array(Y_akt1),xgb_pred_train_2)\n",
    "        train_p3['Test'] = calculate_metrics(np.array(Y_pi3k),xgb_pred_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>map</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.516699</td>\n",
       "      <td>104.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.432593</td>\n",
       "      <td>0.410788</td>\n",
       "      <td>0.487685</td>\n",
       "      <td>0.529541</td>\n",
       "      <td>164.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy     fn     fp       map  precision    recall   roc_auc     tn  \\\n",
       "Test  0.516699  104.0  142.0  0.432593   0.410788  0.487685  0.529541  164.0   \n",
       "\n",
       "        tp  \n",
       "Test  99.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(val_p1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>map</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.928852</td>\n",
       "      <td>96.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.976226</td>\n",
       "      <td>0.919814</td>\n",
       "      <td>0.93531</td>\n",
       "      <td>0.977487</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>1388.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy    fn     fp       map  precision   recall   roc_auc      tn  \\\n",
       "Test  0.928852  96.0  121.0  0.976226   0.919814  0.93531  0.977487  1445.0   \n",
       "\n",
       "          tp  \n",
       "Test  1388.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_p1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>map</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.748366</td>\n",
       "      <td>22.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.736848</td>\n",
       "      <td>0.630872</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.85093</td>\n",
       "      <td>135.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy    fn    fp       map  precision    recall  roc_auc     tn  \\\n",
       "Test  0.748366  22.0  55.0  0.736848   0.630872  0.810345  0.85093  135.0   \n",
       "\n",
       "        tp  \n",
       "Test  94.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(val_p2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>map</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.963468</td>\n",
       "      <td>36.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.989962</td>\n",
       "      <td>0.959264</td>\n",
       "      <td>0.953003</td>\n",
       "      <td>0.992212</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy    fn    fp       map  precision    recall   roc_auc      tn  \\\n",
       "Test  0.963468  36.0  31.0  0.989962   0.959264  0.953003  0.992212  1037.0   \n",
       "\n",
       "         tp  \n",
       "Test  730.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_p2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>map</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.789572</td>\n",
       "      <td>57.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.640471</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.837932</td>\n",
       "      <td>304.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy    fn    fp       map  precision    recall   roc_auc     tn  \\\n",
       "Test  0.789572  57.0  56.0  0.640471   0.681818  0.677966  0.837932  304.0   \n",
       "\n",
       "         tp  \n",
       "Test  120.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(val_p3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>map</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.961144</td>\n",
       "      <td>64.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.986997</td>\n",
       "      <td>0.94861</td>\n",
       "      <td>0.946218</td>\n",
       "      <td>0.992875</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>1126.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy    fn    fp       map  precision    recall   roc_auc      tn  \\\n",
       "Test  0.961144  64.0  61.0  0.986997    0.94861  0.946218  0.992875  1966.0   \n",
       "\n",
       "          tp  \n",
       "Test  1126.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_p3).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
