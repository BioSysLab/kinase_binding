{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.callbacks import History, ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "from data_analysis import calculate_metrics, load_weights_and_evaluate\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, roc_auc_score, auc, average_precision_score\n",
    "#import scikitplot as skplt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from NGF.preprocessing import tensorise_smiles\n",
    "from custom_layers.model_creator import encode_smiles, stage_creator\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, concatenate,Flatten\n",
    "from keras.models import Model, load_model\n",
    "import dill\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "import xgboost as xgb\n",
    "from math import ceil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance(feature, squared):\n",
    "    \"\"\"Computes the pairwise distance matrix with numerical stability.\n",
    "\n",
    "    output[i, j] = || feature[i, :] - feature[j, :] ||_2\n",
    "\n",
    "    Args:\n",
    "      feature: 2-D Tensor of size [number of data, feature dimension].\n",
    "      squared: Boolean, whether or not to square the pairwise distances.\n",
    "\n",
    "    Returns:\n",
    "      pairwise_distances: 2-D Tensor of size [number of data, number of data].\n",
    "    \"\"\"\n",
    "    pairwise_distances_squared = math_ops.add(\n",
    "        math_ops.reduce_sum(math_ops.square(feature), axis=[1], keepdims=True),\n",
    "        math_ops.reduce_sum(\n",
    "            math_ops.square(array_ops.transpose(feature)),\n",
    "            axis=[0],\n",
    "            keepdims=True)) - 2.0 * math_ops.matmul(feature,\n",
    "                                                    array_ops.transpose(feature))\n",
    "\n",
    "    # Deal with numerical inaccuracies. Set small negatives to zero.\n",
    "    pairwise_distances_squared = math_ops.maximum(pairwise_distances_squared, 0.0)\n",
    "    # Get the mask where the zero distances are at.\n",
    "    error_mask = math_ops.less_equal(pairwise_distances_squared, 0.0)\n",
    "\n",
    "    # Optionally take the sqrt.\n",
    "    if squared:\n",
    "        pairwise_distances = pairwise_distances_squared\n",
    "    else:\n",
    "        pairwise_distances = math_ops.sqrt(\n",
    "            pairwise_distances_squared + math_ops.to_float(error_mask) * 1e-16)\n",
    "\n",
    "    # Undo conditionally adding 1e-16.\n",
    "    pairwise_distances = math_ops.multiply(\n",
    "        pairwise_distances, math_ops.to_float(math_ops.logical_not(error_mask)))\n",
    "\n",
    "    num_data = array_ops.shape(feature)[0]\n",
    "    # Explicitly set diagonals to zero.\n",
    "    mask_offdiagonals = array_ops.ones_like(pairwise_distances) - array_ops.diag(\n",
    "        array_ops.ones([num_data]))\n",
    "    pairwise_distances = math_ops.multiply(pairwise_distances, mask_offdiagonals)\n",
    "    return pairwise_distances\n",
    "\n",
    "def masked_maximum(data, mask, dim=1):\n",
    "    \"\"\"Computes the axis wise maximum over chosen elements.\n",
    "\n",
    "    Args:\n",
    "      data: 2-D float `Tensor` of size [n, m].\n",
    "      mask: 2-D Boolean `Tensor` of size [n, m].\n",
    "      dim: The dimension over which to compute the maximum.\n",
    "\n",
    "    Returns:\n",
    "      masked_maximums: N-D `Tensor`.\n",
    "        The maximized dimension is of size 1 after the operation.\n",
    "    \"\"\"\n",
    "    axis_minimums = math_ops.reduce_min(data, dim, keepdims=True)\n",
    "    masked_maximums = math_ops.reduce_max(\n",
    "        math_ops.multiply(data - axis_minimums, mask), dim,\n",
    "        keepdims=True) + axis_minimums\n",
    "    return masked_maximums\n",
    "\n",
    "def masked_minimum(data, mask, dim=1):\n",
    "    \"\"\"Computes the axis wise minimum over chosen elements.\n",
    "\n",
    "    Args:\n",
    "      data: 2-D float `Tensor` of size [n, m].\n",
    "      mask: 2-D Boolean `Tensor` of size [n, m].\n",
    "      dim: The dimension over which to compute the minimum.\n",
    "\n",
    "    Returns:\n",
    "      masked_minimums: N-D `Tensor`.\n",
    "        The minimized dimension is of size 1 after the operation.\n",
    "    \"\"\"\n",
    "    axis_maximums = math_ops.reduce_max(data, dim, keepdims=True)\n",
    "    masked_minimums = math_ops.reduce_min(\n",
    "        math_ops.multiply(data - axis_maximums, mask), dim,\n",
    "        keepdims=True) + axis_maximums\n",
    "    return masked_minimums\n",
    "def triplet_loss_adapted_from_tf(y_true, y_pred):\n",
    "    del y_true\n",
    "    margin = 0.5\n",
    "    labels = y_pred[:, :1]\n",
    "    labels = tf.cast(labels, dtype='int32')\n",
    "    embeddings = y_pred[:, 1:]\n",
    "    \n",
    "    ### Code from Tensorflow function [tf.contrib.losses.metric_learning.triplet_semihard_loss] starts here:\n",
    "    \n",
    "    # Reshape [batch_size] label tensor to a [batch_size, 1] label tensor.\n",
    "    # lshape=array_ops.shape(labels)\n",
    "    # assert lshape.shape == 1\n",
    "    # labels = array_ops.reshape(labels, [lshape[0], 1])\n",
    "\n",
    "    # Build pairwise squared distance matrix.\n",
    "    pdist_matrix = pairwise_distance(embeddings, squared=False)\n",
    "    # Build pairwise binary adjacency matrix.\n",
    "    adjacency = math_ops.equal(labels, array_ops.transpose(labels))\n",
    "    # Invert so we can select negatives only.\n",
    "    adjacency_not = math_ops.logical_not(adjacency)\n",
    "\n",
    "    # global batch_size  \n",
    "    batch_size = array_ops.size(labels) # was 'array_ops.size(labels)'\n",
    "\n",
    "    # Compute the mask.\n",
    "    pdist_matrix_tile = array_ops.tile(pdist_matrix, [batch_size, 1])\n",
    "    mask = math_ops.logical_and(\n",
    "        array_ops.tile(adjacency_not, [batch_size, 1]),\n",
    "        math_ops.greater(\n",
    "            pdist_matrix_tile, array_ops.reshape(\n",
    "                array_ops.transpose(pdist_matrix), [-1, 1])))\n",
    "    mask_final = array_ops.reshape(\n",
    "        math_ops.greater(\n",
    "            math_ops.reduce_sum(\n",
    "                math_ops.cast(mask, dtype=dtypes.float32), 1, keepdims=True),\n",
    "            0.0), [batch_size, batch_size])\n",
    "    mask_final = array_ops.transpose(mask_final)\n",
    "\n",
    "    adjacency_not = math_ops.cast(adjacency_not, dtype=dtypes.float32)\n",
    "    mask = math_ops.cast(mask, dtype=dtypes.float32)\n",
    "\n",
    "    # negatives_outside: smallest D_an where D_an > D_ap.\n",
    "    negatives_outside = array_ops.reshape(\n",
    "        masked_minimum(pdist_matrix_tile, mask), [batch_size, batch_size])\n",
    "    negatives_outside = array_ops.transpose(negatives_outside)\n",
    "\n",
    "    # negatives_inside: largest D_an.\n",
    "    negatives_inside = array_ops.tile(\n",
    "        masked_maximum(pdist_matrix, adjacency_not), [1, batch_size])\n",
    "    semi_hard_negatives = array_ops.where(\n",
    "        mask_final, negatives_outside, negatives_inside)\n",
    "\n",
    "    loss_mat = math_ops.add(margin, pdist_matrix - semi_hard_negatives)\n",
    "\n",
    "    mask_positives = math_ops.cast(\n",
    "        adjacency, dtype=dtypes.float32) - array_ops.diag(\n",
    "        array_ops.ones([batch_size]))\n",
    "\n",
    "    # In lifted-struct, the authors multiply 0.5 for upper triangular\n",
    "    #   in semihard, they take all positive pairs except the diagonal.\n",
    "    num_positives = math_ops.reduce_sum(mask_positives)\n",
    "\n",
    "    semi_hard_triplet_loss_distance = math_ops.truediv(\n",
    "        math_ops.reduce_sum(\n",
    "            math_ops.maximum(\n",
    "                math_ops.multiply(loss_mat, mask_positives), 0.0)),\n",
    "        num_positives,\n",
    "        name='triplet_semihard_loss')\n",
    "    \n",
    "    ### Code from Tensorflow function semi-hard triplet loss ENDS here.\n",
    "    return semi_hard_triplet_loss_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1 = 'p38'\n",
    "base_path_1 = f'C:/Users/tomas/Documents/GitHub/kinase_binding'\n",
    "\n",
    "data_fpath_1 = base_path_1+f'/data/{target_1}/data.csv'\n",
    "df_p38=pd.read_csv(data_fpath_1).set_index('biolab_index')\n",
    "\n",
    "with open(base_path_1+f'/data/{target_1}/train_val_folds.pkl', \"rb\") as in_f:\n",
    "    train_val_folds_p38 = dill.load(in_f)\n",
    "\n",
    "with open(base_path_1+f'/data/{target_1}/train_test_folds.pkl', \"rb\") as in_f:\n",
    "    train_test_folds_p38 = dill.load(in_f)\n",
    "    \n",
    "target_2 = 'akt1'\n",
    "base_path_2 = f'C:/Users/tomas/Documents/GitHub/kinase_binding'\n",
    "\n",
    "data_fpath_2 = base_path_2+f'/data/{target_2}/data.csv'\n",
    "df_akt1 = pd.read_csv(data_fpath_2).set_index('biolab_index')\n",
    "\n",
    "with open(base_path_2+f'/data/{target_2}/train_val_folds.pkl', \"rb\") as in_f:\n",
    "    train_val_folds_akt1 = dill.load(in_f)\n",
    "with open(base_path_2+f'/data/{target_2}/train_test_folds.pkl', \"rb\") as in_f:\n",
    "    train_test_folds_akt1 = dill.load(in_f)\n",
    "    \n",
    "target_3 = 'pi3k'\n",
    "base_path_3 = f'C:/Users/tomas/Documents/GitHub/kinase_binding'\n",
    "\n",
    "data_fpath_3 = base_path_3+f'/data/{target_3}/data.csv'\n",
    "df_pi3k = pd.read_csv(data_fpath_3).set_index('biolab_index')\n",
    "\n",
    "with open(base_path_3+f'/data/{target_3}/train_val_folds.pkl', \"rb\") as in_f:\n",
    "    train_val_folds_pi3k = dill.load(in_f)\n",
    "with open(base_path_3+f'/data/{target_3}/train_test_folds.pkl', \"rb\") as in_f:\n",
    "    train_test_folds_pi3k = dill.load(in_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p38 = df_p38.loc[train_test_folds_p38[0]]            \n",
    "val_p38 = df_p38.loc[train_test_folds_p38[1]]\n",
    "                   \n",
    "\n",
    "train_akt1 = df_akt1.loc[train_test_folds_akt1[0]]           \n",
    "val_akt1 = df_akt1.loc[train_test_folds_akt1[1]]\n",
    "                   \n",
    "\n",
    "train_pi3k = df_pi3k.loc[train_test_folds_pi3k[0]]        \n",
    "val_pi3k = df_pi3k.loc[train_test_folds_pi3k[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random splits with sklearn (on our test set)\n",
    "df_p38 = df_p38.reset_index(drop=True)\n",
    "X_train_p38, X_val_p38, Y_train_p38, Y_val_p38 = train_test_split(df_p38.rdkit,\n",
    "                                                                  df_p38.Binary,\n",
    "                                                                  test_size = 0.15,\n",
    "                                                                  train_size = 0.85,\n",
    "                                                                  shuffle = True)\n",
    "random_train_p38 = pd.DataFrame(X_train_p38)\n",
    "random_train_p38['Binary'] = Y_train_p38\n",
    "random_val_p38 = pd.DataFrame(X_val_p38)\n",
    "random_val_p38['Binary'] = Y_val_p38\n",
    "del X_train_p38,X_val_p38,Y_train_p38,Y_val_p38\n",
    "\n",
    "\n",
    "df_akt1 = df_akt1.reset_index(drop=True)\n",
    "X_train_akt1, X_val_akt1, Y_train_akt1, Y_val_akt1 = train_test_split(df_akt1.rdkit,\n",
    "                                                                     df_akt1.Binary,\n",
    "                                                                     test_size = 0.15,\n",
    "                                                                     train_size = 0.85,\n",
    "                                                                     shuffle = True)\n",
    "random_train_akt1 = pd.DataFrame(X_train_akt1)\n",
    "random_train_akt1['Binary'] = Y_train_akt1\n",
    "random_val_akt1 = pd.DataFrame(X_val_akt1)\n",
    "random_val_akt1['Binary'] = Y_val_akt1\n",
    "del X_train_akt1,X_val_akt1,Y_train_akt1,Y_val_akt1\n",
    "\n",
    "\n",
    "df_pi3k = df_pi3k.reset_index(drop=True)\n",
    "X_train_pi3k, X_val_pi3k, Y_train_pi3k, Y_val_pi3k = train_test_split(df_pi3k.rdkit,\n",
    "                                                                      df_pi3k.Binary,\n",
    "                                                                      test_size = 0.15,\n",
    "                                                                      train_size = 0.85,\n",
    "                                                                      shuffle = True)\n",
    "random_train_pi3k = pd.DataFrame(X_train_pi3k)\n",
    "random_train_pi3k['Binary'] = Y_train_pi3k\n",
    "random_val_pi3k = pd.DataFrame(X_val_pi3k)\n",
    "random_val_pi3k['Binary'] = Y_val_pi3k\n",
    "del X_train_pi3k,X_val_pi3k,Y_train_pi3k,Y_val_pi3k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_generator_mining(bs,df_p1,df_p2,df_p3,\n",
    "                         Y_dummy_p1,Y_dummy_p2,Y_dummy_p3,\n",
    "                         smiles_list_p1,smiles_list_p2,smiles_list_p3,\n",
    "                         Y_p1,Y_p2,Y_p3,\n",
    "                         atoms_p1,bonds_p1,edges_p1,\n",
    "                         atoms_p2,bonds_p2,edges_p2,\n",
    "                         atoms_p3,bonds_p3,edges_p3,mode = 'train',aug = None):\n",
    "    \n",
    "    counter_1=int(0)\n",
    "    counter_2=int(0)\n",
    "    counter_3=int(0)\n",
    "    #Keep looping indefinetely\n",
    "    df_p1 = df_p1.reset_index(drop=True)\n",
    "    df_p2 = df_p2.reset_index(drop=True)\n",
    "    df_p3 = df_p3.reset_index(drop=True)\n",
    "    Y_p1 = np.array(list(Y_p1))\n",
    "    Y_p2 = np.array(list(Y_p2))\n",
    "    Y_p3 = np.array(list(Y_p3))\n",
    "    while True:\n",
    "        \n",
    "        #Initialize batches of inputs and outputs\n",
    "        ind1 = []\n",
    "        ind2 = []\n",
    "        ind3 = []\n",
    "        \n",
    "        d_p1=[]\n",
    "        d_p2=[]\n",
    "        d_p3=[]\n",
    "        \n",
    "        #Keep looping until we reach batch size\n",
    "        while len(ind3)<=bs: #doesn't matter if it is smi1 or smi2 since they have the same len\n",
    "            if counter_3==len(df_p3):\n",
    "                counter_3=int(0)\n",
    "                df_p3 = df_p3.sample(frac=1).reset_index(drop=True)\n",
    "            \n",
    "            smi_p3 = df_p3['rdkit'][counter_3]\n",
    "            ind3.append(smiles_list_p3.index(smi_p3))\n",
    "            d_p3.append(Y_dummy_p3[counter_3])\n",
    "            counter_3+=1\n",
    "            while len(ind1)<=bs:\n",
    "                if counter_1==len(df_p1):\n",
    "                    counter_1=int(0)\n",
    "                    df_p1 = df_p1.sample(frac=1).reset_index(drop=True)\n",
    "                \n",
    "                smi_p1 = df_p1['rdkit'][counter_1]\n",
    "                ind1.append(smiles_list_p1.index(smi_p1))\n",
    "                d_p1.append(Y_dummy_p1[counter_1])\n",
    "                counter_1+=1\n",
    "                \n",
    "                \n",
    "                while len(ind2)<=bs:\n",
    "            # check to see if you reached the end of the frame\n",
    "                    if counter_2==len(df_p2):\n",
    "                        counter_2=int(0)\n",
    "                        df_p2 = df_p2.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "                    smi_p2 = df_p2['rdkit'][counter_2]\n",
    "                    ind2.append(smiles_list_p2.index(smi_p2))\n",
    "                    d_p2.append(Y_dummy_p2[counter_2])\n",
    "                    counter_2+=1\n",
    "                # if we are evaluating we should now break from our \n",
    "                # loop to ensure we don't continue to fill up the batch from samples at the beginning of the file\n",
    "                \n",
    "                   \n",
    "            \n",
    "            \n",
    "\n",
    "            #smi_p1 = df_p1['rdkit'][counter]\n",
    "            #smi_p2 = df_p2['rdkit'][counter]\n",
    "            #smi_p3 = df_p3['rdkit'][counter]\n",
    "            #ind1.append(smiles_list_p1.index(smi_p1))\n",
    "            #ind2.append(smiles_list_p2.index(smi_p2))\n",
    "            #ind3.append(smiles_list_p3.index(smi_p3))\n",
    "            #d_p1.append(Y_dummy_p1[counter])\n",
    "            #d_p2.append(Y_dummy_p2[counter])\n",
    "            #d_p3.append(Y_dummy_p3[counter])\n",
    "            #counter+=1\n",
    "            \n",
    "        atoms_target_1 = np.array(atoms_p1[ind1],dtype = 'float32')\n",
    "        bonds_target_1 = np.array(bonds_p1[ind1],dtype = 'float32')\n",
    "        edges_target_1 = np.array(edges_p1[ind1],dtype = 'int32')\n",
    "        labels_target_1 = Y_p1[ind1]\n",
    "        \n",
    "        atoms_target_2 = np.array(atoms_p2[ind2],dtype = 'float32')\n",
    "        bonds_target_2 = np.array(bonds_p2[ind2],dtype = 'float32')\n",
    "        edges_target_2 = np.array(edges_p2[ind2],dtype = 'int32')\n",
    "        labels_target_2 = Y_p2[ind2]\n",
    "        \n",
    "        atoms_target_3 = np.array(atoms_p3[ind3],dtype = 'float32')\n",
    "        bonds_target_3 = np.array(bonds_p3[ind3],dtype = 'float32')\n",
    "        edges_target_3 = np.array(edges_p3[ind3],dtype = 'int32')\n",
    "        labels_target_3 = Y_p3[ind3]\n",
    "        \n",
    "        yield ({'atom_inputs_1':atoms_target_1,\n",
    "                'bond_inputs_1':bonds_target_1,\n",
    "                'edge_inputs_1':edges_target_1,\n",
    "                'labels_inputs_1':labels_target_1,\n",
    "                'atom_inputs_2':atoms_target_2,\n",
    "                'bond_inputs_2':bonds_target_2,\n",
    "                'edge_inputs_2':edges_target_2,\n",
    "                'labels_inputs_2':labels_target_2,\n",
    "                'atom_inputs_3':atoms_target_3,\n",
    "                'bond_inputs_3':bonds_target_3,\n",
    "                'edge_inputs_3':edges_target_3,\n",
    "                'labels_inputs_3':labels_target_3},{'Protein_1':np.array(d_p1,dtype = 'float32'),\n",
    "                                                    'Protein_2':np.array(d_p2,dtype = 'float32'),\n",
    "                                                    'Protein_3':np.array(d_p3,dtype = 'float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(encoder_params):\n",
    "        model_enc_1 = stage_creator(encoder_params, 1, conv=True)[0]\n",
    "        model_enc_2 = stage_creator(encoder_params, 2, conv=True)[0]\n",
    "        model_enc_3 = stage_creator(encoder_params, 3, conv=True)[0]\n",
    "\n",
    "        model_enc_fp_1 = stage_creator(encoder_params, 1, conv=False)[1]\n",
    "        model_enc_fp_2 = stage_creator(encoder_params, 2, conv=False)[1]\n",
    "        model_enc_fp_3 = stage_creator(encoder_params, 3, conv=False)[1]\n",
    "\n",
    "        atoms, bonds, edges = encode_smiles(encoder_params[\"max_atoms\"],\n",
    "                                            encoder_params[\"num_atom_features\"],\n",
    "                                            encoder_params[\"max_degree\"],\n",
    "                                            encoder_params[\"num_bond_features\"])\n",
    "\n",
    "        graph_conv_1 = model_enc_1([atoms, bonds, edges])\n",
    "        graph_conv_2 = model_enc_2([graph_conv_1, bonds, edges])\n",
    "        graph_conv_3 = model_enc_3([graph_conv_2, bonds, edges])\n",
    "\n",
    "        fingerprint_1 = model_enc_fp_1([graph_conv_1, bonds, edges])\n",
    "        fingerprint_1 = Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0], s[2]))(fingerprint_1)\n",
    "\n",
    "        fingerprint_2 = model_enc_fp_2([graph_conv_2, bonds, edges])\n",
    "        fingerprint_2 = Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0], s[2]))(fingerprint_2)\n",
    "\n",
    "        fingerprint_3 = model_enc_fp_3([graph_conv_3, bonds, edges])\n",
    "        fingerprint_3 = Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0], s[2]))(fingerprint_3)\n",
    "\n",
    "        final_fingerprint = keras.layers.add([fingerprint_1, fingerprint_2, fingerprint_3])\n",
    "\n",
    "        return Model([atoms, bonds, edges], [final_fingerprint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_params, encoder, verbose=False):\n",
    "        atoms_1 = Input(name='atom_inputs_1',\n",
    "                      shape=(model_params['max_atoms'], model_params['num_atom_features']), dtype='float32')\n",
    "        bonds_1 = Input(name='bond_inputs_1', shape=(\n",
    "            model_params['max_atoms'], model_params['max_degree'], model_params['num_bond_features']),\n",
    "                      dtype='float32')\n",
    "        edges_1 = Input(name='edge_inputs_1', shape=(model_params['max_atoms'], model_params['max_degree']),\n",
    "                      dtype='int32')\n",
    "        encode_drug_1 = encoder([atoms_1, bonds_1, edges_1])\n",
    "        \n",
    "        atoms_2 = Input(name='atom_inputs_2',\n",
    "                      shape=(model_params['max_atoms'], model_params['num_atom_features']), dtype='float32')\n",
    "        bonds_2 = Input(name='bond_inputs_2', shape=(\n",
    "            model_params['max_atoms'], model_params['max_degree'], model_params['num_bond_features']),\n",
    "                      dtype='float32')\n",
    "        edges_2 = Input(name='edge_inputs_2', shape=(model_params['max_atoms'], model_params['max_degree']),\n",
    "                      dtype='int32')\n",
    "        encode_drug_2 = encoder([atoms_2, bonds_2, edges_2])\n",
    "        \n",
    "        atoms_3 = Input(name='atom_inputs_3',\n",
    "                      shape=(model_params['max_atoms'], model_params['num_atom_features']), dtype='float32')\n",
    "        bonds_3 = Input(name='bond_inputs_3', shape=(\n",
    "            model_params['max_atoms'], model_params['max_degree'], model_params['num_bond_features']),\n",
    "                      dtype='float32')\n",
    "        edges_3 = Input(name='edge_inputs_3', shape=(model_params['max_atoms'], model_params['max_degree']),\n",
    "                      dtype='int32')\n",
    "        encode_drug_3 = encoder([atoms_3, bonds_3, edges_3])\n",
    "        \n",
    "        conc = keras.layers.Concatenate(axis = -1)([encode_drug_1,encode_drug_2,encode_drug_3])\n",
    "        # Fully connected\n",
    "        FC1 = Dense(model_params[\"dense_size\"][0], activation='relu',kernel_initializer='random_normal')(conc)\n",
    "        FC2 = Dropout(model_params[\"dropout_rate\"][0])(FC1)\n",
    "        FC2 = Dense(model_params[\"dense_size\"][1], activation='relu',kernel_initializer='random_normal')(FC2)\n",
    "        FC2 = Dropout(model_params[\"dropout_rate\"][1])(FC2)\n",
    "        FC2 = Dense(model_params[\"dense_size\"][2], activation = None,kernel_initializer='random_normal')(FC2)\n",
    "        \n",
    "        \n",
    "        embeddings_conc = Lambda(lambda x: K.l2_normalize(x,axis=1),name = 'Embeddings_Concatenated')(FC2)\n",
    "        embeddings_1 = crop(1,0,int(model_params['dense_size'][2]/3),name = 'Target_1')(embeddings_conc) #0 to 255(256)\n",
    "        embeddings_2 = crop(1,int(model_params['dense_size'][2]/3),2*int(model_params['dense_size'][2]/3),name = 'Target_2')(embeddings_conc) #256 to 511(256)\n",
    "        embeddings_3 = crop(1,2*int(model_params['dense_size'][2]/3),3*int(model_params['dense_size'][2]/3),name = 'Target_3')(embeddings_conc)\n",
    "        \n",
    "        gcn_model = Model(inputs=[atoms_1, bonds_1, edges_1,\n",
    "                                  atoms_2, bonds_2, edges_2,\n",
    "                                  atoms_3, bonds_3, edges_3], \n",
    "                                  outputs = [embeddings_1,\n",
    "                                             embeddings_2,\n",
    "                                             embeddings_3]\n",
    "                         )\n",
    "\n",
    "\n",
    "        if verbose:\n",
    "            #print('encoder')\n",
    "            #encoder.summary()\n",
    "            print('GCN_model')\n",
    "            gcn_model.summary()\n",
    "        \n",
    "            \n",
    "        return gcn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mining(model_params,gcn_model):\n",
    "        #First Target\n",
    "        atoms_1 = Input(name='atom_inputs_1',shape=(model_params['max_atoms'], \n",
    "                                                    model_params['num_atom_features']), \n",
    "                                                    dtype='float32')\n",
    "        bonds_1 = Input(name='bond_inputs_1', shape=(model_params['max_atoms'], \n",
    "                                                     model_params['max_degree'], \n",
    "                                                     model_params['num_bond_features']),\n",
    "                                                     dtype='float32')\n",
    "        edges_1 = Input(name='edge_inputs_1', shape=(model_params['max_atoms'], \n",
    "                                                     model_params['max_degree']),\n",
    "                                                     dtype='int32')\n",
    "        \n",
    "        labels_1 = Input(name = 'labels_inputs_1',shape = (1,),dtype = 'float32')\n",
    "        \n",
    "        #Second Target\n",
    "        atoms_2 = Input(name='atom_inputs_2',shape=(model_params['max_atoms'], \n",
    "                                                    model_params['num_atom_features']), \n",
    "                                                    dtype='float32')\n",
    "        bonds_2 = Input(name='bond_inputs_2', shape=(model_params['max_atoms'], \n",
    "                                                     model_params['max_degree'], \n",
    "                                                     model_params['num_bond_features']),\n",
    "                                                     dtype='float32')\n",
    "        edges_2 = Input(name='edge_inputs_2', shape=(model_params['max_atoms'], \n",
    "                                                     model_params['max_degree']),\n",
    "                                                     dtype='int32')\n",
    "        \n",
    "        labels_2 = Input(name = 'labels_inputs_2',shape = (1,),dtype = 'float32')\n",
    "        \n",
    "        #Third Target\n",
    "        atoms_3 = Input(name='atom_inputs_3',shape=(model_params['max_atoms'], \n",
    "                                                    model_params['num_atom_features']), \n",
    "                                                    dtype='float32')\n",
    "        bonds_3 = Input(name='bond_inputs_3', shape=(model_params['max_atoms'], \n",
    "                                                     model_params['max_degree'], \n",
    "                                                     model_params['num_bond_features']),\n",
    "                                                     dtype='float32')\n",
    "        edges_3 = Input(name='edge_inputs_3', shape=(model_params['max_atoms'], model_params['max_degree']),\n",
    "                      dtype='int32')\n",
    "        \n",
    "        labels_3 = Input(name = 'labels_inputs_3',shape = (1,),dtype = 'float32')\n",
    "        encoded_1,encoded_2,encoded_3 = gcn_model([atoms_1,bonds_1,edges_1,\n",
    "                                                   atoms_2,bonds_2,edges_2,\n",
    "                                                   atoms_3,bonds_3,edges_3])\n",
    "        \n",
    "        labels_plus_embeddings_1 = concatenate([labels_1, encoded_1],name = 'Protein_1')\n",
    "        labels_plus_embeddings_2 = concatenate([labels_2, encoded_2],name = 'Protein_2')\n",
    "        labels_plus_embeddings_3 = concatenate([labels_3, encoded_3],name = 'Protein_3')\n",
    "        \n",
    "        mining_net = Model(inputs = [atoms_1,bonds_1,edges_1,labels_1,\n",
    "                                     atoms_2,bonds_2,edges_2,labels_2,\n",
    "                                     atoms_3,bonds_3,edges_3,labels_3],\n",
    "                           outputs = [labels_plus_embeddings_1,\n",
    "                                      labels_plus_embeddings_2,\n",
    "                                      labels_plus_embeddings_3])\n",
    "        adam = keras.optimizers.Adam(lr = model_params[\"lr\"], \n",
    "                                     beta_1=0.9, \n",
    "                                     beta_2=0.999, \n",
    "                                     decay=0.0, \n",
    "                                     amsgrad=False)\n",
    "    \n",
    "    \n",
    "        mining_net.compile(optimizer=adam , loss = {'Protein_1' : triplet_loss_adapted_from_tf,\n",
    "                                                    'Protein_2' : triplet_loss_adapted_from_tf,\n",
    "                                                    'Protein_3' : triplet_loss_adapted_from_tf})\n",
    "        mining_net.summary()\n",
    "        return mining_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_gcn_input(input_data):\n",
    "        x_atoms_cold, x_bonds_cold, x_edges_cold = tensorise_smiles(input_data['rdkit'],\n",
    "                                                                    max_degree=model_params['max_degree'],\n",
    "                                                                    max_atoms=model_params['max_atoms'])\n",
    "        return [x_atoms_cold, x_bonds_cold, x_edges_cold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss',patience=8, min_delta=0)\n",
    "rlr = ReduceLROnPlateau(monitor='loss',factor=0.5, patience=4, verbose=1, min_lr=0.0000001)\n",
    "model_params = {\n",
    "        \"num_layers\" : 3,\n",
    "        \"max_atoms\" : 70,\n",
    "        \"num_atom_features\" : 62,\n",
    "        \"num_atom_features_original\" : 62,\n",
    "        \"num_bond_features\" : 6,\n",
    "        \"max_degree\" : 5,\n",
    "        \"conv_width\" : [int(96), int(104), int(120)],\n",
    "        \"fp_length\" : [int(160), int(160), int(160)],\n",
    "        \"activ_enc\" : \"selu\",\n",
    "        \"activ_dec\" : \"selu\",\n",
    "        \"learning_rates\" : [0.001,0.001,0.001],\n",
    "        \"learning_rates_fp\": [0.005,0.005,0.005],\n",
    "        \"losses_conv\" : {\n",
    "                    \"neighbor_output\": \"mean_squared_error\",\n",
    "                    \"self_output\": \"mean_squared_error\",\n",
    "                    },\n",
    "        \"lossWeights\" : {\"neighbor_output\": 1.0, \"self_output\": 1.0},\n",
    "        \"metrics\" : \"mse\",\n",
    "        \"loss_fp\" : \"mean_squared_error\",\n",
    "        \"enc_layer_names\" : [\"enc_1\", \"enc_2\", \"enc_3\"],\n",
    "        'callbacks' : [es,rlr],\n",
    "        'adam_decay': 0.0005329142291371636,\n",
    "        'beta': 5,\n",
    "        'p': 0.004465204118126482,\n",
    "        'dense_size' : [int(3*160), int(3*160), int(3*96)], \n",
    "        'dropout_rate' : [0.27225175676555935, 0.27225175676555935],\n",
    "        'lr' : 0.008110012706176706,\n",
    "        'batch_size' : int(256),\n",
    "        'n_epochs' : int(20),\n",
    "        'margin' : 1\n",
    "        }\n",
    "xgb_hyper = {\n",
    "        \"colsample_bylevel\" : 0.4371082812232264,\n",
    "        \"colsample_bytree\" : 0.4179415558635843,\n",
    "        \"gamma\" : 0.919836526180396,\n",
    "        \"eta\" : 0.41409388868400826,\n",
    "        \"max_delta_step\" : int(2),\n",
    "        \"max_depth\" : int(7),\n",
    "        \"min_child_weight\" : int(20),\n",
    "        \"alpha\" : 0.15030685758880047,\n",
    "        \"lambda\" : 12.306130216692438,\n",
    "        \"subsample\" : 0.6038298323514097,\n",
    "        \"max_bin\" : int(48.0),\n",
    "        \"eval_metric\":'auc',\n",
    "        \"objective\":'binary:logistic',\n",
    "        \"booster\":'gbtree'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(dimension, start, end,name):\n",
    "    # Crops (or slices) a Tensor on a given dimension from start to end\n",
    "    # example : to crop tensor x[:, :, 5:10]\n",
    "    # call slice(2, 5, 10) as you want to crop on the second dimension\n",
    "    def func(x):\n",
    "        if dimension == 0:\n",
    "            return x[start: end]\n",
    "        if dimension == 1:\n",
    "            return x[:, start: end]\n",
    "        if dimension == 2:\n",
    "            return x[:, :, start: end]\n",
    "        if dimension == 3:\n",
    "            return x[:, :, :, start: end]\n",
    "        if dimension == 4:\n",
    "            return x[:, :, :, :, start: end]\n",
    "    return Lambda(func,name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_p38 = [train_p38,random_train_p38]\n",
    "validation_p38 = [val_p38,random_val_p38]\n",
    "\n",
    "training_akt1 = [train_akt1,random_train_akt1]\n",
    "validation_akt1 = [val_akt1,random_val_akt1]\n",
    "\n",
    "training_pi3k = [train_pi3k,random_train_pi3k]\n",
    "validation_pi3k = [val_pi3k,random_val_pi3k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "atom_inputs_1 (InputLayer)      (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_1 (InputLayer)      (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_1 (InputLayer)      (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_inputs_2 (InputLayer)      (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_2 (InputLayer)      (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_2 (InputLayer)      (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_inputs_3 (InputLayer)      (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_3 (InputLayer)      (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_3 (InputLayer)      (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "labels_inputs_1 (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_11 (Model)                [(None, 96), (None,  841984      atom_inputs_1[0][0]              \n",
      "                                                                 bond_inputs_1[0][0]              \n",
      "                                                                 edge_inputs_1[0][0]              \n",
      "                                                                 atom_inputs_2[0][0]              \n",
      "                                                                 bond_inputs_2[0][0]              \n",
      "                                                                 edge_inputs_2[0][0]              \n",
      "                                                                 atom_inputs_3[0][0]              \n",
      "                                                                 bond_inputs_3[0][0]              \n",
      "                                                                 edge_inputs_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "labels_inputs_2 (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "labels_inputs_3 (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Protein_1 (Concatenate)         (None, 97)           0           labels_inputs_1[0][0]            \n",
      "                                                                 model_11[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Protein_2 (Concatenate)         (None, 97)           0           labels_inputs_2[0][0]            \n",
      "                                                                 model_11[1][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "Protein_3 (Concatenate)         (None, 97)           0           labels_inputs_3[0][0]            \n",
      "                                                                 model_11[1][2]                   \n",
      "==================================================================================================\n",
      "Total params: 841,984\n",
      "Trainable params: 840,384\n",
      "Non-trainable params: 1,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "95/95 [==============================] - 25s 267ms/step - loss: 1.4795 - Protein_1_loss: 0.4931 - Protein_2_loss: 0.4926 - Protein_3_loss: 0.4938\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 16s 166ms/step - loss: 1.4654 - Protein_1_loss: 0.4927 - Protein_2_loss: 0.4801 - Protein_3_loss: 0.4926\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 16s 166ms/step - loss: 1.4668 - Protein_1_loss: 0.4930 - Protein_2_loss: 0.4812 - Protein_3_loss: 0.4925\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 16s 166ms/step - loss: 1.4642 - Protein_1_loss: 0.4929 - Protein_2_loss: 0.4797 - Protein_3_loss: 0.4916\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4581 - Protein_1_loss: 0.4933 - Protein_2_loss: 0.4754 - Protein_3_loss: 0.4894\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4562 - Protein_1_loss: 0.4924 - Protein_2_loss: 0.4741 - Protein_3_loss: 0.4897\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4527 - Protein_1_loss: 0.4921 - Protein_2_loss: 0.4706 - Protein_3_loss: 0.4900\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4523 - Protein_1_loss: 0.4916 - Protein_2_loss: 0.4692 - Protein_3_loss: 0.4915s - loss: 1.4528 - Protein_1_loss: 0.4917 - Prote\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4558 - Protein_1_loss: 0.4908 - Protein_2_loss: 0.4746 - Protein_3_loss: 0.4905\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4512 - Protein_1_loss: 0.4913 - Protein_2_loss: 0.4694 - Protein_3_loss: 0.4906\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4498 - Protein_1_loss: 0.4928 - Protein_2_loss: 0.4656 - Protein_3_loss: 0.4913\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4519 - Protein_1_loss: 0.4915 - Protein_2_loss: 0.4706 - Protein_3_loss: 0.4898\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4459 - Protein_1_loss: 0.4918 - Protein_2_loss: 0.4630 - Protein_3_loss: 0.4910\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4425 - Protein_1_loss: 0.4921 - Protein_2_loss: 0.4599 - Protein_3_loss: 0.4905\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4422 - Protein_1_loss: 0.4928 - Protein_2_loss: 0.4589 - Protein_3_loss: 0.4905\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 16s 168ms/step - loss: 1.4318 - Protein_1_loss: 0.4924 - Protein_2_loss: 0.4476 - Protein_3_loss: 0.4917\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4299 - Protein_1_loss: 0.4929 - Protein_2_loss: 0.4452 - Protein_3_loss: 0.4919\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4229 - Protein_1_loss: 0.4923 - Protein_2_loss: 0.4383 - Protein_3_loss: 0.4923\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4166 - Protein_1_loss: 0.4922 - Protein_2_loss: 0.4313 - Protein_3_loss: 0.4931\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4076 - Protein_1_loss: 0.4923 - Protein_2_loss: 0.4216 - Protein_3_loss: 0.4938\n",
      "[0]\ttrain-auc:0.62006\teval-auc:0.47418\n",
      "[1]\ttrain-auc:0.63382\teval-auc:0.46166\n",
      "[2]\ttrain-auc:0.64228\teval-auc:0.47406\n",
      "[3]\ttrain-auc:0.64493\teval-auc:0.47075\n",
      "[4]\ttrain-auc:0.65103\teval-auc:0.46957\n",
      "[5]\ttrain-auc:0.65516\teval-auc:0.48075\n",
      "[6]\ttrain-auc:0.66016\teval-auc:0.47427\n",
      "[7]\ttrain-auc:0.66696\teval-auc:0.46861\n",
      "[8]\ttrain-auc:0.67007\teval-auc:0.46085\n",
      "[9]\ttrain-auc:0.67339\teval-auc:0.46425\n",
      "[10]\ttrain-auc:0.67805\teval-auc:0.45763\n",
      "[11]\ttrain-auc:0.68243\teval-auc:0.45522\n",
      "[12]\ttrain-auc:0.68723\teval-auc:0.46377\n",
      "[13]\ttrain-auc:0.69175\teval-auc:0.48235\n",
      "[14]\ttrain-auc:0.69609\teval-auc:0.46333\n",
      "[15]\ttrain-auc:0.69773\teval-auc:0.46303\n",
      "[16]\ttrain-auc:0.70046\teval-auc:0.46961\n",
      "[17]\ttrain-auc:0.70446\teval-auc:0.46015\n",
      "[18]\ttrain-auc:0.70484\teval-auc:0.45542\n",
      "[19]\ttrain-auc:0.70797\teval-auc:0.45938\n",
      "[20]\ttrain-auc:0.71351\teval-auc:0.47378\n",
      "[21]\ttrain-auc:0.71555\teval-auc:0.47100\n",
      "[22]\ttrain-auc:0.72120\teval-auc:0.46642\n",
      "[23]\ttrain-auc:0.72357\teval-auc:0.47461\n",
      "[24]\ttrain-auc:0.72492\teval-auc:0.47975\n",
      "[25]\ttrain-auc:0.72829\teval-auc:0.48237\n",
      "[26]\ttrain-auc:0.73087\teval-auc:0.47761\n",
      "[27]\ttrain-auc:0.73295\teval-auc:0.47170\n",
      "[28]\ttrain-auc:0.73472\teval-auc:0.47609\n",
      "[29]\ttrain-auc:0.73232\teval-auc:0.46980\n",
      "[30]\ttrain-auc:0.73558\teval-auc:0.46750\n",
      "[31]\ttrain-auc:0.73922\teval-auc:0.47518\n",
      "[32]\ttrain-auc:0.74062\teval-auc:0.47387\n",
      "[33]\ttrain-auc:0.74591\teval-auc:0.48022\n",
      "[34]\ttrain-auc:0.74655\teval-auc:0.48472\n",
      "[35]\ttrain-auc:0.74803\teval-auc:0.48562\n",
      "[36]\ttrain-auc:0.74945\teval-auc:0.48822\n",
      "[37]\ttrain-auc:0.75168\teval-auc:0.48891\n",
      "[38]\ttrain-auc:0.75131\teval-auc:0.48484\n",
      "[39]\ttrain-auc:0.75580\teval-auc:0.48140\n",
      "[40]\ttrain-auc:0.75867\teval-auc:0.49404\n",
      "[41]\ttrain-auc:0.75711\teval-auc:0.48428\n",
      "[42]\ttrain-auc:0.75665\teval-auc:0.48628\n",
      "[43]\ttrain-auc:0.76164\teval-auc:0.49024\n",
      "[44]\ttrain-auc:0.76071\teval-auc:0.48738\n",
      "[45]\ttrain-auc:0.76531\teval-auc:0.48497\n",
      "[46]\ttrain-auc:0.76686\teval-auc:0.47579\n",
      "[47]\ttrain-auc:0.76904\teval-auc:0.47147\n",
      "[48]\ttrain-auc:0.76861\teval-auc:0.47931\n",
      "[49]\ttrain-auc:0.77212\teval-auc:0.48298\n",
      "[50]\ttrain-auc:0.77220\teval-auc:0.47822\n",
      "[51]\ttrain-auc:0.77386\teval-auc:0.48288\n",
      "[52]\ttrain-auc:0.77458\teval-auc:0.47485\n",
      "[53]\ttrain-auc:0.77705\teval-auc:0.48415\n",
      "[54]\ttrain-auc:0.77868\teval-auc:0.48042\n",
      "[55]\ttrain-auc:0.77826\teval-auc:0.47834\n",
      "[56]\ttrain-auc:0.78032\teval-auc:0.48300\n",
      "[57]\ttrain-auc:0.78221\teval-auc:0.48492\n",
      "[58]\ttrain-auc:0.78151\teval-auc:0.48796\n",
      "[59]\ttrain-auc:0.78360\teval-auc:0.49742\n",
      "[60]\ttrain-auc:0.78485\teval-auc:0.49135\n",
      "[61]\ttrain-auc:0.78746\teval-auc:0.48657\n",
      "[62]\ttrain-auc:0.79030\teval-auc:0.48215\n",
      "[63]\ttrain-auc:0.79254\teval-auc:0.48124\n",
      "[64]\ttrain-auc:0.79315\teval-auc:0.48970\n",
      "[65]\ttrain-auc:0.79511\teval-auc:0.49403\n",
      "[66]\ttrain-auc:0.79386\teval-auc:0.49119\n",
      "[67]\ttrain-auc:0.79907\teval-auc:0.48019\n",
      "[68]\ttrain-auc:0.79909\teval-auc:0.47798\n",
      "[69]\ttrain-auc:0.80242\teval-auc:0.48152\n",
      "[70]\ttrain-auc:0.80315\teval-auc:0.47906\n",
      "[71]\ttrain-auc:0.80299\teval-auc:0.48165\n",
      "[72]\ttrain-auc:0.80399\teval-auc:0.47880\n",
      "[73]\ttrain-auc:0.80826\teval-auc:0.47401\n",
      "[74]\ttrain-auc:0.80825\teval-auc:0.47089\n",
      "[75]\ttrain-auc:0.81144\teval-auc:0.47460\n",
      "[76]\ttrain-auc:0.81084\teval-auc:0.48263\n",
      "[77]\ttrain-auc:0.81004\teval-auc:0.48160\n",
      "[78]\ttrain-auc:0.81099\teval-auc:0.47888\n",
      "[79]\ttrain-auc:0.81044\teval-auc:0.47595\n",
      "[80]\ttrain-auc:0.81331\teval-auc:0.47925\n",
      "[81]\ttrain-auc:0.81259\teval-auc:0.47627\n",
      "[82]\ttrain-auc:0.81787\teval-auc:0.47504\n",
      "[83]\ttrain-auc:0.81730\teval-auc:0.47990\n",
      "[84]\ttrain-auc:0.81459\teval-auc:0.48581\n",
      "[85]\ttrain-auc:0.81654\teval-auc:0.48111\n",
      "[86]\ttrain-auc:0.81854\teval-auc:0.47895\n",
      "[87]\ttrain-auc:0.81939\teval-auc:0.48186\n",
      "[88]\ttrain-auc:0.81746\teval-auc:0.48298\n",
      "[89]\ttrain-auc:0.81683\teval-auc:0.48265\n",
      "[90]\ttrain-auc:0.81983\teval-auc:0.47815\n",
      "[91]\ttrain-auc:0.81869\teval-auc:0.48609\n",
      "[92]\ttrain-auc:0.82456\teval-auc:0.47807\n",
      "[93]\ttrain-auc:0.82445\teval-auc:0.47769\n",
      "[94]\ttrain-auc:0.82412\teval-auc:0.47455\n",
      "[95]\ttrain-auc:0.82446\teval-auc:0.47926\n",
      "[96]\ttrain-auc:0.82598\teval-auc:0.47394\n",
      "[97]\ttrain-auc:0.82764\teval-auc:0.47600\n",
      "[98]\ttrain-auc:0.83013\teval-auc:0.48052\n",
      "[99]\ttrain-auc:0.83019\teval-auc:0.48479\n",
      "[100]\ttrain-auc:0.82974\teval-auc:0.48300\n",
      "[101]\ttrain-auc:0.83110\teval-auc:0.48005\n",
      "[102]\ttrain-auc:0.83302\teval-auc:0.47972\n",
      "[103]\ttrain-auc:0.83450\teval-auc:0.47805\n",
      "[104]\ttrain-auc:0.83453\teval-auc:0.48470\n",
      "[105]\ttrain-auc:0.83425\teval-auc:0.47662\n",
      "[106]\ttrain-auc:0.83479\teval-auc:0.47866\n",
      "[107]\ttrain-auc:0.83701\teval-auc:0.47740\n",
      "[108]\ttrain-auc:0.83672\teval-auc:0.48134\n",
      "[109]\ttrain-auc:0.83563\teval-auc:0.48517\n",
      "[110]\ttrain-auc:0.83785\teval-auc:0.48641\n",
      "[111]\ttrain-auc:0.83651\teval-auc:0.49074\n",
      "[112]\ttrain-auc:0.83807\teval-auc:0.49086\n",
      "[113]\ttrain-auc:0.83937\teval-auc:0.48834\n",
      "[114]\ttrain-auc:0.83968\teval-auc:0.48288\n",
      "[115]\ttrain-auc:0.84049\teval-auc:0.48251\n",
      "[116]\ttrain-auc:0.84304\teval-auc:0.48068\n",
      "[117]\ttrain-auc:0.84624\teval-auc:0.48190\n",
      "[118]\ttrain-auc:0.84655\teval-auc:0.48586\n",
      "[119]\ttrain-auc:0.84662\teval-auc:0.48193\n",
      "[120]\ttrain-auc:0.84723\teval-auc:0.48043\n",
      "[121]\ttrain-auc:0.84648\teval-auc:0.48412\n",
      "[122]\ttrain-auc:0.84957\teval-auc:0.48566\n",
      "[123]\ttrain-auc:0.84900\teval-auc:0.48305\n",
      "[124]\ttrain-auc:0.84720\teval-auc:0.49134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125]\ttrain-auc:0.84648\teval-auc:0.48954\n",
      "[126]\ttrain-auc:0.84738\teval-auc:0.48136\n",
      "[127]\ttrain-auc:0.84807\teval-auc:0.48076\n",
      "[128]\ttrain-auc:0.85171\teval-auc:0.48411\n",
      "[129]\ttrain-auc:0.85333\teval-auc:0.48662\n",
      "[130]\ttrain-auc:0.85091\teval-auc:0.49135\n",
      "[131]\ttrain-auc:0.85266\teval-auc:0.48968\n",
      "[132]\ttrain-auc:0.85358\teval-auc:0.49218\n",
      "[133]\ttrain-auc:0.85141\teval-auc:0.49101\n",
      "[134]\ttrain-auc:0.85281\teval-auc:0.49132\n",
      "[135]\ttrain-auc:0.85388\teval-auc:0.48765\n",
      "[136]\ttrain-auc:0.85333\teval-auc:0.49680\n",
      "[137]\ttrain-auc:0.85594\teval-auc:0.48762\n",
      "[138]\ttrain-auc:0.85672\teval-auc:0.48810\n",
      "[139]\ttrain-auc:0.85967\teval-auc:0.48758\n",
      "[140]\ttrain-auc:0.85970\teval-auc:0.49134\n",
      "[141]\ttrain-auc:0.85941\teval-auc:0.49148\n",
      "[142]\ttrain-auc:0.85710\teval-auc:0.49453\n",
      "[143]\ttrain-auc:0.85883\teval-auc:0.49646\n",
      "[144]\ttrain-auc:0.86071\teval-auc:0.49366\n",
      "[145]\ttrain-auc:0.86145\teval-auc:0.49388\n",
      "[146]\ttrain-auc:0.86158\teval-auc:0.50000\n",
      "[147]\ttrain-auc:0.86367\teval-auc:0.50048\n",
      "[148]\ttrain-auc:0.86382\teval-auc:0.49651\n",
      "[149]\ttrain-auc:0.86502\teval-auc:0.49859\n",
      "[150]\ttrain-auc:0.86677\teval-auc:0.49373\n",
      "[151]\ttrain-auc:0.86545\teval-auc:0.49091\n",
      "[152]\ttrain-auc:0.86622\teval-auc:0.49507\n",
      "[153]\ttrain-auc:0.86730\teval-auc:0.49323\n",
      "[154]\ttrain-auc:0.86696\teval-auc:0.49764\n",
      "[155]\ttrain-auc:0.86792\teval-auc:0.49806\n",
      "[156]\ttrain-auc:0.86881\teval-auc:0.49329\n",
      "[157]\ttrain-auc:0.86843\teval-auc:0.49194\n",
      "[158]\ttrain-auc:0.86891\teval-auc:0.49500\n",
      "[159]\ttrain-auc:0.86735\teval-auc:0.48719\n",
      "[160]\ttrain-auc:0.86951\teval-auc:0.49156\n",
      "[161]\ttrain-auc:0.86871\teval-auc:0.49166\n",
      "[162]\ttrain-auc:0.86743\teval-auc:0.49221\n",
      "[163]\ttrain-auc:0.87013\teval-auc:0.49258\n",
      "[164]\ttrain-auc:0.86897\teval-auc:0.49638\n",
      "[165]\ttrain-auc:0.87028\teval-auc:0.49958\n",
      "[166]\ttrain-auc:0.87287\teval-auc:0.49480\n",
      "[167]\ttrain-auc:0.87367\teval-auc:0.49647\n",
      "[168]\ttrain-auc:0.87460\teval-auc:0.49433\n",
      "[169]\ttrain-auc:0.87637\teval-auc:0.49382\n",
      "[170]\ttrain-auc:0.87686\teval-auc:0.49177\n",
      "[171]\ttrain-auc:0.87854\teval-auc:0.49547\n",
      "[172]\ttrain-auc:0.88002\teval-auc:0.49547\n",
      "[173]\ttrain-auc:0.87951\teval-auc:0.49573\n",
      "[174]\ttrain-auc:0.88160\teval-auc:0.50178\n",
      "[175]\ttrain-auc:0.88362\teval-auc:0.50596\n",
      "[176]\ttrain-auc:0.88275\teval-auc:0.50127\n",
      "[177]\ttrain-auc:0.88305\teval-auc:0.50052\n",
      "[178]\ttrain-auc:0.88293\teval-auc:0.50252\n",
      "[179]\ttrain-auc:0.88264\teval-auc:0.50120\n",
      "[180]\ttrain-auc:0.88430\teval-auc:0.50064\n",
      "[181]\ttrain-auc:0.88451\teval-auc:0.49903\n",
      "[182]\ttrain-auc:0.88387\teval-auc:0.49405\n",
      "[183]\ttrain-auc:0.88401\teval-auc:0.49927\n",
      "[184]\ttrain-auc:0.88513\teval-auc:0.50197\n",
      "[185]\ttrain-auc:0.88623\teval-auc:0.49811\n",
      "[186]\ttrain-auc:0.88541\teval-auc:0.49754\n",
      "[187]\ttrain-auc:0.88664\teval-auc:0.49358\n",
      "[188]\ttrain-auc:0.88940\teval-auc:0.49518\n",
      "[189]\ttrain-auc:0.88729\teval-auc:0.49437\n",
      "[190]\ttrain-auc:0.88902\teval-auc:0.49663\n",
      "[191]\ttrain-auc:0.88983\teval-auc:0.49651\n",
      "[192]\ttrain-auc:0.89034\teval-auc:0.49562\n",
      "[193]\ttrain-auc:0.88980\teval-auc:0.49675\n",
      "[194]\ttrain-auc:0.89075\teval-auc:0.49419\n",
      "[195]\ttrain-auc:0.89340\teval-auc:0.49589\n",
      "[196]\ttrain-auc:0.89225\teval-auc:0.49813\n",
      "[197]\ttrain-auc:0.89204\teval-auc:0.49473\n",
      "[198]\ttrain-auc:0.89508\teval-auc:0.49589\n",
      "[199]\ttrain-auc:0.89416\teval-auc:0.48869\n",
      "[200]\ttrain-auc:0.89375\teval-auc:0.48716\n",
      "[201]\ttrain-auc:0.89561\teval-auc:0.48938\n",
      "[202]\ttrain-auc:0.89568\teval-auc:0.48766\n",
      "[203]\ttrain-auc:0.89490\teval-auc:0.49140\n",
      "[204]\ttrain-auc:0.89463\teval-auc:0.49101\n",
      "[205]\ttrain-auc:0.89544\teval-auc:0.49405\n",
      "[206]\ttrain-auc:0.89560\teval-auc:0.49357\n",
      "[207]\ttrain-auc:0.89543\teval-auc:0.49603\n",
      "[208]\ttrain-auc:0.89318\teval-auc:0.49584\n",
      "[209]\ttrain-auc:0.89328\teval-auc:0.49722\n",
      "[210]\ttrain-auc:0.89337\teval-auc:0.49491\n",
      "[211]\ttrain-auc:0.89609\teval-auc:0.49353\n",
      "[212]\ttrain-auc:0.89670\teval-auc:0.49106\n",
      "[213]\ttrain-auc:0.89923\teval-auc:0.49256\n",
      "[214]\ttrain-auc:0.89981\teval-auc:0.49239\n",
      "[215]\ttrain-auc:0.89822\teval-auc:0.49433\n",
      "[216]\ttrain-auc:0.89974\teval-auc:0.49564\n",
      "[217]\ttrain-auc:0.90041\teval-auc:0.49258\n",
      "[218]\ttrain-auc:0.90177\teval-auc:0.49689\n",
      "[219]\ttrain-auc:0.90007\teval-auc:0.49375\n",
      "[220]\ttrain-auc:0.90157\teval-auc:0.50027\n",
      "[221]\ttrain-auc:0.90104\teval-auc:0.49441\n",
      "[222]\ttrain-auc:0.90334\teval-auc:0.49749\n",
      "[223]\ttrain-auc:0.90442\teval-auc:0.49750\n",
      "[224]\ttrain-auc:0.90519\teval-auc:0.50222\n",
      "[225]\ttrain-auc:0.90409\teval-auc:0.50006\n",
      "[226]\ttrain-auc:0.90627\teval-auc:0.50357\n",
      "[227]\ttrain-auc:0.90525\teval-auc:0.50469\n",
      "[228]\ttrain-auc:0.90599\teval-auc:0.50130\n",
      "[229]\ttrain-auc:0.90651\teval-auc:0.50250\n",
      "[230]\ttrain-auc:0.90534\teval-auc:0.50222\n",
      "[231]\ttrain-auc:0.90681\teval-auc:0.50291\n",
      "[232]\ttrain-auc:0.90748\teval-auc:0.50293\n",
      "[233]\ttrain-auc:0.90926\teval-auc:0.50003\n",
      "[234]\ttrain-auc:0.90644\teval-auc:0.49826\n",
      "[235]\ttrain-auc:0.90798\teval-auc:0.50182\n",
      "[236]\ttrain-auc:0.90871\teval-auc:0.49346\n",
      "[237]\ttrain-auc:0.90920\teval-auc:0.49817\n",
      "[238]\ttrain-auc:0.91058\teval-auc:0.49952\n",
      "[239]\ttrain-auc:0.91027\teval-auc:0.50080\n",
      "[240]\ttrain-auc:0.91132\teval-auc:0.50658\n",
      "[241]\ttrain-auc:0.91060\teval-auc:0.50264\n",
      "[242]\ttrain-auc:0.91015\teval-auc:0.50328\n",
      "[243]\ttrain-auc:0.91136\teval-auc:0.50193\n",
      "[244]\ttrain-auc:0.91256\teval-auc:0.49799\n",
      "[245]\ttrain-auc:0.91207\teval-auc:0.49680\n",
      "[246]\ttrain-auc:0.91164\teval-auc:0.49705\n",
      "[247]\ttrain-auc:0.91204\teval-auc:0.49327\n",
      "[248]\ttrain-auc:0.91372\teval-auc:0.50071\n",
      "[249]\ttrain-auc:0.91185\teval-auc:0.50493\n",
      "[250]\ttrain-auc:0.91336\teval-auc:0.50308\n",
      "[251]\ttrain-auc:0.91474\teval-auc:0.49688\n",
      "[252]\ttrain-auc:0.91637\teval-auc:0.49190\n",
      "[253]\ttrain-auc:0.91563\teval-auc:0.49561\n",
      "[254]\ttrain-auc:0.91483\teval-auc:0.49099\n",
      "[255]\ttrain-auc:0.91624\teval-auc:0.49064\n",
      "[256]\ttrain-auc:0.91566\teval-auc:0.49459\n",
      "[257]\ttrain-auc:0.91587\teval-auc:0.49350\n",
      "[258]\ttrain-auc:0.91645\teval-auc:0.49725\n",
      "[259]\ttrain-auc:0.91817\teval-auc:0.49625\n",
      "[260]\ttrain-auc:0.91837\teval-auc:0.50008\n",
      "[261]\ttrain-auc:0.91820\teval-auc:0.49301\n",
      "[262]\ttrain-auc:0.91800\teval-auc:0.49636\n",
      "[263]\ttrain-auc:0.91793\teval-auc:0.49095\n",
      "[264]\ttrain-auc:0.91904\teval-auc:0.49725\n",
      "[265]\ttrain-auc:0.91827\teval-auc:0.49865\n",
      "[266]\ttrain-auc:0.91827\teval-auc:0.49849\n",
      "[267]\ttrain-auc:0.91946\teval-auc:0.49924\n",
      "[268]\ttrain-auc:0.92095\teval-auc:0.49902\n",
      "[269]\ttrain-auc:0.92233\teval-auc:0.49456\n",
      "[270]\ttrain-auc:0.92126\teval-auc:0.49116\n",
      "[271]\ttrain-auc:0.92152\teval-auc:0.48939\n",
      "[272]\ttrain-auc:0.92298\teval-auc:0.49342\n",
      "[273]\ttrain-auc:0.92411\teval-auc:0.49519\n",
      "[274]\ttrain-auc:0.92605\teval-auc:0.49729\n",
      "[275]\ttrain-auc:0.92352\teval-auc:0.49312\n",
      "[276]\ttrain-auc:0.92410\teval-auc:0.49515\n",
      "[277]\ttrain-auc:0.92361\teval-auc:0.49331\n",
      "[278]\ttrain-auc:0.92240\teval-auc:0.49437\n",
      "[279]\ttrain-auc:0.92477\teval-auc:0.49499\n",
      "[280]\ttrain-auc:0.92412\teval-auc:0.49562\n",
      "[281]\ttrain-auc:0.92548\teval-auc:0.49854\n",
      "[282]\ttrain-auc:0.92595\teval-auc:0.49779\n",
      "[283]\ttrain-auc:0.92629\teval-auc:0.50092\n",
      "[284]\ttrain-auc:0.92688\teval-auc:0.50177\n",
      "[285]\ttrain-auc:0.92631\teval-auc:0.50014\n",
      "[286]\ttrain-auc:0.92697\teval-auc:0.49722\n",
      "[287]\ttrain-auc:0.92707\teval-auc:0.49852\n",
      "[288]\ttrain-auc:0.92651\teval-auc:0.49902\n",
      "[289]\ttrain-auc:0.92535\teval-auc:0.49644\n",
      "[290]\ttrain-auc:0.92659\teval-auc:0.49670\n",
      "[291]\ttrain-auc:0.92769\teval-auc:0.49791\n",
      "[292]\ttrain-auc:0.92855\teval-auc:0.49573\n",
      "[293]\ttrain-auc:0.92797\teval-auc:0.49904\n",
      "[294]\ttrain-auc:0.92711\teval-auc:0.49829\n",
      "[295]\ttrain-auc:0.92609\teval-auc:0.49243\n",
      "[296]\ttrain-auc:0.92707\teval-auc:0.49455\n",
      "[297]\ttrain-auc:0.92707\teval-auc:0.49642\n",
      "[298]\ttrain-auc:0.92823\teval-auc:0.49946\n",
      "[299]\ttrain-auc:0.92885\teval-auc:0.50377\n",
      "[0]\ttrain-auc:0.92387\teval-auc:0.76041\n",
      "[1]\ttrain-auc:0.95103\teval-auc:0.83149\n",
      "[2]\ttrain-auc:0.95185\teval-auc:0.83185\n",
      "[3]\ttrain-auc:0.95211\teval-auc:0.83056\n",
      "[4]\ttrain-auc:0.95271\teval-auc:0.83444\n",
      "[5]\ttrain-auc:0.95283\teval-auc:0.83369\n",
      "[6]\ttrain-auc:0.95387\teval-auc:0.83510\n",
      "[7]\ttrain-auc:0.95874\teval-auc:0.85590\n",
      "[8]\ttrain-auc:0.95835\teval-auc:0.85615\n",
      "[9]\ttrain-auc:0.95839\teval-auc:0.85794\n",
      "[10]\ttrain-auc:0.95939\teval-auc:0.85628\n",
      "[11]\ttrain-auc:0.95978\teval-auc:0.85622\n",
      "[12]\ttrain-auc:0.95944\teval-auc:0.86384\n",
      "[13]\ttrain-auc:0.95925\teval-auc:0.86075\n",
      "[14]\ttrain-auc:0.95969\teval-auc:0.86014\n",
      "[15]\ttrain-auc:0.95964\teval-auc:0.86032\n",
      "[16]\ttrain-auc:0.95975\teval-auc:0.86150\n",
      "[17]\ttrain-auc:0.95983\teval-auc:0.86084\n",
      "[18]\ttrain-auc:0.95973\teval-auc:0.86171\n",
      "[19]\ttrain-auc:0.95989\teval-auc:0.86143\n",
      "[20]\ttrain-auc:0.95999\teval-auc:0.86184\n",
      "[21]\ttrain-auc:0.96036\teval-auc:0.86139\n",
      "[22]\ttrain-auc:0.96065\teval-auc:0.86107\n",
      "[23]\ttrain-auc:0.96094\teval-auc:0.86100\n",
      "[24]\ttrain-auc:0.96102\teval-auc:0.86080\n",
      "[25]\ttrain-auc:0.96098\teval-auc:0.85998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\ttrain-auc:0.96155\teval-auc:0.86069\n",
      "[27]\ttrain-auc:0.96176\teval-auc:0.85971\n",
      "[28]\ttrain-auc:0.96149\teval-auc:0.85985\n",
      "[29]\ttrain-auc:0.96175\teval-auc:0.86041\n",
      "[30]\ttrain-auc:0.96191\teval-auc:0.86010\n",
      "[31]\ttrain-auc:0.96226\teval-auc:0.86019\n",
      "[32]\ttrain-auc:0.96225\teval-auc:0.86109\n",
      "[33]\ttrain-auc:0.96242\teval-auc:0.86128\n",
      "[34]\ttrain-auc:0.96290\teval-auc:0.85987\n",
      "[35]\ttrain-auc:0.96275\teval-auc:0.86041\n",
      "[36]\ttrain-auc:0.96283\teval-auc:0.85987\n",
      "[37]\ttrain-auc:0.96315\teval-auc:0.86016\n",
      "[38]\ttrain-auc:0.96314\teval-auc:0.86089\n",
      "[39]\ttrain-auc:0.96316\teval-auc:0.86059\n",
      "[40]\ttrain-auc:0.96340\teval-auc:0.86064\n",
      "[41]\ttrain-auc:0.96329\teval-auc:0.86014\n",
      "[42]\ttrain-auc:0.96341\teval-auc:0.85903\n",
      "[43]\ttrain-auc:0.96353\teval-auc:0.85871\n",
      "[44]\ttrain-auc:0.96354\teval-auc:0.85907\n",
      "[45]\ttrain-auc:0.96342\teval-auc:0.85916\n",
      "[46]\ttrain-auc:0.96401\teval-auc:0.84764\n",
      "[47]\ttrain-auc:0.96419\teval-auc:0.84814\n",
      "[48]\ttrain-auc:0.96415\teval-auc:0.84732\n",
      "[49]\ttrain-auc:0.96435\teval-auc:0.84714\n",
      "[50]\ttrain-auc:0.96410\teval-auc:0.84782\n",
      "[51]\ttrain-auc:0.96433\teval-auc:0.84714\n",
      "[52]\ttrain-auc:0.96442\teval-auc:0.84678\n",
      "[53]\ttrain-auc:0.96456\teval-auc:0.84651\n",
      "[54]\ttrain-auc:0.96446\teval-auc:0.84859\n",
      "[55]\ttrain-auc:0.96469\teval-auc:0.84850\n",
      "[56]\ttrain-auc:0.96512\teval-auc:0.84823\n",
      "[57]\ttrain-auc:0.96495\teval-auc:0.84796\n",
      "[58]\ttrain-auc:0.96514\teval-auc:0.84660\n",
      "[59]\ttrain-auc:0.96604\teval-auc:0.84905\n",
      "[60]\ttrain-auc:0.96592\teval-auc:0.84973\n",
      "[61]\ttrain-auc:0.96593\teval-auc:0.84932\n",
      "[62]\ttrain-auc:0.96583\teval-auc:0.84957\n",
      "[63]\ttrain-auc:0.96584\teval-auc:0.84948\n",
      "[64]\ttrain-auc:0.96605\teval-auc:0.84943\n",
      "[65]\ttrain-auc:0.96617\teval-auc:0.84834\n",
      "[66]\ttrain-auc:0.96632\teval-auc:0.84862\n",
      "[67]\ttrain-auc:0.96625\teval-auc:0.84907\n",
      "[68]\ttrain-auc:0.96653\teval-auc:0.85066\n",
      "[69]\ttrain-auc:0.96667\teval-auc:0.85152\n",
      "[70]\ttrain-auc:0.96698\teval-auc:0.85025\n",
      "[71]\ttrain-auc:0.96729\teval-auc:0.85011\n",
      "[72]\ttrain-auc:0.96724\teval-auc:0.85116\n",
      "[73]\ttrain-auc:0.96732\teval-auc:0.85002\n",
      "[74]\ttrain-auc:0.96721\teval-auc:0.85002\n",
      "[75]\ttrain-auc:0.96732\teval-auc:0.84975\n",
      "[76]\ttrain-auc:0.96761\teval-auc:0.84635\n",
      "[77]\ttrain-auc:0.96756\teval-auc:0.84839\n",
      "[78]\ttrain-auc:0.96770\teval-auc:0.84839\n",
      "[79]\ttrain-auc:0.96788\teval-auc:0.84871\n",
      "[80]\ttrain-auc:0.96808\teval-auc:0.84789\n",
      "[81]\ttrain-auc:0.96802\teval-auc:0.84816\n",
      "[82]\ttrain-auc:0.96802\teval-auc:0.84653\n",
      "[83]\ttrain-auc:0.96826\teval-auc:0.84678\n",
      "[84]\ttrain-auc:0.96809\teval-auc:0.84691\n",
      "[85]\ttrain-auc:0.96819\teval-auc:0.84682\n",
      "[86]\ttrain-auc:0.96803\teval-auc:0.84333\n",
      "[87]\ttrain-auc:0.96801\teval-auc:0.84315\n",
      "[88]\ttrain-auc:0.96836\teval-auc:0.84242\n",
      "[89]\ttrain-auc:0.96833\teval-auc:0.84233\n",
      "[90]\ttrain-auc:0.96831\teval-auc:0.84251\n",
      "[91]\ttrain-auc:0.96843\teval-auc:0.84242\n",
      "[92]\ttrain-auc:0.96847\teval-auc:0.84256\n",
      "[93]\ttrain-auc:0.96837\teval-auc:0.84328\n",
      "[94]\ttrain-auc:0.96877\teval-auc:0.84111\n",
      "[95]\ttrain-auc:0.96870\teval-auc:0.84269\n",
      "[96]\ttrain-auc:0.96876\teval-auc:0.84524\n",
      "[97]\ttrain-auc:0.96876\teval-auc:0.84360\n",
      "[98]\ttrain-auc:0.96891\teval-auc:0.84465\n",
      "[99]\ttrain-auc:0.96924\teval-auc:0.84465\n",
      "[100]\ttrain-auc:0.96913\teval-auc:0.84501\n",
      "[101]\ttrain-auc:0.96926\teval-auc:0.84823\n",
      "[102]\ttrain-auc:0.96940\teval-auc:0.84803\n",
      "[103]\ttrain-auc:0.96940\teval-auc:0.84930\n",
      "[104]\ttrain-auc:0.96976\teval-auc:0.84898\n",
      "[105]\ttrain-auc:0.96959\teval-auc:0.84875\n",
      "[106]\ttrain-auc:0.96959\teval-auc:0.84844\n",
      "[107]\ttrain-auc:0.96972\teval-auc:0.84589\n",
      "[108]\ttrain-auc:0.97001\teval-auc:0.85134\n",
      "[109]\ttrain-auc:0.96983\teval-auc:0.85129\n",
      "[110]\ttrain-auc:0.97015\teval-auc:0.85238\n",
      "[111]\ttrain-auc:0.97028\teval-auc:0.85229\n",
      "[112]\ttrain-auc:0.97030\teval-auc:0.85179\n",
      "[113]\ttrain-auc:0.97030\teval-auc:0.85179\n",
      "[114]\ttrain-auc:0.97009\teval-auc:0.85211\n",
      "[115]\ttrain-auc:0.97027\teval-auc:0.85252\n",
      "[116]\ttrain-auc:0.97047\teval-auc:0.85225\n",
      "[117]\ttrain-auc:0.97059\teval-auc:0.84701\n",
      "[118]\ttrain-auc:0.97030\teval-auc:0.84619\n",
      "[119]\ttrain-auc:0.97046\teval-auc:0.84560\n",
      "[120]\ttrain-auc:0.97042\teval-auc:0.84605\n",
      "[121]\ttrain-auc:0.97060\teval-auc:0.84646\n",
      "[122]\ttrain-auc:0.97042\teval-auc:0.84637\n",
      "[123]\ttrain-auc:0.97075\teval-auc:0.84555\n",
      "[124]\ttrain-auc:0.97090\teval-auc:0.84546\n",
      "[125]\ttrain-auc:0.97096\teval-auc:0.84465\n",
      "[126]\ttrain-auc:0.97109\teval-auc:0.84664\n",
      "[127]\ttrain-auc:0.97094\teval-auc:0.84669\n",
      "[128]\ttrain-auc:0.97115\teval-auc:0.84773\n",
      "[129]\ttrain-auc:0.97142\teval-auc:0.84755\n",
      "[130]\ttrain-auc:0.97123\teval-auc:0.84757\n",
      "[131]\ttrain-auc:0.97130\teval-auc:0.84712\n",
      "[132]\ttrain-auc:0.97114\teval-auc:0.85247\n",
      "[133]\ttrain-auc:0.97138\teval-auc:0.85234\n",
      "[134]\ttrain-auc:0.97145\teval-auc:0.84458\n",
      "[135]\ttrain-auc:0.97146\teval-auc:0.84807\n",
      "[136]\ttrain-auc:0.97178\teval-auc:0.85166\n",
      "[137]\ttrain-auc:0.97156\teval-auc:0.85166\n",
      "[138]\ttrain-auc:0.97179\teval-auc:0.85034\n",
      "[139]\ttrain-auc:0.97164\teval-auc:0.85111\n",
      "[140]\ttrain-auc:0.97186\teval-auc:0.85016\n",
      "[141]\ttrain-auc:0.97203\teval-auc:0.84957\n",
      "[142]\ttrain-auc:0.97235\teval-auc:0.84857\n",
      "[143]\ttrain-auc:0.97225\teval-auc:0.84943\n",
      "[144]\ttrain-auc:0.97242\teval-auc:0.85034\n",
      "[145]\ttrain-auc:0.97222\teval-auc:0.85043\n",
      "[146]\ttrain-auc:0.97218\teval-auc:0.85079\n",
      "[147]\ttrain-auc:0.97213\teval-auc:0.85084\n",
      "[148]\ttrain-auc:0.97206\teval-auc:0.84603\n",
      "[149]\ttrain-auc:0.97208\teval-auc:0.84648\n",
      "[150]\ttrain-auc:0.97205\teval-auc:0.84485\n",
      "[151]\ttrain-auc:0.97236\teval-auc:0.84943\n",
      "[152]\ttrain-auc:0.97234\teval-auc:0.84934\n",
      "[153]\ttrain-auc:0.97237\teval-auc:0.84984\n",
      "[154]\ttrain-auc:0.97234\teval-auc:0.85016\n",
      "[155]\ttrain-auc:0.97225\teval-auc:0.85075\n",
      "[156]\ttrain-auc:0.97252\teval-auc:0.85193\n",
      "[157]\ttrain-auc:0.97230\teval-auc:0.85111\n",
      "[158]\ttrain-auc:0.97222\teval-auc:0.85175\n",
      "[159]\ttrain-auc:0.97243\teval-auc:0.85134\n",
      "[160]\ttrain-auc:0.97249\teval-auc:0.85157\n",
      "[161]\ttrain-auc:0.97253\teval-auc:0.85206\n",
      "[162]\ttrain-auc:0.97250\teval-auc:0.85329\n",
      "[163]\ttrain-auc:0.97242\teval-auc:0.85311\n",
      "[164]\ttrain-auc:0.97275\teval-auc:0.85238\n",
      "[165]\ttrain-auc:0.97283\teval-auc:0.85411\n",
      "[166]\ttrain-auc:0.97284\teval-auc:0.85456\n",
      "[167]\ttrain-auc:0.97313\teval-auc:0.85470\n",
      "[168]\ttrain-auc:0.97320\teval-auc:0.85438\n",
      "[169]\ttrain-auc:0.97335\teval-auc:0.85433\n",
      "[170]\ttrain-auc:0.97329\teval-auc:0.85520\n",
      "[171]\ttrain-auc:0.97362\teval-auc:0.85356\n",
      "[172]\ttrain-auc:0.97361\teval-auc:0.85338\n",
      "[173]\ttrain-auc:0.97358\teval-auc:0.85333\n",
      "[174]\ttrain-auc:0.97382\teval-auc:0.85238\n",
      "[175]\ttrain-auc:0.97365\teval-auc:0.85261\n",
      "[176]\ttrain-auc:0.97368\teval-auc:0.85138\n",
      "[177]\ttrain-auc:0.97350\teval-auc:0.85261\n",
      "[178]\ttrain-auc:0.97366\teval-auc:0.85256\n",
      "[179]\ttrain-auc:0.97370\teval-auc:0.85270\n",
      "[180]\ttrain-auc:0.97389\teval-auc:0.85279\n",
      "[181]\ttrain-auc:0.97389\teval-auc:0.85157\n",
      "[182]\ttrain-auc:0.97380\teval-auc:0.85197\n",
      "[183]\ttrain-auc:0.97387\teval-auc:0.85016\n",
      "[184]\ttrain-auc:0.97378\teval-auc:0.85052\n",
      "[185]\ttrain-auc:0.97398\teval-auc:0.85016\n",
      "[186]\ttrain-auc:0.97384\teval-auc:0.85147\n",
      "[187]\ttrain-auc:0.97392\teval-auc:0.85020\n",
      "[188]\ttrain-auc:0.97408\teval-auc:0.85166\n",
      "[189]\ttrain-auc:0.97384\teval-auc:0.85202\n",
      "[190]\ttrain-auc:0.97384\teval-auc:0.85202\n",
      "[191]\ttrain-auc:0.97424\teval-auc:0.85256\n",
      "[192]\ttrain-auc:0.97412\teval-auc:0.85261\n",
      "[193]\ttrain-auc:0.97437\teval-auc:0.85256\n",
      "[194]\ttrain-auc:0.97437\teval-auc:0.85256\n",
      "[195]\ttrain-auc:0.97410\teval-auc:0.85429\n",
      "[196]\ttrain-auc:0.97415\teval-auc:0.85452\n",
      "[197]\ttrain-auc:0.97426\teval-auc:0.85306\n",
      "[198]\ttrain-auc:0.97418\teval-auc:0.85411\n",
      "[199]\ttrain-auc:0.97445\teval-auc:0.85161\n",
      "[200]\ttrain-auc:0.97433\teval-auc:0.85284\n",
      "[201]\ttrain-auc:0.97451\teval-auc:0.85211\n",
      "[202]\ttrain-auc:0.97463\teval-auc:0.85329\n",
      "[203]\ttrain-auc:0.97487\teval-auc:0.85134\n",
      "[204]\ttrain-auc:0.97507\teval-auc:0.85107\n",
      "[205]\ttrain-auc:0.97501\teval-auc:0.85243\n",
      "[206]\ttrain-auc:0.97499\teval-auc:0.85447\n",
      "[207]\ttrain-auc:0.97504\teval-auc:0.85470\n",
      "[208]\ttrain-auc:0.97500\teval-auc:0.85365\n",
      "[209]\ttrain-auc:0.97523\teval-auc:0.85415\n",
      "[210]\ttrain-auc:0.97508\teval-auc:0.85579\n",
      "[211]\ttrain-auc:0.97508\teval-auc:0.85579\n",
      "[212]\ttrain-auc:0.97535\teval-auc:0.85406\n",
      "[213]\ttrain-auc:0.97537\teval-auc:0.85347\n",
      "[214]\ttrain-auc:0.97522\teval-auc:0.85420\n",
      "[215]\ttrain-auc:0.97521\teval-auc:0.85383\n",
      "[216]\ttrain-auc:0.97529\teval-auc:0.85352\n",
      "[217]\ttrain-auc:0.97520\teval-auc:0.85574\n",
      "[218]\ttrain-auc:0.97551\teval-auc:0.85542\n",
      "[219]\ttrain-auc:0.97551\teval-auc:0.85542\n",
      "[220]\ttrain-auc:0.97561\teval-auc:0.85560\n",
      "[221]\ttrain-auc:0.97561\teval-auc:0.85560\n",
      "[222]\ttrain-auc:0.97573\teval-auc:0.85601\n",
      "[223]\ttrain-auc:0.97579\teval-auc:0.85651\n",
      "[224]\ttrain-auc:0.97585\teval-auc:0.85533\n",
      "[225]\ttrain-auc:0.97605\teval-auc:0.85610\n",
      "[226]\ttrain-auc:0.97606\teval-auc:0.85633\n",
      "[227]\ttrain-auc:0.97624\teval-auc:0.85692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[228]\ttrain-auc:0.97608\teval-auc:0.85628\n",
      "[229]\ttrain-auc:0.97630\teval-auc:0.85465\n",
      "[230]\ttrain-auc:0.97619\teval-auc:0.85406\n",
      "[231]\ttrain-auc:0.97619\teval-auc:0.85406\n",
      "[232]\ttrain-auc:0.97623\teval-auc:0.84948\n",
      "[233]\ttrain-auc:0.97667\teval-auc:0.85238\n",
      "[234]\ttrain-auc:0.97667\teval-auc:0.85238\n",
      "[235]\ttrain-auc:0.97645\teval-auc:0.85265\n",
      "[236]\ttrain-auc:0.97664\teval-auc:0.85215\n",
      "[237]\ttrain-auc:0.97651\teval-auc:0.85270\n",
      "[238]\ttrain-auc:0.97671\teval-auc:0.85288\n",
      "[239]\ttrain-auc:0.97678\teval-auc:0.85352\n",
      "[240]\ttrain-auc:0.97706\teval-auc:0.85379\n",
      "[241]\ttrain-auc:0.97678\teval-auc:0.85374\n",
      "[242]\ttrain-auc:0.97705\teval-auc:0.85401\n",
      "[243]\ttrain-auc:0.97674\teval-auc:0.85411\n",
      "[244]\ttrain-auc:0.97667\teval-auc:0.85393\n",
      "[245]\ttrain-auc:0.97680\teval-auc:0.85370\n",
      "[246]\ttrain-auc:0.97676\teval-auc:0.85393\n",
      "[247]\ttrain-auc:0.97706\teval-auc:0.85411\n",
      "[248]\ttrain-auc:0.97705\teval-auc:0.85547\n",
      "[249]\ttrain-auc:0.97686\teval-auc:0.85274\n",
      "[250]\ttrain-auc:0.97674\teval-auc:0.85229\n",
      "[251]\ttrain-auc:0.97679\teval-auc:0.85252\n",
      "[252]\ttrain-auc:0.97683\teval-auc:0.85111\n",
      "[253]\ttrain-auc:0.97657\teval-auc:0.85138\n",
      "[254]\ttrain-auc:0.97665\teval-auc:0.85052\n",
      "[255]\ttrain-auc:0.97705\teval-auc:0.85093\n",
      "[256]\ttrain-auc:0.97706\teval-auc:0.85125\n",
      "[257]\ttrain-auc:0.97679\teval-auc:0.85061\n",
      "[258]\ttrain-auc:0.97711\teval-auc:0.84975\n",
      "[259]\ttrain-auc:0.97713\teval-auc:0.84998\n",
      "[260]\ttrain-auc:0.97736\teval-auc:0.85079\n",
      "[261]\ttrain-auc:0.97716\teval-auc:0.85075\n",
      "[262]\ttrain-auc:0.97739\teval-auc:0.85157\n",
      "[263]\ttrain-auc:0.97747\teval-auc:0.85247\n",
      "[264]\ttrain-auc:0.97741\teval-auc:0.85247\n",
      "[265]\ttrain-auc:0.97773\teval-auc:0.85057\n",
      "[266]\ttrain-auc:0.97794\teval-auc:0.85138\n",
      "[267]\ttrain-auc:0.97788\teval-auc:0.85206\n",
      "[268]\ttrain-auc:0.97779\teval-auc:0.85288\n",
      "[269]\ttrain-auc:0.97766\teval-auc:0.85215\n",
      "[270]\ttrain-auc:0.97767\teval-auc:0.85075\n",
      "[271]\ttrain-auc:0.97787\teval-auc:0.85070\n",
      "[272]\ttrain-auc:0.97762\teval-auc:0.85089\n",
      "[273]\ttrain-auc:0.97783\teval-auc:0.85079\n",
      "[274]\ttrain-auc:0.97779\teval-auc:0.85111\n",
      "[275]\ttrain-auc:0.97783\teval-auc:0.85188\n",
      "[276]\ttrain-auc:0.97783\teval-auc:0.85193\n",
      "[277]\ttrain-auc:0.97802\teval-auc:0.85206\n",
      "[278]\ttrain-auc:0.97780\teval-auc:0.85234\n",
      "[279]\ttrain-auc:0.97784\teval-auc:0.85352\n",
      "[280]\ttrain-auc:0.97784\teval-auc:0.85352\n",
      "[281]\ttrain-auc:0.97757\teval-auc:0.85324\n",
      "[282]\ttrain-auc:0.97757\teval-auc:0.85324\n",
      "[283]\ttrain-auc:0.97778\teval-auc:0.85306\n",
      "[284]\ttrain-auc:0.97776\teval-auc:0.85352\n",
      "[285]\ttrain-auc:0.97804\teval-auc:0.85274\n",
      "[286]\ttrain-auc:0.97804\teval-auc:0.85274\n",
      "[287]\ttrain-auc:0.97813\teval-auc:0.85247\n",
      "[288]\ttrain-auc:0.97808\teval-auc:0.85311\n",
      "[289]\ttrain-auc:0.97803\teval-auc:0.85261\n",
      "[290]\ttrain-auc:0.97773\teval-auc:0.85125\n",
      "[291]\ttrain-auc:0.97805\teval-auc:0.85066\n",
      "[292]\ttrain-auc:0.97820\teval-auc:0.84943\n",
      "[293]\ttrain-auc:0.97832\teval-auc:0.84902\n",
      "[294]\ttrain-auc:0.97822\teval-auc:0.84921\n",
      "[295]\ttrain-auc:0.97838\teval-auc:0.84889\n",
      "[296]\ttrain-auc:0.97848\teval-auc:0.84862\n",
      "[297]\ttrain-auc:0.97835\teval-auc:0.84911\n",
      "[298]\ttrain-auc:0.97821\teval-auc:0.84789\n",
      "[299]\ttrain-auc:0.97828\teval-auc:0.84848\n",
      "[0]\ttrain-auc:0.61000\teval-auc:0.55231\n",
      "[1]\ttrain-auc:0.63295\teval-auc:0.53786\n",
      "[2]\ttrain-auc:0.65152\teval-auc:0.56380\n",
      "[3]\ttrain-auc:0.67687\teval-auc:0.59538\n",
      "[4]\ttrain-auc:0.69738\teval-auc:0.61213\n",
      "[5]\ttrain-auc:0.70458\teval-auc:0.62976\n",
      "[6]\ttrain-auc:0.71191\teval-auc:0.63528\n",
      "[7]\ttrain-auc:0.72012\teval-auc:0.64123\n",
      "[8]\ttrain-auc:0.72333\teval-auc:0.65221\n",
      "[9]\ttrain-auc:0.72832\teval-auc:0.65240\n",
      "[10]\ttrain-auc:0.73318\teval-auc:0.64837\n",
      "[11]\ttrain-auc:0.73406\teval-auc:0.63617\n",
      "[12]\ttrain-auc:0.73938\teval-auc:0.63229\n",
      "[13]\ttrain-auc:0.74156\teval-auc:0.62716\n",
      "[14]\ttrain-auc:0.74429\teval-auc:0.62261\n",
      "[15]\ttrain-auc:0.75131\teval-auc:0.62747\n",
      "[16]\ttrain-auc:0.75534\teval-auc:0.63060\n",
      "[17]\ttrain-auc:0.76102\teval-auc:0.63331\n",
      "[18]\ttrain-auc:0.76537\teval-auc:0.63932\n",
      "[19]\ttrain-auc:0.76714\teval-auc:0.63502\n",
      "[20]\ttrain-auc:0.76940\teval-auc:0.63537\n",
      "[21]\ttrain-auc:0.77392\teval-auc:0.63763\n",
      "[22]\ttrain-auc:0.77948\teval-auc:0.64398\n",
      "[23]\ttrain-auc:0.78266\teval-auc:0.63968\n",
      "[24]\ttrain-auc:0.78624\teval-auc:0.63951\n",
      "[25]\ttrain-auc:0.79006\teval-auc:0.64197\n",
      "[26]\ttrain-auc:0.79255\teval-auc:0.64308\n",
      "[27]\ttrain-auc:0.79456\teval-auc:0.63909\n",
      "[28]\ttrain-auc:0.79733\teval-auc:0.64155\n",
      "[29]\ttrain-auc:0.80024\teval-auc:0.64776\n",
      "[30]\ttrain-auc:0.80079\teval-auc:0.64613\n",
      "[31]\ttrain-auc:0.80340\teval-auc:0.64346\n",
      "[32]\ttrain-auc:0.80739\teval-auc:0.63529\n",
      "[33]\ttrain-auc:0.80951\teval-auc:0.64144\n",
      "[34]\ttrain-auc:0.81088\teval-auc:0.64708\n",
      "[35]\ttrain-auc:0.81443\teval-auc:0.64955\n",
      "[36]\ttrain-auc:0.81656\teval-auc:0.65027\n",
      "[37]\ttrain-auc:0.81973\teval-auc:0.65019\n",
      "[38]\ttrain-auc:0.82088\teval-auc:0.64842\n",
      "[39]\ttrain-auc:0.82113\teval-auc:0.65027\n",
      "[40]\ttrain-auc:0.82106\teval-auc:0.65288\n",
      "[41]\ttrain-auc:0.82340\teval-auc:0.65745\n",
      "[42]\ttrain-auc:0.82728\teval-auc:0.65989\n",
      "[43]\ttrain-auc:0.82974\teval-auc:0.65541\n",
      "[44]\ttrain-auc:0.82932\teval-auc:0.65720\n",
      "[45]\ttrain-auc:0.83011\teval-auc:0.65169\n",
      "[46]\ttrain-auc:0.83224\teval-auc:0.65222\n",
      "[47]\ttrain-auc:0.83444\teval-auc:0.65142\n",
      "[48]\ttrain-auc:0.83752\teval-auc:0.65379\n",
      "[49]\ttrain-auc:0.83868\teval-auc:0.65544\n",
      "[50]\ttrain-auc:0.84028\teval-auc:0.65269\n",
      "[51]\ttrain-auc:0.84040\teval-auc:0.65519\n",
      "[52]\ttrain-auc:0.84374\teval-auc:0.65514\n",
      "[53]\ttrain-auc:0.84305\teval-auc:0.65654\n",
      "[54]\ttrain-auc:0.84395\teval-auc:0.66087\n",
      "[55]\ttrain-auc:0.84679\teval-auc:0.65633\n",
      "[56]\ttrain-auc:0.84723\teval-auc:0.66165\n",
      "[57]\ttrain-auc:0.84804\teval-auc:0.66188\n",
      "[58]\ttrain-auc:0.85037\teval-auc:0.66657\n",
      "[59]\ttrain-auc:0.85033\teval-auc:0.66943\n",
      "[60]\ttrain-auc:0.85179\teval-auc:0.66262\n",
      "[61]\ttrain-auc:0.85533\teval-auc:0.65891\n",
      "[62]\ttrain-auc:0.85727\teval-auc:0.65173\n",
      "[63]\ttrain-auc:0.85868\teval-auc:0.65129\n",
      "[64]\ttrain-auc:0.85956\teval-auc:0.65474\n",
      "[65]\ttrain-auc:0.85994\teval-auc:0.65801\n",
      "[66]\ttrain-auc:0.86230\teval-auc:0.65657\n",
      "[67]\ttrain-auc:0.86313\teval-auc:0.65360\n",
      "[68]\ttrain-auc:0.86325\teval-auc:0.65465\n",
      "[69]\ttrain-auc:0.86352\teval-auc:0.65111\n",
      "[70]\ttrain-auc:0.86329\teval-auc:0.65544\n",
      "[71]\ttrain-auc:0.86680\teval-auc:0.65633\n",
      "[72]\ttrain-auc:0.86999\teval-auc:0.65663\n",
      "[73]\ttrain-auc:0.87105\teval-auc:0.65490\n",
      "[74]\ttrain-auc:0.87250\teval-auc:0.65144\n",
      "[75]\ttrain-auc:0.87335\teval-auc:0.64918\n",
      "[76]\ttrain-auc:0.87628\teval-auc:0.65168\n",
      "[77]\ttrain-auc:0.87870\teval-auc:0.65383\n",
      "[78]\ttrain-auc:0.88134\teval-auc:0.65270\n",
      "[79]\ttrain-auc:0.88217\teval-auc:0.65262\n",
      "[80]\ttrain-auc:0.88316\teval-auc:0.65046\n",
      "[81]\ttrain-auc:0.88440\teval-auc:0.65193\n",
      "[82]\ttrain-auc:0.88460\teval-auc:0.65471\n",
      "[83]\ttrain-auc:0.88530\teval-auc:0.65899\n",
      "[84]\ttrain-auc:0.88632\teval-auc:0.65910\n",
      "[85]\ttrain-auc:0.88641\teval-auc:0.65741\n",
      "[86]\ttrain-auc:0.88585\teval-auc:0.65868\n",
      "[87]\ttrain-auc:0.88639\teval-auc:0.66510\n",
      "[88]\ttrain-auc:0.88796\teval-auc:0.66463\n",
      "[89]\ttrain-auc:0.88868\teval-auc:0.66323\n",
      "[90]\ttrain-auc:0.89120\teval-auc:0.65827\n",
      "[91]\ttrain-auc:0.89190\teval-auc:0.65954\n",
      "[92]\ttrain-auc:0.89382\teval-auc:0.66092\n",
      "[93]\ttrain-auc:0.89521\teval-auc:0.66288\n",
      "[94]\ttrain-auc:0.89428\teval-auc:0.66519\n",
      "[95]\ttrain-auc:0.89410\teval-auc:0.66339\n",
      "[96]\ttrain-auc:0.89607\teval-auc:0.65797\n",
      "[97]\ttrain-auc:0.89660\teval-auc:0.65858\n",
      "[98]\ttrain-auc:0.89692\teval-auc:0.65592\n",
      "[99]\ttrain-auc:0.89949\teval-auc:0.65160\n",
      "[100]\ttrain-auc:0.90109\teval-auc:0.65097\n",
      "[101]\ttrain-auc:0.90069\teval-auc:0.64769\n",
      "[102]\ttrain-auc:0.90042\teval-auc:0.65245\n",
      "[103]\ttrain-auc:0.90133\teval-auc:0.65469\n",
      "[104]\ttrain-auc:0.90243\teval-auc:0.65408\n",
      "[105]\ttrain-auc:0.90287\teval-auc:0.65311\n",
      "[106]\ttrain-auc:0.90523\teval-auc:0.65353\n",
      "[107]\ttrain-auc:0.90585\teval-auc:0.65413\n",
      "[108]\ttrain-auc:0.90586\teval-auc:0.65348\n",
      "[109]\ttrain-auc:0.90672\teval-auc:0.65546\n",
      "[110]\ttrain-auc:0.90575\teval-auc:0.65416\n",
      "[111]\ttrain-auc:0.90628\teval-auc:0.65534\n",
      "[112]\ttrain-auc:0.90690\teval-auc:0.65022\n",
      "[113]\ttrain-auc:0.90693\teval-auc:0.65322\n",
      "[114]\ttrain-auc:0.90740\teval-auc:0.65221\n",
      "[115]\ttrain-auc:0.90924\teval-auc:0.64900\n",
      "[116]\ttrain-auc:0.91127\teval-auc:0.64980\n",
      "[117]\ttrain-auc:0.91236\teval-auc:0.64762\n",
      "[118]\ttrain-auc:0.91302\teval-auc:0.64734\n",
      "[119]\ttrain-auc:0.91233\teval-auc:0.65059\n",
      "[120]\ttrain-auc:0.91212\teval-auc:0.64922\n",
      "[121]\ttrain-auc:0.91180\teval-auc:0.65032\n",
      "[122]\ttrain-auc:0.91291\teval-auc:0.64971\n",
      "[123]\ttrain-auc:0.91367\teval-auc:0.65351\n",
      "[124]\ttrain-auc:0.91413\teval-auc:0.65519\n",
      "[125]\ttrain-auc:0.91571\teval-auc:0.65352\n",
      "[126]\ttrain-auc:0.91608\teval-auc:0.65255\n",
      "[127]\ttrain-auc:0.91824\teval-auc:0.65040\n",
      "[128]\ttrain-auc:0.91821\teval-auc:0.65112\n",
      "[129]\ttrain-auc:0.91925\teval-auc:0.65233\n",
      "[130]\ttrain-auc:0.91953\teval-auc:0.65516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131]\ttrain-auc:0.92017\teval-auc:0.65238\n",
      "[132]\ttrain-auc:0.92091\teval-auc:0.64761\n",
      "[133]\ttrain-auc:0.92126\teval-auc:0.64707\n",
      "[134]\ttrain-auc:0.92082\teval-auc:0.64649\n",
      "[135]\ttrain-auc:0.92044\teval-auc:0.65228\n",
      "[136]\ttrain-auc:0.92142\teval-auc:0.65545\n",
      "[137]\ttrain-auc:0.91998\teval-auc:0.65554\n",
      "[138]\ttrain-auc:0.92049\teval-auc:0.65611\n",
      "[139]\ttrain-auc:0.92113\teval-auc:0.65532\n",
      "[140]\ttrain-auc:0.92191\teval-auc:0.65552\n",
      "[141]\ttrain-auc:0.92338\teval-auc:0.65312\n",
      "[142]\ttrain-auc:0.92388\teval-auc:0.65428\n",
      "[143]\ttrain-auc:0.92446\teval-auc:0.65461\n",
      "[144]\ttrain-auc:0.92503\teval-auc:0.65647\n",
      "[145]\ttrain-auc:0.92505\teval-auc:0.65734\n",
      "[146]\ttrain-auc:0.92495\teval-auc:0.65799\n",
      "[147]\ttrain-auc:0.92558\teval-auc:0.65709\n",
      "[148]\ttrain-auc:0.92669\teval-auc:0.65140\n",
      "[149]\ttrain-auc:0.92754\teval-auc:0.65146\n",
      "[150]\ttrain-auc:0.92703\teval-auc:0.65133\n",
      "[151]\ttrain-auc:0.92590\teval-auc:0.65006\n",
      "[152]\ttrain-auc:0.92817\teval-auc:0.64385\n",
      "[153]\ttrain-auc:0.92707\teval-auc:0.64600\n",
      "[154]\ttrain-auc:0.92786\teval-auc:0.64601\n",
      "[155]\ttrain-auc:0.92890\teval-auc:0.64488\n",
      "[156]\ttrain-auc:0.92972\teval-auc:0.64455\n",
      "[157]\ttrain-auc:0.92920\teval-auc:0.64176\n",
      "[158]\ttrain-auc:0.93115\teval-auc:0.64451\n",
      "[159]\ttrain-auc:0.93189\teval-auc:0.64090\n",
      "[160]\ttrain-auc:0.93331\teval-auc:0.64265\n",
      "[161]\ttrain-auc:0.93351\teval-auc:0.64506\n",
      "[162]\ttrain-auc:0.93428\teval-auc:0.64112\n",
      "[163]\ttrain-auc:0.93561\teval-auc:0.63810\n",
      "[164]\ttrain-auc:0.93607\teval-auc:0.63663\n",
      "[165]\ttrain-auc:0.93625\teval-auc:0.63282\n",
      "[166]\ttrain-auc:0.93724\teval-auc:0.63026\n",
      "[167]\ttrain-auc:0.93743\teval-auc:0.63369\n",
      "[168]\ttrain-auc:0.93728\teval-auc:0.63330\n",
      "[169]\ttrain-auc:0.93851\teval-auc:0.63467\n",
      "[170]\ttrain-auc:0.93877\teval-auc:0.63646\n",
      "[171]\ttrain-auc:0.93961\teval-auc:0.63894\n",
      "[172]\ttrain-auc:0.94045\teval-auc:0.63616\n",
      "[173]\ttrain-auc:0.94133\teval-auc:0.63473\n",
      "[174]\ttrain-auc:0.94051\teval-auc:0.63471\n",
      "[175]\ttrain-auc:0.93973\teval-auc:0.63358\n",
      "[176]\ttrain-auc:0.93989\teval-auc:0.63663\n",
      "[177]\ttrain-auc:0.94095\teval-auc:0.63597\n",
      "[178]\ttrain-auc:0.94116\teval-auc:0.63512\n",
      "[179]\ttrain-auc:0.94199\teval-auc:0.63729\n",
      "[180]\ttrain-auc:0.94245\teval-auc:0.63767\n",
      "[181]\ttrain-auc:0.94406\teval-auc:0.63647\n",
      "[182]\ttrain-auc:0.94392\teval-auc:0.63555\n",
      "[183]\ttrain-auc:0.94389\teval-auc:0.63655\n",
      "[184]\ttrain-auc:0.94360\teval-auc:0.63522\n",
      "[185]\ttrain-auc:0.94319\teval-auc:0.63996\n",
      "[186]\ttrain-auc:0.94353\teval-auc:0.63903\n",
      "[187]\ttrain-auc:0.94516\teval-auc:0.63886\n",
      "[188]\ttrain-auc:0.94499\teval-auc:0.63919\n",
      "[189]\ttrain-auc:0.94588\teval-auc:0.63752\n",
      "[190]\ttrain-auc:0.94491\teval-auc:0.63997\n",
      "[191]\ttrain-auc:0.94555\teval-auc:0.64048\n",
      "[192]\ttrain-auc:0.94515\teval-auc:0.64030\n",
      "[193]\ttrain-auc:0.94533\teval-auc:0.64134\n",
      "[194]\ttrain-auc:0.94580\teval-auc:0.64295\n",
      "[195]\ttrain-auc:0.94607\teval-auc:0.64187\n",
      "[196]\ttrain-auc:0.94660\teval-auc:0.64321\n",
      "[197]\ttrain-auc:0.94714\teval-auc:0.64333\n",
      "[198]\ttrain-auc:0.94744\teval-auc:0.64240\n",
      "[199]\ttrain-auc:0.94798\teval-auc:0.64121\n",
      "[200]\ttrain-auc:0.94855\teval-auc:0.64192\n",
      "[201]\ttrain-auc:0.94960\teval-auc:0.64206\n",
      "[202]\ttrain-auc:0.94951\teval-auc:0.64212\n",
      "[203]\ttrain-auc:0.94837\teval-auc:0.64386\n",
      "[204]\ttrain-auc:0.94895\teval-auc:0.64380\n",
      "[205]\ttrain-auc:0.95000\teval-auc:0.64206\n",
      "[206]\ttrain-auc:0.95008\teval-auc:0.64592\n",
      "[207]\ttrain-auc:0.95031\teval-auc:0.64532\n",
      "[208]\ttrain-auc:0.95083\teval-auc:0.64791\n",
      "[209]\ttrain-auc:0.95207\teval-auc:0.64695\n",
      "[210]\ttrain-auc:0.95262\teval-auc:0.64413\n",
      "[211]\ttrain-auc:0.95228\teval-auc:0.64581\n",
      "[212]\ttrain-auc:0.95271\teval-auc:0.64435\n",
      "[213]\ttrain-auc:0.95271\teval-auc:0.64568\n",
      "[214]\ttrain-auc:0.95189\teval-auc:0.65047\n",
      "[215]\ttrain-auc:0.95208\teval-auc:0.64634\n",
      "[216]\ttrain-auc:0.95205\teval-auc:0.64480\n",
      "[217]\ttrain-auc:0.95275\teval-auc:0.64344\n",
      "[218]\ttrain-auc:0.95397\teval-auc:0.64330\n",
      "[219]\ttrain-auc:0.95466\teval-auc:0.64411\n",
      "[220]\ttrain-auc:0.95466\teval-auc:0.64609\n",
      "[221]\ttrain-auc:0.95483\teval-auc:0.64564\n",
      "[222]\ttrain-auc:0.95593\teval-auc:0.64626\n",
      "[223]\ttrain-auc:0.95570\teval-auc:0.64743\n",
      "[224]\ttrain-auc:0.95639\teval-auc:0.64520\n",
      "[225]\ttrain-auc:0.95604\teval-auc:0.64435\n",
      "[226]\ttrain-auc:0.95494\teval-auc:0.64470\n",
      "[227]\ttrain-auc:0.95554\teval-auc:0.64626\n",
      "[228]\ttrain-auc:0.95598\teval-auc:0.64600\n",
      "[229]\ttrain-auc:0.95629\teval-auc:0.64551\n",
      "[230]\ttrain-auc:0.95623\teval-auc:0.64518\n",
      "[231]\ttrain-auc:0.95643\teval-auc:0.64178\n",
      "[232]\ttrain-auc:0.95688\teval-auc:0.64415\n",
      "[233]\ttrain-auc:0.95698\teval-auc:0.64322\n",
      "[234]\ttrain-auc:0.95740\teval-auc:0.64248\n",
      "[235]\ttrain-auc:0.95901\teval-auc:0.63894\n",
      "[236]\ttrain-auc:0.95937\teval-auc:0.63755\n",
      "[237]\ttrain-auc:0.96018\teval-auc:0.63547\n",
      "[238]\ttrain-auc:0.96027\teval-auc:0.63653\n",
      "[239]\ttrain-auc:0.96044\teval-auc:0.64121\n",
      "[240]\ttrain-auc:0.96016\teval-auc:0.64022\n",
      "[241]\ttrain-auc:0.96054\teval-auc:0.64165\n",
      "[242]\ttrain-auc:0.96163\teval-auc:0.64397\n",
      "[243]\ttrain-auc:0.96223\teval-auc:0.64256\n",
      "[244]\ttrain-auc:0.96319\teval-auc:0.64185\n",
      "[245]\ttrain-auc:0.96293\teval-auc:0.64360\n",
      "[246]\ttrain-auc:0.96292\teval-auc:0.64305\n",
      "[247]\ttrain-auc:0.96283\teval-auc:0.64314\n",
      "[248]\ttrain-auc:0.96261\teval-auc:0.64277\n",
      "[249]\ttrain-auc:0.96259\teval-auc:0.64259\n",
      "[250]\ttrain-auc:0.96322\teval-auc:0.64437\n",
      "[251]\ttrain-auc:0.96264\teval-auc:0.64203\n",
      "[252]\ttrain-auc:0.96296\teval-auc:0.64335\n",
      "[253]\ttrain-auc:0.96322\teval-auc:0.64341\n",
      "[254]\ttrain-auc:0.96374\teval-auc:0.64206\n",
      "[255]\ttrain-auc:0.96356\teval-auc:0.64259\n",
      "[256]\ttrain-auc:0.96417\teval-auc:0.64594\n",
      "[257]\ttrain-auc:0.96473\teval-auc:0.64488\n",
      "[258]\ttrain-auc:0.96529\teval-auc:0.64399\n",
      "[259]\ttrain-auc:0.96505\teval-auc:0.64229\n",
      "[260]\ttrain-auc:0.96562\teval-auc:0.64021\n",
      "[261]\ttrain-auc:0.96579\teval-auc:0.64123\n",
      "[262]\ttrain-auc:0.96540\teval-auc:0.64364\n",
      "[263]\ttrain-auc:0.96524\teval-auc:0.64123\n",
      "[264]\ttrain-auc:0.96493\teval-auc:0.64014\n",
      "[265]\ttrain-auc:0.96542\teval-auc:0.64226\n",
      "[266]\ttrain-auc:0.96642\teval-auc:0.64145\n",
      "[267]\ttrain-auc:0.96636\teval-auc:0.64181\n",
      "[268]\ttrain-auc:0.96701\teval-auc:0.64093\n",
      "[269]\ttrain-auc:0.96734\teval-auc:0.64029\n",
      "[270]\ttrain-auc:0.96790\teval-auc:0.63880\n",
      "[271]\ttrain-auc:0.96779\teval-auc:0.64314\n",
      "[272]\ttrain-auc:0.96784\teval-auc:0.64035\n",
      "[273]\ttrain-auc:0.96854\teval-auc:0.64044\n",
      "[274]\ttrain-auc:0.96853\teval-auc:0.63868\n",
      "[275]\ttrain-auc:0.96860\teval-auc:0.63895\n",
      "[276]\ttrain-auc:0.96856\teval-auc:0.63958\n",
      "[277]\ttrain-auc:0.96896\teval-auc:0.63919\n",
      "[278]\ttrain-auc:0.96960\teval-auc:0.63868\n",
      "[279]\ttrain-auc:0.97001\teval-auc:0.64008\n",
      "[280]\ttrain-auc:0.97016\teval-auc:0.63792\n",
      "[281]\ttrain-auc:0.97006\teval-auc:0.63768\n",
      "[282]\ttrain-auc:0.97010\teval-auc:0.63685\n",
      "[283]\ttrain-auc:0.97006\teval-auc:0.63867\n",
      "[284]\ttrain-auc:0.97085\teval-auc:0.63790\n",
      "[285]\ttrain-auc:0.97144\teval-auc:0.63925\n",
      "[286]\ttrain-auc:0.97204\teval-auc:0.63788\n",
      "[287]\ttrain-auc:0.97256\teval-auc:0.63509\n",
      "[288]\ttrain-auc:0.97218\teval-auc:0.63721\n",
      "[289]\ttrain-auc:0.97214\teval-auc:0.63628\n",
      "[290]\ttrain-auc:0.97181\teval-auc:0.63912\n",
      "[291]\ttrain-auc:0.97215\teval-auc:0.63760\n",
      "[292]\ttrain-auc:0.97201\teval-auc:0.64035\n",
      "[293]\ttrain-auc:0.97187\teval-auc:0.63777\n",
      "[294]\ttrain-auc:0.97240\teval-auc:0.63799\n",
      "[295]\ttrain-auc:0.97263\teval-auc:0.63608\n",
      "[296]\ttrain-auc:0.97296\teval-auc:0.63573\n",
      "[297]\ttrain-auc:0.97322\teval-auc:0.63649\n",
      "[298]\ttrain-auc:0.97265\teval-auc:0.64018\n",
      "[299]\ttrain-auc:0.97323\teval-auc:0.64156\n",
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "atom_inputs_1 (InputLayer)      (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_1 (InputLayer)      (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_1 (InputLayer)      (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_inputs_2 (InputLayer)      (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_2 (InputLayer)      (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_2 (InputLayer)      (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_inputs_3 (InputLayer)      (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_3 (InputLayer)      (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_3 (InputLayer)      (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "labels_inputs_1 (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_23 (Model)                [(None, 96), (None,  841984      atom_inputs_1[0][0]              \n",
      "                                                                 bond_inputs_1[0][0]              \n",
      "                                                                 edge_inputs_1[0][0]              \n",
      "                                                                 atom_inputs_2[0][0]              \n",
      "                                                                 bond_inputs_2[0][0]              \n",
      "                                                                 edge_inputs_2[0][0]              \n",
      "                                                                 atom_inputs_3[0][0]              \n",
      "                                                                 bond_inputs_3[0][0]              \n",
      "                                                                 edge_inputs_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "labels_inputs_2 (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "labels_inputs_3 (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Protein_1 (Concatenate)         (None, 97)           0           labels_inputs_1[0][0]            \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Protein_2 (Concatenate)         (None, 97)           0           labels_inputs_2[0][0]            \n",
      "                                                                 model_23[1][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "Protein_3 (Concatenate)         (None, 97)           0           labels_inputs_3[0][0]            \n",
      "                                                                 model_23[1][2]                   \n",
      "==================================================================================================\n",
      "Total params: 841,984\n",
      "Trainable params: 840,384\n",
      "Non-trainable params: 1,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "95/95 [==============================] - 25s 262ms/step - loss: 1.4780 - Protein_1_loss: 0.4926 - Protein_2_loss: 0.4940 - Protein_3_loss: 0.4914\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 16s 166ms/step - loss: 1.4656 - Protein_1_loss: 0.4914 - Protein_2_loss: 0.4849 - Protein_3_loss: 0.4893\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 16s 168ms/step - loss: 1.4579 - Protein_1_loss: 0.4907 - Protein_2_loss: 0.4751 - Protein_3_loss: 0.4921\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4582 - Protein_1_loss: 0.4904 - Protein_2_loss: 0.4776 - Protein_3_loss: 0.4902\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4550 - Protein_1_loss: 0.4915 - Protein_2_loss: 0.4734 - Protein_3_loss: 0.4902\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4547 - Protein_1_loss: 0.4915 - Protein_2_loss: 0.4726 - Protein_3_loss: 0.4905\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4451 - Protein_1_loss: 0.4917 - Protein_2_loss: 0.4627 - Protein_3_loss: 0.4906\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4370 - Protein_1_loss: 0.4924 - Protein_2_loss: 0.4533 - Protein_3_loss: 0.4913\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4371 - Protein_1_loss: 0.4929 - Protein_2_loss: 0.4536 - Protein_3_loss: 0.4906\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4273 - Protein_1_loss: 0.4929 - Protein_2_loss: 0.4435 - Protein_3_loss: 0.4909\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4276 - Protein_1_loss: 0.4931 - Protein_2_loss: 0.4440 - Protein_3_loss: 0.4905\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4183 - Protein_1_loss: 0.4924 - Protein_2_loss: 0.4353 - Protein_3_loss: 0.4906\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4116 - Protein_1_loss: 0.4934 - Protein_2_loss: 0.4276 - Protein_3_loss: 0.4905\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4129 - Protein_1_loss: 0.4928 - Protein_2_loss: 0.4299 - Protein_3_loss: 0.4902\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4101 - Protein_1_loss: 0.4922 - Protein_2_loss: 0.4273 - Protein_3_loss: 0.4906\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.4172 - Protein_1_loss: 0.4923 - Protein_2_loss: 0.4347 - Protein_3_loss: 0.4901\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.3961 - Protein_1_loss: 0.4924 - Protein_2_loss: 0.4131 - Protein_3_loss: 0.4906\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 16s 167ms/step - loss: 1.3925 - Protein_1_loss: 0.4924 - Protein_2_loss: 0.4095 - Protein_3_loss: 0.4907\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 16s 168ms/step - loss: 1.3877 - Protein_1_loss: 0.4918 - Protein_2_loss: 0.4052 - Protein_3_loss: 0.4906\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 16s 168ms/step - loss: 1.3809 - Protein_1_loss: 0.4922 - Protein_2_loss: 0.3985 - Protein_3_loss: 0.4903\n",
      "[0]\ttrain-auc:0.63218\teval-auc:0.60549\n",
      "[1]\ttrain-auc:0.64840\teval-auc:0.61447\n",
      "[2]\ttrain-auc:0.65854\teval-auc:0.61435\n",
      "[3]\ttrain-auc:0.66650\teval-auc:0.61184\n",
      "[4]\ttrain-auc:0.67629\teval-auc:0.59724\n",
      "[5]\ttrain-auc:0.67861\teval-auc:0.60907\n",
      "[6]\ttrain-auc:0.68221\teval-auc:0.60583\n",
      "[7]\ttrain-auc:0.69046\teval-auc:0.60623\n",
      "[8]\ttrain-auc:0.69315\teval-auc:0.60225\n",
      "[9]\ttrain-auc:0.69830\teval-auc:0.60712\n",
      "[10]\ttrain-auc:0.70530\teval-auc:0.61468\n",
      "[11]\ttrain-auc:0.70588\teval-auc:0.61309\n",
      "[12]\ttrain-auc:0.70910\teval-auc:0.61501\n",
      "[13]\ttrain-auc:0.71251\teval-auc:0.61150\n",
      "[14]\ttrain-auc:0.71615\teval-auc:0.62149\n",
      "[15]\ttrain-auc:0.71917\teval-auc:0.62850\n",
      "[16]\ttrain-auc:0.72199\teval-auc:0.62614\n",
      "[17]\ttrain-auc:0.72398\teval-auc:0.62079\n",
      "[18]\ttrain-auc:0.72733\teval-auc:0.62297\n",
      "[19]\ttrain-auc:0.73052\teval-auc:0.62215\n",
      "[20]\ttrain-auc:0.73221\teval-auc:0.62118\n",
      "[21]\ttrain-auc:0.73540\teval-auc:0.61600\n",
      "[22]\ttrain-auc:0.73903\teval-auc:0.61833\n",
      "[23]\ttrain-auc:0.74168\teval-auc:0.61926\n",
      "[24]\ttrain-auc:0.74398\teval-auc:0.62188\n",
      "[25]\ttrain-auc:0.74756\teval-auc:0.62426\n",
      "[26]\ttrain-auc:0.75134\teval-auc:0.61618\n",
      "[27]\ttrain-auc:0.75413\teval-auc:0.62684\n",
      "[28]\ttrain-auc:0.75786\teval-auc:0.63030\n",
      "[29]\ttrain-auc:0.75973\teval-auc:0.62491\n",
      "[30]\ttrain-auc:0.76176\teval-auc:0.62546\n",
      "[31]\ttrain-auc:0.76325\teval-auc:0.62387\n",
      "[32]\ttrain-auc:0.76521\teval-auc:0.62234\n",
      "[33]\ttrain-auc:0.76703\teval-auc:0.62135\n",
      "[34]\ttrain-auc:0.77126\teval-auc:0.62336\n",
      "[35]\ttrain-auc:0.77245\teval-auc:0.62344\n",
      "[36]\ttrain-auc:0.77307\teval-auc:0.61782\n",
      "[37]\ttrain-auc:0.77536\teval-auc:0.61634\n",
      "[38]\ttrain-auc:0.77482\teval-auc:0.61518\n",
      "[39]\ttrain-auc:0.77593\teval-auc:0.61589\n",
      "[40]\ttrain-auc:0.77825\teval-auc:0.61912\n",
      "[41]\ttrain-auc:0.77963\teval-auc:0.61412\n",
      "[42]\ttrain-auc:0.78147\teval-auc:0.61789\n",
      "[43]\ttrain-auc:0.78319\teval-auc:0.61739\n",
      "[44]\ttrain-auc:0.78453\teval-auc:0.61427\n",
      "[45]\ttrain-auc:0.78602\teval-auc:0.61643\n",
      "[46]\ttrain-auc:0.78424\teval-auc:0.61533\n",
      "[47]\ttrain-auc:0.78562\teval-auc:0.61816\n",
      "[48]\ttrain-auc:0.78839\teval-auc:0.62157\n",
      "[49]\ttrain-auc:0.79169\teval-auc:0.62478\n",
      "[50]\ttrain-auc:0.79145\teval-auc:0.62032\n",
      "[51]\ttrain-auc:0.79431\teval-auc:0.61909\n",
      "[52]\ttrain-auc:0.79705\teval-auc:0.61744\n",
      "[53]\ttrain-auc:0.79829\teval-auc:0.61670\n",
      "[54]\ttrain-auc:0.80039\teval-auc:0.61595\n",
      "[55]\ttrain-auc:0.80131\teval-auc:0.62121\n",
      "[56]\ttrain-auc:0.80215\teval-auc:0.62432\n",
      "[57]\ttrain-auc:0.80561\teval-auc:0.62677\n",
      "[58]\ttrain-auc:0.80425\teval-auc:0.62329\n",
      "[59]\ttrain-auc:0.80552\teval-auc:0.62050\n",
      "[60]\ttrain-auc:0.80685\teval-auc:0.61804\n",
      "[61]\ttrain-auc:0.80897\teval-auc:0.61620\n",
      "[62]\ttrain-auc:0.81241\teval-auc:0.61518\n",
      "[63]\ttrain-auc:0.81285\teval-auc:0.62035\n",
      "[64]\ttrain-auc:0.81269\teval-auc:0.62073\n",
      "[65]\ttrain-auc:0.81472\teval-auc:0.62315\n",
      "[66]\ttrain-auc:0.81508\teval-auc:0.62177\n",
      "[67]\ttrain-auc:0.81492\teval-auc:0.61887\n",
      "[68]\ttrain-auc:0.81764\teval-auc:0.61919\n",
      "[69]\ttrain-auc:0.81778\teval-auc:0.62414\n",
      "[70]\ttrain-auc:0.82273\teval-auc:0.61989\n",
      "[71]\ttrain-auc:0.82379\teval-auc:0.61840\n",
      "[72]\ttrain-auc:0.82416\teval-auc:0.61697\n",
      "[73]\ttrain-auc:0.82451\teval-auc:0.61617\n",
      "[74]\ttrain-auc:0.82622\teval-auc:0.61964\n",
      "[75]\ttrain-auc:0.82552\teval-auc:0.61792\n",
      "[76]\ttrain-auc:0.82805\teval-auc:0.61867\n",
      "[77]\ttrain-auc:0.83084\teval-auc:0.61235\n",
      "[78]\ttrain-auc:0.83021\teval-auc:0.61432\n",
      "[79]\ttrain-auc:0.83451\teval-auc:0.61447\n",
      "[80]\ttrain-auc:0.83610\teval-auc:0.61291\n",
      "[81]\ttrain-auc:0.83648\teval-auc:0.61202\n",
      "[82]\ttrain-auc:0.83448\teval-auc:0.61177\n",
      "[83]\ttrain-auc:0.83459\teval-auc:0.61174\n",
      "[84]\ttrain-auc:0.83536\teval-auc:0.61020\n",
      "[85]\ttrain-auc:0.83672\teval-auc:0.60981\n",
      "[86]\ttrain-auc:0.83625\teval-auc:0.61273\n",
      "[87]\ttrain-auc:0.83617\teval-auc:0.61311\n",
      "[88]\ttrain-auc:0.83686\teval-auc:0.60985\n",
      "[89]\ttrain-auc:0.83856\teval-auc:0.60988\n",
      "[90]\ttrain-auc:0.83993\teval-auc:0.61291\n",
      "[91]\ttrain-auc:0.84230\teval-auc:0.61211\n",
      "[92]\ttrain-auc:0.84459\teval-auc:0.60737\n",
      "[93]\ttrain-auc:0.84378\teval-auc:0.60541\n",
      "[94]\ttrain-auc:0.84601\teval-auc:0.60642\n",
      "[95]\ttrain-auc:0.84711\teval-auc:0.60611\n",
      "[96]\ttrain-auc:0.84734\teval-auc:0.60232\n",
      "[97]\ttrain-auc:0.84635\teval-auc:0.60124\n",
      "[98]\ttrain-auc:0.84774\teval-auc:0.60241\n",
      "[99]\ttrain-auc:0.84864\teval-auc:0.60361\n",
      "[100]\ttrain-auc:0.85000\teval-auc:0.60501\n",
      "[101]\ttrain-auc:0.85092\teval-auc:0.59849\n",
      "[102]\ttrain-auc:0.85115\teval-auc:0.59719\n",
      "[103]\ttrain-auc:0.85172\teval-auc:0.59678\n",
      "[104]\ttrain-auc:0.85126\teval-auc:0.59695\n",
      "[105]\ttrain-auc:0.85511\teval-auc:0.60180\n",
      "[106]\ttrain-auc:0.85664\teval-auc:0.60208\n",
      "[107]\ttrain-auc:0.85709\teval-auc:0.60234\n",
      "[108]\ttrain-auc:0.85762\teval-auc:0.60393\n",
      "[109]\ttrain-auc:0.85953\teval-auc:0.60487\n",
      "[110]\ttrain-auc:0.86037\teval-auc:0.60414\n",
      "[111]\ttrain-auc:0.86017\teval-auc:0.60059\n",
      "[112]\ttrain-auc:0.86264\teval-auc:0.60340\n",
      "[113]\ttrain-auc:0.86279\teval-auc:0.60353\n",
      "[114]\ttrain-auc:0.86381\teval-auc:0.60531\n",
      "[115]\ttrain-auc:0.86499\teval-auc:0.60741\n",
      "[116]\ttrain-auc:0.86512\teval-auc:0.60443\n",
      "[117]\ttrain-auc:0.86411\teval-auc:0.60628\n",
      "[118]\ttrain-auc:0.86652\teval-auc:0.60489\n",
      "[119]\ttrain-auc:0.86656\teval-auc:0.60101\n",
      "[120]\ttrain-auc:0.86695\teval-auc:0.59971\n",
      "[121]\ttrain-auc:0.86610\teval-auc:0.60229\n",
      "[122]\ttrain-auc:0.86587\teval-auc:0.59940\n",
      "[123]\ttrain-auc:0.86736\teval-auc:0.60237\n",
      "[124]\ttrain-auc:0.86853\teval-auc:0.59913\n",
      "[125]\ttrain-auc:0.87001\teval-auc:0.60309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[126]\ttrain-auc:0.87291\teval-auc:0.60063\n",
      "[127]\ttrain-auc:0.87231\teval-auc:0.60011\n",
      "[128]\ttrain-auc:0.87479\teval-auc:0.59890\n",
      "[129]\ttrain-auc:0.87523\teval-auc:0.59803\n",
      "[130]\ttrain-auc:0.87553\teval-auc:0.59405\n",
      "[131]\ttrain-auc:0.87612\teval-auc:0.59873\n",
      "[132]\ttrain-auc:0.87470\teval-auc:0.59255\n",
      "[133]\ttrain-auc:0.87501\teval-auc:0.59034\n",
      "[134]\ttrain-auc:0.87722\teval-auc:0.59076\n",
      "[135]\ttrain-auc:0.87639\teval-auc:0.58910\n",
      "[136]\ttrain-auc:0.87761\teval-auc:0.59152\n",
      "[137]\ttrain-auc:0.87783\teval-auc:0.59093\n",
      "[138]\ttrain-auc:0.88008\teval-auc:0.58938\n",
      "[139]\ttrain-auc:0.88001\teval-auc:0.58999\n",
      "[140]\ttrain-auc:0.88016\teval-auc:0.59192\n",
      "[141]\ttrain-auc:0.88247\teval-auc:0.58949\n",
      "[142]\ttrain-auc:0.88229\teval-auc:0.58487\n",
      "[143]\ttrain-auc:0.88265\teval-auc:0.58779\n",
      "[144]\ttrain-auc:0.88339\teval-auc:0.58849\n",
      "[145]\ttrain-auc:0.88345\teval-auc:0.58935\n",
      "[146]\ttrain-auc:0.88429\teval-auc:0.58996\n",
      "[147]\ttrain-auc:0.88536\teval-auc:0.58896\n",
      "[148]\ttrain-auc:0.88800\teval-auc:0.59197\n",
      "[149]\ttrain-auc:0.88791\teval-auc:0.59224\n",
      "[150]\ttrain-auc:0.88812\teval-auc:0.59437\n",
      "[151]\ttrain-auc:0.88950\teval-auc:0.59205\n",
      "[152]\ttrain-auc:0.89030\teval-auc:0.59506\n",
      "[153]\ttrain-auc:0.89065\teval-auc:0.58999\n",
      "[154]\ttrain-auc:0.89152\teval-auc:0.59383\n",
      "[155]\ttrain-auc:0.88930\teval-auc:0.59295\n",
      "[156]\ttrain-auc:0.89092\teval-auc:0.59222\n",
      "[157]\ttrain-auc:0.89064\teval-auc:0.59007\n",
      "[158]\ttrain-auc:0.89217\teval-auc:0.59074\n",
      "[159]\ttrain-auc:0.89263\teval-auc:0.59024\n",
      "[160]\ttrain-auc:0.89495\teval-auc:0.59181\n",
      "[161]\ttrain-auc:0.89357\teval-auc:0.58954\n",
      "[162]\ttrain-auc:0.89497\teval-auc:0.59020\n",
      "[163]\ttrain-auc:0.89515\teval-auc:0.59188\n",
      "[164]\ttrain-auc:0.89378\teval-auc:0.59061\n",
      "[165]\ttrain-auc:0.89440\teval-auc:0.58722\n",
      "[166]\ttrain-auc:0.89334\teval-auc:0.58615\n",
      "[167]\ttrain-auc:0.89604\teval-auc:0.58860\n",
      "[168]\ttrain-auc:0.89489\teval-auc:0.58526\n",
      "[169]\ttrain-auc:0.89465\teval-auc:0.58296\n",
      "[170]\ttrain-auc:0.89712\teval-auc:0.57964\n",
      "[171]\ttrain-auc:0.89758\teval-auc:0.58158\n",
      "[172]\ttrain-auc:0.89697\teval-auc:0.58489\n",
      "[173]\ttrain-auc:0.89795\teval-auc:0.58507\n",
      "[174]\ttrain-auc:0.89742\teval-auc:0.58641\n",
      "[175]\ttrain-auc:0.89806\teval-auc:0.58151\n",
      "[176]\ttrain-auc:0.90014\teval-auc:0.58194\n",
      "[177]\ttrain-auc:0.90123\teval-auc:0.57979\n",
      "[178]\ttrain-auc:0.90265\teval-auc:0.57980\n",
      "[179]\ttrain-auc:0.90099\teval-auc:0.58077\n",
      "[180]\ttrain-auc:0.90331\teval-auc:0.58313\n",
      "[181]\ttrain-auc:0.90439\teval-auc:0.58217\n",
      "[182]\ttrain-auc:0.90332\teval-auc:0.58338\n",
      "[183]\ttrain-auc:0.90300\teval-auc:0.58286\n",
      "[184]\ttrain-auc:0.90318\teval-auc:0.58355\n",
      "[185]\ttrain-auc:0.90270\teval-auc:0.58259\n",
      "[186]\ttrain-auc:0.90406\teval-auc:0.58192\n",
      "[187]\ttrain-auc:0.90465\teval-auc:0.58580\n",
      "[188]\ttrain-auc:0.90438\teval-auc:0.58689\n",
      "[189]\ttrain-auc:0.90580\teval-auc:0.58694\n",
      "[190]\ttrain-auc:0.90443\teval-auc:0.58640\n",
      "[191]\ttrain-auc:0.90638\teval-auc:0.58402\n",
      "[192]\ttrain-auc:0.90806\teval-auc:0.58488\n",
      "[193]\ttrain-auc:0.90878\teval-auc:0.58683\n",
      "[194]\ttrain-auc:0.90867\teval-auc:0.58935\n",
      "[195]\ttrain-auc:0.90785\teval-auc:0.58993\n",
      "[196]\ttrain-auc:0.90900\teval-auc:0.58708\n",
      "[197]\ttrain-auc:0.90807\teval-auc:0.58678\n",
      "[198]\ttrain-auc:0.90876\teval-auc:0.58745\n",
      "[199]\ttrain-auc:0.91024\teval-auc:0.58782\n",
      "[200]\ttrain-auc:0.90842\teval-auc:0.58875\n",
      "[201]\ttrain-auc:0.90754\teval-auc:0.58892\n",
      "[202]\ttrain-auc:0.90819\teval-auc:0.58799\n",
      "[203]\ttrain-auc:0.90891\teval-auc:0.59107\n",
      "[204]\ttrain-auc:0.91035\teval-auc:0.59229\n",
      "[205]\ttrain-auc:0.91123\teval-auc:0.58940\n",
      "[206]\ttrain-auc:0.91186\teval-auc:0.58906\n",
      "[207]\ttrain-auc:0.91138\teval-auc:0.58711\n",
      "[208]\ttrain-auc:0.91294\teval-auc:0.58917\n",
      "[209]\ttrain-auc:0.91232\teval-auc:0.59151\n",
      "[210]\ttrain-auc:0.91377\teval-auc:0.59127\n",
      "[211]\ttrain-auc:0.91332\teval-auc:0.59169\n",
      "[212]\ttrain-auc:0.91365\teval-auc:0.59192\n",
      "[213]\ttrain-auc:0.91553\teval-auc:0.58989\n",
      "[214]\ttrain-auc:0.91306\teval-auc:0.59000\n",
      "[215]\ttrain-auc:0.91523\teval-auc:0.58929\n",
      "[216]\ttrain-auc:0.91450\teval-auc:0.58749\n",
      "[217]\ttrain-auc:0.91478\teval-auc:0.59053\n",
      "[218]\ttrain-auc:0.91610\teval-auc:0.58764\n",
      "[219]\ttrain-auc:0.91560\teval-auc:0.58638\n",
      "[220]\ttrain-auc:0.91826\teval-auc:0.58537\n",
      "[221]\ttrain-auc:0.91802\teval-auc:0.58697\n",
      "[222]\ttrain-auc:0.91831\teval-auc:0.58739\n",
      "[223]\ttrain-auc:0.91754\teval-auc:0.58967\n",
      "[224]\ttrain-auc:0.91881\teval-auc:0.58783\n",
      "[225]\ttrain-auc:0.91874\teval-auc:0.58681\n",
      "[226]\ttrain-auc:0.92082\teval-auc:0.58810\n",
      "[227]\ttrain-auc:0.92106\teval-auc:0.58738\n",
      "[228]\ttrain-auc:0.92182\teval-auc:0.58789\n",
      "[229]\ttrain-auc:0.92261\teval-auc:0.58577\n",
      "[230]\ttrain-auc:0.92266\teval-auc:0.58595\n",
      "[231]\ttrain-auc:0.92231\teval-auc:0.58600\n",
      "[232]\ttrain-auc:0.92322\teval-auc:0.59061\n",
      "[233]\ttrain-auc:0.92317\teval-auc:0.58980\n",
      "[234]\ttrain-auc:0.92277\teval-auc:0.59157\n",
      "[235]\ttrain-auc:0.92318\teval-auc:0.58783\n",
      "[236]\ttrain-auc:0.92327\teval-auc:0.58762\n",
      "[237]\ttrain-auc:0.92413\teval-auc:0.58593\n",
      "[238]\ttrain-auc:0.92463\teval-auc:0.58554\n",
      "[239]\ttrain-auc:0.92590\teval-auc:0.58697\n",
      "[240]\ttrain-auc:0.92592\teval-auc:0.58418\n",
      "[241]\ttrain-auc:0.92558\teval-auc:0.58835\n",
      "[242]\ttrain-auc:0.92634\teval-auc:0.58784\n",
      "[243]\ttrain-auc:0.92682\teval-auc:0.58908\n",
      "[244]\ttrain-auc:0.92763\teval-auc:0.58838\n",
      "[245]\ttrain-auc:0.92706\teval-auc:0.58677\n",
      "[246]\ttrain-auc:0.92811\teval-auc:0.58664\n",
      "[247]\ttrain-auc:0.92844\teval-auc:0.58721\n",
      "[248]\ttrain-auc:0.92945\teval-auc:0.58926\n",
      "[249]\ttrain-auc:0.92901\teval-auc:0.58596\n",
      "[250]\ttrain-auc:0.92967\teval-auc:0.58808\n",
      "[251]\ttrain-auc:0.92920\teval-auc:0.58788\n",
      "[252]\ttrain-auc:0.92930\teval-auc:0.58699\n",
      "[253]\ttrain-auc:0.92851\teval-auc:0.58766\n",
      "[254]\ttrain-auc:0.92759\teval-auc:0.58932\n",
      "[255]\ttrain-auc:0.92870\teval-auc:0.59088\n",
      "[256]\ttrain-auc:0.92957\teval-auc:0.59251\n",
      "[257]\ttrain-auc:0.92994\teval-auc:0.59205\n",
      "[258]\ttrain-auc:0.92956\teval-auc:0.59169\n",
      "[259]\ttrain-auc:0.93081\teval-auc:0.59388\n",
      "[260]\ttrain-auc:0.93102\teval-auc:0.59028\n",
      "[261]\ttrain-auc:0.93188\teval-auc:0.59093\n",
      "[262]\ttrain-auc:0.93216\teval-auc:0.59315\n",
      "[263]\ttrain-auc:0.93061\teval-auc:0.59576\n",
      "[264]\ttrain-auc:0.93103\teval-auc:0.59333\n",
      "[265]\ttrain-auc:0.93162\teval-auc:0.59383\n",
      "[266]\ttrain-auc:0.93137\teval-auc:0.59282\n",
      "[267]\ttrain-auc:0.93138\teval-auc:0.59540\n",
      "[268]\ttrain-auc:0.93060\teval-auc:0.59251\n",
      "[269]\ttrain-auc:0.93266\teval-auc:0.59353\n",
      "[270]\ttrain-auc:0.93358\teval-auc:0.59219\n",
      "[271]\ttrain-auc:0.93354\teval-auc:0.59185\n",
      "[272]\ttrain-auc:0.93376\teval-auc:0.59039\n",
      "[273]\ttrain-auc:0.93480\teval-auc:0.59039\n",
      "[274]\ttrain-auc:0.93448\teval-auc:0.58657\n",
      "[275]\ttrain-auc:0.93477\teval-auc:0.58981\n",
      "[276]\ttrain-auc:0.93481\teval-auc:0.58825\n",
      "[277]\ttrain-auc:0.93529\teval-auc:0.58959\n",
      "[278]\ttrain-auc:0.93550\teval-auc:0.58940\n",
      "[279]\ttrain-auc:0.93753\teval-auc:0.58439\n",
      "[280]\ttrain-auc:0.93836\teval-auc:0.58499\n",
      "[281]\ttrain-auc:0.93676\teval-auc:0.58888\n",
      "[282]\ttrain-auc:0.93768\teval-auc:0.58813\n",
      "[283]\ttrain-auc:0.93739\teval-auc:0.58752\n",
      "[284]\ttrain-auc:0.93771\teval-auc:0.58729\n",
      "[285]\ttrain-auc:0.93807\teval-auc:0.58671\n",
      "[286]\ttrain-auc:0.93955\teval-auc:0.58477\n",
      "[287]\ttrain-auc:0.94072\teval-auc:0.58748\n",
      "[288]\ttrain-auc:0.94121\teval-auc:0.58665\n",
      "[289]\ttrain-auc:0.94058\teval-auc:0.58942\n",
      "[290]\ttrain-auc:0.94116\teval-auc:0.58737\n",
      "[291]\ttrain-auc:0.94027\teval-auc:0.58832\n",
      "[292]\ttrain-auc:0.93931\teval-auc:0.58931\n",
      "[293]\ttrain-auc:0.93924\teval-auc:0.59006\n",
      "[294]\ttrain-auc:0.93966\teval-auc:0.59229\n",
      "[295]\ttrain-auc:0.94076\teval-auc:0.59184\n",
      "[296]\ttrain-auc:0.94096\teval-auc:0.59243\n",
      "[297]\ttrain-auc:0.94154\teval-auc:0.59311\n",
      "[298]\ttrain-auc:0.94086\teval-auc:0.59202\n",
      "[299]\ttrain-auc:0.94120\teval-auc:0.58806\n",
      "[0]\ttrain-auc:0.91624\teval-auc:0.83349\n",
      "[1]\ttrain-auc:0.94612\teval-auc:0.84438\n",
      "[2]\ttrain-auc:0.95372\teval-auc:0.85820\n",
      "[3]\ttrain-auc:0.95474\teval-auc:0.85979\n",
      "[4]\ttrain-auc:0.95556\teval-auc:0.85792\n",
      "[5]\ttrain-auc:0.95744\teval-auc:0.85828\n",
      "[6]\ttrain-auc:0.95868\teval-auc:0.86063\n",
      "[7]\ttrain-auc:0.95900\teval-auc:0.85999\n",
      "[8]\ttrain-auc:0.96111\teval-auc:0.86259\n",
      "[9]\ttrain-auc:0.96130\teval-auc:0.86127\n",
      "[10]\ttrain-auc:0.96181\teval-auc:0.86151\n",
      "[11]\ttrain-auc:0.96272\teval-auc:0.86103\n",
      "[12]\ttrain-auc:0.96249\teval-auc:0.86083\n",
      "[13]\ttrain-auc:0.96279\teval-auc:0.86119\n",
      "[14]\ttrain-auc:0.96283\teval-auc:0.86093\n",
      "[15]\ttrain-auc:0.96287\teval-auc:0.86269\n",
      "[16]\ttrain-auc:0.96338\teval-auc:0.86328\n",
      "[17]\ttrain-auc:0.96393\teval-auc:0.86286\n",
      "[18]\ttrain-auc:0.96426\teval-auc:0.86420\n",
      "[19]\ttrain-auc:0.96517\teval-auc:0.86456\n",
      "[20]\ttrain-auc:0.96518\teval-auc:0.86490\n",
      "[21]\ttrain-auc:0.96576\teval-auc:0.86560\n",
      "[22]\ttrain-auc:0.96603\teval-auc:0.86478\n",
      "[23]\ttrain-auc:0.96586\teval-auc:0.86486\n",
      "[24]\ttrain-auc:0.96614\teval-auc:0.86289\n",
      "[25]\ttrain-auc:0.96660\teval-auc:0.86404\n",
      "[26]\ttrain-auc:0.96685\teval-auc:0.86372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27]\ttrain-auc:0.96676\teval-auc:0.86392\n",
      "[28]\ttrain-auc:0.96706\teval-auc:0.86396\n",
      "[29]\ttrain-auc:0.96762\teval-auc:0.86392\n",
      "[30]\ttrain-auc:0.96795\teval-auc:0.86344\n",
      "[31]\ttrain-auc:0.96858\teval-auc:0.86326\n",
      "[32]\ttrain-auc:0.96899\teval-auc:0.86185\n",
      "[33]\ttrain-auc:0.96930\teval-auc:0.86197\n",
      "[34]\ttrain-auc:0.96946\teval-auc:0.86253\n",
      "[35]\ttrain-auc:0.96960\teval-auc:0.86277\n",
      "[36]\ttrain-auc:0.96970\teval-auc:0.86247\n",
      "[37]\ttrain-auc:0.96965\teval-auc:0.86243\n",
      "[38]\ttrain-auc:0.96976\teval-auc:0.86207\n",
      "[39]\ttrain-auc:0.96994\teval-auc:0.86095\n",
      "[40]\ttrain-auc:0.97003\teval-auc:0.86255\n",
      "[41]\ttrain-auc:0.97038\teval-auc:0.86207\n",
      "[42]\ttrain-auc:0.97053\teval-auc:0.86163\n",
      "[43]\ttrain-auc:0.97046\teval-auc:0.86245\n",
      "[44]\ttrain-auc:0.97103\teval-auc:0.86294\n",
      "[45]\ttrain-auc:0.97118\teval-auc:0.86306\n",
      "[46]\ttrain-auc:0.97152\teval-auc:0.86161\n",
      "[47]\ttrain-auc:0.97142\teval-auc:0.86237\n",
      "[48]\ttrain-auc:0.97158\teval-auc:0.86233\n",
      "[49]\ttrain-auc:0.97149\teval-auc:0.86318\n",
      "[50]\ttrain-auc:0.97151\teval-auc:0.86362\n",
      "[51]\ttrain-auc:0.97138\teval-auc:0.86370\n",
      "[52]\ttrain-auc:0.97162\teval-auc:0.86378\n",
      "[53]\ttrain-auc:0.97174\teval-auc:0.86386\n",
      "[54]\ttrain-auc:0.97176\teval-auc:0.86462\n",
      "[55]\ttrain-auc:0.97170\teval-auc:0.86510\n",
      "[56]\ttrain-auc:0.97180\teval-auc:0.86478\n",
      "[57]\ttrain-auc:0.97190\teval-auc:0.86396\n",
      "[58]\ttrain-auc:0.97212\teval-auc:0.86420\n",
      "[59]\ttrain-auc:0.97233\teval-auc:0.86380\n",
      "[60]\ttrain-auc:0.97262\teval-auc:0.86235\n",
      "[61]\ttrain-auc:0.97293\teval-auc:0.86155\n",
      "[62]\ttrain-auc:0.97308\teval-auc:0.86085\n",
      "[63]\ttrain-auc:0.97333\teval-auc:0.86045\n",
      "[64]\ttrain-auc:0.97323\teval-auc:0.86161\n",
      "[65]\ttrain-auc:0.97323\teval-auc:0.86233\n",
      "[66]\ttrain-auc:0.97341\teval-auc:0.86277\n",
      "[67]\ttrain-auc:0.97369\teval-auc:0.86153\n",
      "[68]\ttrain-auc:0.97386\teval-auc:0.86281\n",
      "[69]\ttrain-auc:0.97394\teval-auc:0.86374\n",
      "[70]\ttrain-auc:0.97425\teval-auc:0.86422\n",
      "[71]\ttrain-auc:0.97447\teval-auc:0.86406\n",
      "[72]\ttrain-auc:0.97462\teval-auc:0.86422\n",
      "[73]\ttrain-auc:0.97508\teval-auc:0.86418\n",
      "[74]\ttrain-auc:0.97496\teval-auc:0.86434\n",
      "[75]\ttrain-auc:0.97531\teval-auc:0.86506\n",
      "[76]\ttrain-auc:0.97550\teval-auc:0.86578\n",
      "[77]\ttrain-auc:0.97528\teval-auc:0.86586\n",
      "[78]\ttrain-auc:0.97537\teval-auc:0.86546\n",
      "[79]\ttrain-auc:0.97576\teval-auc:0.86534\n",
      "[80]\ttrain-auc:0.97552\teval-auc:0.86578\n",
      "[81]\ttrain-auc:0.97599\teval-auc:0.86570\n",
      "[82]\ttrain-auc:0.97642\teval-auc:0.86474\n",
      "[83]\ttrain-auc:0.97624\teval-auc:0.86566\n",
      "[84]\ttrain-auc:0.97606\teval-auc:0.86504\n",
      "[85]\ttrain-auc:0.97618\teval-auc:0.86428\n",
      "[86]\ttrain-auc:0.97648\teval-auc:0.86352\n",
      "[87]\ttrain-auc:0.97644\teval-auc:0.86368\n",
      "[88]\ttrain-auc:0.97625\teval-auc:0.86348\n",
      "[89]\ttrain-auc:0.97628\teval-auc:0.86432\n",
      "[90]\ttrain-auc:0.97646\teval-auc:0.86392\n",
      "[91]\ttrain-auc:0.97676\teval-auc:0.86396\n",
      "[92]\ttrain-auc:0.97704\teval-auc:0.86261\n",
      "[93]\ttrain-auc:0.97715\teval-auc:0.86233\n",
      "[94]\ttrain-auc:0.97710\teval-auc:0.86221\n",
      "[95]\ttrain-auc:0.97697\teval-auc:0.86213\n",
      "[96]\ttrain-auc:0.97700\teval-auc:0.86213\n",
      "[97]\ttrain-auc:0.97747\teval-auc:0.86101\n",
      "[98]\ttrain-auc:0.97737\teval-auc:0.86053\n",
      "[99]\ttrain-auc:0.97720\teval-auc:0.86105\n",
      "[100]\ttrain-auc:0.97732\teval-auc:0.86005\n",
      "[101]\ttrain-auc:0.97774\teval-auc:0.85989\n",
      "[102]\ttrain-auc:0.97803\teval-auc:0.85933\n",
      "[103]\ttrain-auc:0.97838\teval-auc:0.85901\n",
      "[104]\ttrain-auc:0.97861\teval-auc:0.85865\n",
      "[105]\ttrain-auc:0.97852\teval-auc:0.85905\n",
      "[106]\ttrain-auc:0.97865\teval-auc:0.85877\n",
      "[107]\ttrain-auc:0.97882\teval-auc:0.85813\n",
      "[108]\ttrain-auc:0.97856\teval-auc:0.85845\n",
      "[109]\ttrain-auc:0.97871\teval-auc:0.85849\n",
      "[110]\ttrain-auc:0.97867\teval-auc:0.85877\n",
      "[111]\ttrain-auc:0.97882\teval-auc:0.85917\n",
      "[112]\ttrain-auc:0.97889\teval-auc:0.85889\n",
      "[113]\ttrain-auc:0.97879\teval-auc:0.85861\n",
      "[114]\ttrain-auc:0.97865\teval-auc:0.85897\n",
      "[115]\ttrain-auc:0.97893\teval-auc:0.85861\n",
      "[116]\ttrain-auc:0.97878\teval-auc:0.85849\n",
      "[117]\ttrain-auc:0.97878\teval-auc:0.85849\n",
      "[118]\ttrain-auc:0.97876\teval-auc:0.85804\n",
      "[119]\ttrain-auc:0.97867\teval-auc:0.85853\n",
      "[120]\ttrain-auc:0.97896\teval-auc:0.85913\n",
      "[121]\ttrain-auc:0.97922\teval-auc:0.85845\n",
      "[122]\ttrain-auc:0.97922\teval-auc:0.85901\n",
      "[123]\ttrain-auc:0.97924\teval-auc:0.85857\n",
      "[124]\ttrain-auc:0.97924\teval-auc:0.85857\n",
      "[125]\ttrain-auc:0.97942\teval-auc:0.85877\n",
      "[126]\ttrain-auc:0.97942\teval-auc:0.85877\n",
      "[127]\ttrain-auc:0.97919\teval-auc:0.85837\n",
      "[128]\ttrain-auc:0.97930\teval-auc:0.85849\n",
      "[129]\ttrain-auc:0.97912\teval-auc:0.85897\n",
      "[130]\ttrain-auc:0.97957\teval-auc:0.85897\n",
      "[131]\ttrain-auc:0.97965\teval-auc:0.85813\n",
      "[132]\ttrain-auc:0.97985\teval-auc:0.85780\n",
      "[133]\ttrain-auc:0.97989\teval-auc:0.85772\n",
      "[134]\ttrain-auc:0.98030\teval-auc:0.85808\n",
      "[135]\ttrain-auc:0.98037\teval-auc:0.85837\n",
      "[136]\ttrain-auc:0.98046\teval-auc:0.85696\n",
      "[137]\ttrain-auc:0.98052\teval-auc:0.85849\n",
      "[138]\ttrain-auc:0.98040\teval-auc:0.85885\n",
      "[139]\ttrain-auc:0.98020\teval-auc:0.85825\n",
      "[140]\ttrain-auc:0.98045\teval-auc:0.85692\n",
      "[141]\ttrain-auc:0.98073\teval-auc:0.85696\n",
      "[142]\ttrain-auc:0.98071\teval-auc:0.85692\n",
      "[143]\ttrain-auc:0.98129\teval-auc:0.85760\n",
      "[144]\ttrain-auc:0.98116\teval-auc:0.85732\n",
      "[145]\ttrain-auc:0.98094\teval-auc:0.85728\n",
      "[146]\ttrain-auc:0.98079\teval-auc:0.85752\n",
      "[147]\ttrain-auc:0.98117\teval-auc:0.85676\n",
      "[148]\ttrain-auc:0.98119\teval-auc:0.85596\n",
      "[149]\ttrain-auc:0.98131\teval-auc:0.85536\n",
      "[150]\ttrain-auc:0.98115\teval-auc:0.85560\n",
      "[151]\ttrain-auc:0.98089\teval-auc:0.85536\n",
      "[152]\ttrain-auc:0.98102\teval-auc:0.85708\n",
      "[153]\ttrain-auc:0.98131\teval-auc:0.85736\n",
      "[154]\ttrain-auc:0.98138\teval-auc:0.85752\n",
      "[155]\ttrain-auc:0.98140\teval-auc:0.85704\n",
      "[156]\ttrain-auc:0.98164\teval-auc:0.85680\n",
      "[157]\ttrain-auc:0.98157\teval-auc:0.85732\n",
      "[158]\ttrain-auc:0.98184\teval-auc:0.85752\n",
      "[159]\ttrain-auc:0.98191\teval-auc:0.85881\n",
      "[160]\ttrain-auc:0.98189\teval-auc:0.85744\n",
      "[161]\ttrain-auc:0.98191\teval-auc:0.85696\n",
      "[162]\ttrain-auc:0.98211\teval-auc:0.85672\n",
      "[163]\ttrain-auc:0.98224\teval-auc:0.85536\n",
      "[164]\ttrain-auc:0.98216\teval-auc:0.85576\n",
      "[165]\ttrain-auc:0.98236\teval-auc:0.85656\n",
      "[166]\ttrain-auc:0.98247\teval-auc:0.85576\n",
      "[167]\ttrain-auc:0.98252\teval-auc:0.85564\n",
      "[168]\ttrain-auc:0.98240\teval-auc:0.85628\n",
      "[169]\ttrain-auc:0.98225\teval-auc:0.85768\n",
      "[170]\ttrain-auc:0.98211\teval-auc:0.85833\n",
      "[171]\ttrain-auc:0.98213\teval-auc:0.85728\n",
      "[172]\ttrain-auc:0.98235\teval-auc:0.85696\n",
      "[173]\ttrain-auc:0.98222\teval-auc:0.85648\n",
      "[174]\ttrain-auc:0.98275\teval-auc:0.85592\n",
      "[175]\ttrain-auc:0.98302\teval-auc:0.85588\n",
      "[176]\ttrain-auc:0.98302\teval-auc:0.85588\n",
      "[177]\ttrain-auc:0.98334\teval-auc:0.85364\n",
      "[178]\ttrain-auc:0.98365\teval-auc:0.85464\n",
      "[179]\ttrain-auc:0.98354\teval-auc:0.85508\n",
      "[180]\ttrain-auc:0.98342\teval-auc:0.85596\n",
      "[181]\ttrain-auc:0.98366\teval-auc:0.85544\n",
      "[182]\ttrain-auc:0.98381\teval-auc:0.85560\n",
      "[183]\ttrain-auc:0.98409\teval-auc:0.85532\n",
      "[184]\ttrain-auc:0.98388\teval-auc:0.85608\n",
      "[185]\ttrain-auc:0.98421\teval-auc:0.85540\n",
      "[186]\ttrain-auc:0.98407\teval-auc:0.85560\n",
      "[187]\ttrain-auc:0.98378\teval-auc:0.85572\n",
      "[188]\ttrain-auc:0.98348\teval-auc:0.85568\n",
      "[189]\ttrain-auc:0.98333\teval-auc:0.85580\n",
      "[190]\ttrain-auc:0.98363\teval-auc:0.85560\n",
      "[191]\ttrain-auc:0.98365\teval-auc:0.85680\n",
      "[192]\ttrain-auc:0.98420\teval-auc:0.85664\n",
      "[193]\ttrain-auc:0.98406\teval-auc:0.85736\n",
      "[194]\ttrain-auc:0.98440\teval-auc:0.85664\n",
      "[195]\ttrain-auc:0.98463\teval-auc:0.85512\n",
      "[196]\ttrain-auc:0.98437\teval-auc:0.85580\n",
      "[197]\ttrain-auc:0.98453\teval-auc:0.85604\n",
      "[198]\ttrain-auc:0.98476\teval-auc:0.85568\n",
      "[199]\ttrain-auc:0.98481\teval-auc:0.85608\n",
      "[200]\ttrain-auc:0.98481\teval-auc:0.85608\n",
      "[201]\ttrain-auc:0.98473\teval-auc:0.85596\n",
      "[202]\ttrain-auc:0.98496\teval-auc:0.85556\n",
      "[203]\ttrain-auc:0.98481\teval-auc:0.85660\n",
      "[204]\ttrain-auc:0.98474\teval-auc:0.85584\n",
      "[205]\ttrain-auc:0.98487\teval-auc:0.85460\n",
      "[206]\ttrain-auc:0.98452\teval-auc:0.85524\n",
      "[207]\ttrain-auc:0.98452\teval-auc:0.85524\n",
      "[208]\ttrain-auc:0.98499\teval-auc:0.85412\n",
      "[209]\ttrain-auc:0.98485\teval-auc:0.85432\n",
      "[210]\ttrain-auc:0.98486\teval-auc:0.85524\n",
      "[211]\ttrain-auc:0.98487\teval-auc:0.85500\n",
      "[212]\ttrain-auc:0.98513\teval-auc:0.85460\n",
      "[213]\ttrain-auc:0.98469\teval-auc:0.85528\n",
      "[214]\ttrain-auc:0.98491\teval-auc:0.85532\n",
      "[215]\ttrain-auc:0.98493\teval-auc:0.85540\n",
      "[216]\ttrain-auc:0.98514\teval-auc:0.85504\n",
      "[217]\ttrain-auc:0.98500\teval-auc:0.85564\n",
      "[218]\ttrain-auc:0.98528\teval-auc:0.85556\n",
      "[219]\ttrain-auc:0.98535\teval-auc:0.85520\n",
      "[220]\ttrain-auc:0.98518\teval-auc:0.85500\n",
      "[221]\ttrain-auc:0.98512\teval-auc:0.85520\n",
      "[222]\ttrain-auc:0.98548\teval-auc:0.85432\n",
      "[223]\ttrain-auc:0.98549\teval-auc:0.85488\n",
      "[224]\ttrain-auc:0.98552\teval-auc:0.85464\n",
      "[225]\ttrain-auc:0.98542\teval-auc:0.85472\n",
      "[226]\ttrain-auc:0.98502\teval-auc:0.85544\n",
      "[227]\ttrain-auc:0.98513\teval-auc:0.85488\n",
      "[228]\ttrain-auc:0.98500\teval-auc:0.85464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[229]\ttrain-auc:0.98536\teval-auc:0.85464\n",
      "[230]\ttrain-auc:0.98505\teval-auc:0.85480\n",
      "[231]\ttrain-auc:0.98484\teval-auc:0.85504\n",
      "[232]\ttrain-auc:0.98520\teval-auc:0.85476\n",
      "[233]\ttrain-auc:0.98539\teval-auc:0.85456\n",
      "[234]\ttrain-auc:0.98573\teval-auc:0.85444\n",
      "[235]\ttrain-auc:0.98613\teval-auc:0.85376\n",
      "[236]\ttrain-auc:0.98575\teval-auc:0.85476\n",
      "[237]\ttrain-auc:0.98581\teval-auc:0.85380\n",
      "[238]\ttrain-auc:0.98608\teval-auc:0.85340\n",
      "[239]\ttrain-auc:0.98580\teval-auc:0.85412\n",
      "[240]\ttrain-auc:0.98606\teval-auc:0.85392\n",
      "[241]\ttrain-auc:0.98604\teval-auc:0.85340\n",
      "[242]\ttrain-auc:0.98617\teval-auc:0.85259\n",
      "[243]\ttrain-auc:0.98614\teval-auc:0.85328\n",
      "[244]\ttrain-auc:0.98582\teval-auc:0.85400\n",
      "[245]\ttrain-auc:0.98592\teval-auc:0.85452\n",
      "[246]\ttrain-auc:0.98613\teval-auc:0.85408\n",
      "[247]\ttrain-auc:0.98613\teval-auc:0.85408\n",
      "[248]\ttrain-auc:0.98620\teval-auc:0.85392\n",
      "[249]\ttrain-auc:0.98596\teval-auc:0.85476\n",
      "[250]\ttrain-auc:0.98594\teval-auc:0.85496\n",
      "[251]\ttrain-auc:0.98614\teval-auc:0.85464\n",
      "[252]\ttrain-auc:0.98644\teval-auc:0.85359\n",
      "[253]\ttrain-auc:0.98656\teval-auc:0.85392\n",
      "[254]\ttrain-auc:0.98639\teval-auc:0.85480\n",
      "[255]\ttrain-auc:0.98628\teval-auc:0.85432\n",
      "[256]\ttrain-auc:0.98609\teval-auc:0.85500\n",
      "[257]\ttrain-auc:0.98598\teval-auc:0.85508\n",
      "[258]\ttrain-auc:0.98585\teval-auc:0.85472\n",
      "[259]\ttrain-auc:0.98628\teval-auc:0.85408\n",
      "[260]\ttrain-auc:0.98662\teval-auc:0.85384\n",
      "[261]\ttrain-auc:0.98667\teval-auc:0.85432\n",
      "[262]\ttrain-auc:0.98683\teval-auc:0.85420\n",
      "[263]\ttrain-auc:0.98691\teval-auc:0.85452\n",
      "[264]\ttrain-auc:0.98700\teval-auc:0.85504\n",
      "[265]\ttrain-auc:0.98683\teval-auc:0.85536\n",
      "[266]\ttrain-auc:0.98684\teval-auc:0.85568\n",
      "[267]\ttrain-auc:0.98734\teval-auc:0.85548\n",
      "[268]\ttrain-auc:0.98719\teval-auc:0.85512\n",
      "[269]\ttrain-auc:0.98716\teval-auc:0.85504\n",
      "[270]\ttrain-auc:0.98678\teval-auc:0.85604\n",
      "[271]\ttrain-auc:0.98718\teval-auc:0.85572\n",
      "[272]\ttrain-auc:0.98720\teval-auc:0.85524\n",
      "[273]\ttrain-auc:0.98718\teval-auc:0.85480\n",
      "[274]\ttrain-auc:0.98758\teval-auc:0.85484\n",
      "[275]\ttrain-auc:0.98790\teval-auc:0.85416\n",
      "[276]\ttrain-auc:0.98775\teval-auc:0.85460\n",
      "[277]\ttrain-auc:0.98823\teval-auc:0.85412\n",
      "[278]\ttrain-auc:0.98823\teval-auc:0.85380\n",
      "[279]\ttrain-auc:0.98790\teval-auc:0.85416\n",
      "[280]\ttrain-auc:0.98777\teval-auc:0.85452\n",
      "[281]\ttrain-auc:0.98778\teval-auc:0.85496\n",
      "[282]\ttrain-auc:0.98744\teval-auc:0.85556\n",
      "[283]\ttrain-auc:0.98773\teval-auc:0.85540\n",
      "[284]\ttrain-auc:0.98801\teval-auc:0.85468\n",
      "[285]\ttrain-auc:0.98787\teval-auc:0.85396\n",
      "[286]\ttrain-auc:0.98819\teval-auc:0.85328\n",
      "[287]\ttrain-auc:0.98781\teval-auc:0.85412\n",
      "[288]\ttrain-auc:0.98775\teval-auc:0.85476\n",
      "[289]\ttrain-auc:0.98799\teval-auc:0.85464\n",
      "[290]\ttrain-auc:0.98789\teval-auc:0.85516\n",
      "[291]\ttrain-auc:0.98798\teval-auc:0.85456\n",
      "[292]\ttrain-auc:0.98821\teval-auc:0.85464\n",
      "[293]\ttrain-auc:0.98813\teval-auc:0.85480\n",
      "[294]\ttrain-auc:0.98785\teval-auc:0.85548\n",
      "[295]\ttrain-auc:0.98806\teval-auc:0.85452\n",
      "[296]\ttrain-auc:0.98840\teval-auc:0.85556\n",
      "[297]\ttrain-auc:0.98840\teval-auc:0.85556\n",
      "[298]\ttrain-auc:0.98813\teval-auc:0.85620\n",
      "[299]\ttrain-auc:0.98784\teval-auc:0.85680\n",
      "[0]\ttrain-auc:0.52276\teval-auc:0.53080\n",
      "[1]\ttrain-auc:0.58203\teval-auc:0.57093\n",
      "[2]\ttrain-auc:0.60626\teval-auc:0.56908\n",
      "[3]\ttrain-auc:0.63029\teval-auc:0.57509\n",
      "[4]\ttrain-auc:0.63597\teval-auc:0.56540\n",
      "[5]\ttrain-auc:0.65259\teval-auc:0.56412\n",
      "[6]\ttrain-auc:0.65515\teval-auc:0.55854\n",
      "[7]\ttrain-auc:0.66226\teval-auc:0.54720\n",
      "[8]\ttrain-auc:0.66704\teval-auc:0.54887\n",
      "[9]\ttrain-auc:0.67079\teval-auc:0.54218\n",
      "[10]\ttrain-auc:0.68035\teval-auc:0.54051\n",
      "[11]\ttrain-auc:0.68693\teval-auc:0.54331\n",
      "[12]\ttrain-auc:0.69107\teval-auc:0.55688\n",
      "[13]\ttrain-auc:0.69379\teval-auc:0.55443\n",
      "[14]\ttrain-auc:0.69732\teval-auc:0.55484\n",
      "[15]\ttrain-auc:0.70193\teval-auc:0.55771\n",
      "[16]\ttrain-auc:0.70684\teval-auc:0.56569\n",
      "[17]\ttrain-auc:0.70994\teval-auc:0.56392\n",
      "[18]\ttrain-auc:0.71380\teval-auc:0.55830\n",
      "[19]\ttrain-auc:0.71685\teval-auc:0.55940\n",
      "[20]\ttrain-auc:0.71939\teval-auc:0.55811\n",
      "[21]\ttrain-auc:0.72569\teval-auc:0.55683\n",
      "[22]\ttrain-auc:0.72906\teval-auc:0.55830\n",
      "[23]\ttrain-auc:0.73531\teval-auc:0.55651\n",
      "[24]\ttrain-auc:0.73520\teval-auc:0.56204\n",
      "[25]\ttrain-auc:0.74128\teval-auc:0.56337\n",
      "[26]\ttrain-auc:0.74669\teval-auc:0.55725\n",
      "[27]\ttrain-auc:0.75191\teval-auc:0.56023\n",
      "[28]\ttrain-auc:0.75731\teval-auc:0.56268\n",
      "[29]\ttrain-auc:0.75978\teval-auc:0.56438\n",
      "[30]\ttrain-auc:0.75881\teval-auc:0.56324\n",
      "[31]\ttrain-auc:0.76361\teval-auc:0.55838\n",
      "[32]\ttrain-auc:0.76447\teval-auc:0.55917\n",
      "[33]\ttrain-auc:0.76671\teval-auc:0.56305\n",
      "[34]\ttrain-auc:0.76772\teval-auc:0.56643\n",
      "[35]\ttrain-auc:0.77274\teval-auc:0.56032\n",
      "[36]\ttrain-auc:0.77364\teval-auc:0.55989\n",
      "[37]\ttrain-auc:0.77603\teval-auc:0.55782\n",
      "[38]\ttrain-auc:0.77461\teval-auc:0.55855\n",
      "[39]\ttrain-auc:0.77702\teval-auc:0.55739\n",
      "[40]\ttrain-auc:0.78052\teval-auc:0.56355\n",
      "[41]\ttrain-auc:0.78316\teval-auc:0.56634\n",
      "[42]\ttrain-auc:0.78211\teval-auc:0.56556\n",
      "[43]\ttrain-auc:0.78551\teval-auc:0.56175\n",
      "[44]\ttrain-auc:0.78700\teval-auc:0.55964\n",
      "[45]\ttrain-auc:0.79190\teval-auc:0.56167\n",
      "[46]\ttrain-auc:0.79266\teval-auc:0.56582\n",
      "[47]\ttrain-auc:0.79621\teval-auc:0.56307\n",
      "[48]\ttrain-auc:0.79982\teval-auc:0.56102\n",
      "[49]\ttrain-auc:0.80087\teval-auc:0.55840\n",
      "[50]\ttrain-auc:0.80221\teval-auc:0.55868\n",
      "[51]\ttrain-auc:0.80205\teval-auc:0.56239\n",
      "[52]\ttrain-auc:0.80348\teval-auc:0.56424\n",
      "[53]\ttrain-auc:0.80353\teval-auc:0.55957\n",
      "[54]\ttrain-auc:0.80420\teval-auc:0.56017\n",
      "[55]\ttrain-auc:0.80973\teval-auc:0.56627\n",
      "[56]\ttrain-auc:0.81297\teval-auc:0.56690\n",
      "[57]\ttrain-auc:0.81604\teval-auc:0.56810\n",
      "[58]\ttrain-auc:0.81724\teval-auc:0.56740\n",
      "[59]\ttrain-auc:0.81824\teval-auc:0.56375\n",
      "[60]\ttrain-auc:0.81781\teval-auc:0.56478\n",
      "[61]\ttrain-auc:0.82082\teval-auc:0.56690\n",
      "[62]\ttrain-auc:0.82270\teval-auc:0.56305\n",
      "[63]\ttrain-auc:0.82412\teval-auc:0.55987\n",
      "[64]\ttrain-auc:0.82516\teval-auc:0.56072\n",
      "[65]\ttrain-auc:0.82721\teval-auc:0.55950\n",
      "[66]\ttrain-auc:0.82940\teval-auc:0.55972\n",
      "[67]\ttrain-auc:0.82991\teval-auc:0.55749\n",
      "[68]\ttrain-auc:0.83117\teval-auc:0.55873\n",
      "[69]\ttrain-auc:0.83059\teval-auc:0.55808\n",
      "[70]\ttrain-auc:0.83210\teval-auc:0.55348\n",
      "[71]\ttrain-auc:0.83483\teval-auc:0.55648\n",
      "[72]\ttrain-auc:0.83934\teval-auc:0.55602\n",
      "[73]\ttrain-auc:0.83940\teval-auc:0.55522\n",
      "[74]\ttrain-auc:0.84007\teval-auc:0.55521\n",
      "[75]\ttrain-auc:0.84194\teval-auc:0.55487\n",
      "[76]\ttrain-auc:0.84521\teval-auc:0.54880\n",
      "[77]\ttrain-auc:0.84640\teval-auc:0.54936\n",
      "[78]\ttrain-auc:0.84701\teval-auc:0.54817\n",
      "[79]\ttrain-auc:0.85053\teval-auc:0.54884\n",
      "[80]\ttrain-auc:0.85189\teval-auc:0.55107\n",
      "[81]\ttrain-auc:0.85328\teval-auc:0.55199\n",
      "[82]\ttrain-auc:0.85469\teval-auc:0.55027\n",
      "[83]\ttrain-auc:0.85568\teval-auc:0.55472\n",
      "[84]\ttrain-auc:0.85376\teval-auc:0.55779\n",
      "[85]\ttrain-auc:0.85623\teval-auc:0.55572\n",
      "[86]\ttrain-auc:0.85829\teval-auc:0.55213\n",
      "[87]\ttrain-auc:0.85756\teval-auc:0.55084\n",
      "[88]\ttrain-auc:0.85877\teval-auc:0.54759\n",
      "[89]\ttrain-auc:0.85767\teval-auc:0.54978\n",
      "[90]\ttrain-auc:0.85731\teval-auc:0.55046\n",
      "[91]\ttrain-auc:0.85926\teval-auc:0.54792\n",
      "[92]\ttrain-auc:0.86077\teval-auc:0.54606\n",
      "[93]\ttrain-auc:0.86303\teval-auc:0.54625\n",
      "[94]\ttrain-auc:0.86499\teval-auc:0.54370\n",
      "[95]\ttrain-auc:0.86409\teval-auc:0.54752\n",
      "[96]\ttrain-auc:0.86434\teval-auc:0.54831\n",
      "[97]\ttrain-auc:0.86400\teval-auc:0.54833\n",
      "[98]\ttrain-auc:0.86667\teval-auc:0.54496\n",
      "[99]\ttrain-auc:0.87075\teval-auc:0.54646\n",
      "[100]\ttrain-auc:0.87067\teval-auc:0.54846\n",
      "[101]\ttrain-auc:0.87192\teval-auc:0.54761\n",
      "[102]\ttrain-auc:0.87161\teval-auc:0.54785\n",
      "[103]\ttrain-auc:0.87217\teval-auc:0.54703\n",
      "[104]\ttrain-auc:0.87706\teval-auc:0.54521\n",
      "[105]\ttrain-auc:0.87527\teval-auc:0.54400\n",
      "[106]\ttrain-auc:0.87761\teval-auc:0.54045\n",
      "[107]\ttrain-auc:0.87813\teval-auc:0.54007\n",
      "[108]\ttrain-auc:0.87749\teval-auc:0.54532\n",
      "[109]\ttrain-auc:0.87770\teval-auc:0.54252\n",
      "[110]\ttrain-auc:0.87865\teval-auc:0.54336\n",
      "[111]\ttrain-auc:0.88123\teval-auc:0.54266\n",
      "[112]\ttrain-auc:0.88147\teval-auc:0.54217\n",
      "[113]\ttrain-auc:0.88374\teval-auc:0.54203\n",
      "[114]\ttrain-auc:0.88545\teval-auc:0.54239\n",
      "[115]\ttrain-auc:0.88670\teval-auc:0.53746\n",
      "[116]\ttrain-auc:0.88700\teval-auc:0.53540\n",
      "[117]\ttrain-auc:0.88659\teval-auc:0.53653\n",
      "[118]\ttrain-auc:0.88531\teval-auc:0.53772\n",
      "[119]\ttrain-auc:0.88436\teval-auc:0.53647\n",
      "[120]\ttrain-auc:0.88708\teval-auc:0.54105\n",
      "[121]\ttrain-auc:0.88846\teval-auc:0.54025\n",
      "[122]\ttrain-auc:0.89099\teval-auc:0.54222\n",
      "[123]\ttrain-auc:0.89245\teval-auc:0.54167\n",
      "[124]\ttrain-auc:0.89272\teval-auc:0.54130\n",
      "[125]\ttrain-auc:0.89406\teval-auc:0.53979\n",
      "[126]\ttrain-auc:0.89182\teval-auc:0.54221\n",
      "[127]\ttrain-auc:0.89303\teval-auc:0.54103\n",
      "[128]\ttrain-auc:0.89543\teval-auc:0.53652\n",
      "[129]\ttrain-auc:0.89394\teval-auc:0.53642\n",
      "[130]\ttrain-auc:0.89538\teval-auc:0.53606\n",
      "[131]\ttrain-auc:0.89591\teval-auc:0.53739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[132]\ttrain-auc:0.89863\teval-auc:0.53454\n",
      "[133]\ttrain-auc:0.89752\teval-auc:0.53551\n",
      "[134]\ttrain-auc:0.89860\teval-auc:0.53814\n",
      "[135]\ttrain-auc:0.90029\teval-auc:0.53452\n",
      "[136]\ttrain-auc:0.90087\teval-auc:0.53213\n",
      "[137]\ttrain-auc:0.90074\teval-auc:0.53226\n",
      "[138]\ttrain-auc:0.90149\teval-auc:0.53026\n",
      "[139]\ttrain-auc:0.90095\teval-auc:0.53199\n",
      "[140]\ttrain-auc:0.90270\teval-auc:0.53036\n",
      "[141]\ttrain-auc:0.90188\teval-auc:0.53333\n",
      "[142]\ttrain-auc:0.90378\teval-auc:0.53520\n",
      "[143]\ttrain-auc:0.90338\teval-auc:0.53624\n",
      "[144]\ttrain-auc:0.90550\teval-auc:0.53693\n",
      "[145]\ttrain-auc:0.90606\teval-auc:0.53768\n",
      "[146]\ttrain-auc:0.90533\teval-auc:0.53915\n",
      "[147]\ttrain-auc:0.90540\teval-auc:0.53585\n",
      "[148]\ttrain-auc:0.90610\teval-auc:0.53632\n",
      "[149]\ttrain-auc:0.90621\teval-auc:0.53595\n",
      "[150]\ttrain-auc:0.90737\teval-auc:0.54046\n",
      "[151]\ttrain-auc:0.90764\teval-auc:0.54064\n",
      "[152]\ttrain-auc:0.90869\teval-auc:0.53939\n",
      "[153]\ttrain-auc:0.90769\teval-auc:0.53744\n",
      "[154]\ttrain-auc:0.90701\teval-auc:0.53769\n",
      "[155]\ttrain-auc:0.91008\teval-auc:0.53709\n",
      "[156]\ttrain-auc:0.90950\teval-auc:0.53914\n",
      "[157]\ttrain-auc:0.91099\teval-auc:0.54156\n",
      "[158]\ttrain-auc:0.91223\teval-auc:0.54072\n",
      "[159]\ttrain-auc:0.91412\teval-auc:0.54330\n",
      "[160]\ttrain-auc:0.91540\teval-auc:0.54430\n",
      "[161]\ttrain-auc:0.91547\teval-auc:0.54564\n",
      "[162]\ttrain-auc:0.91720\teval-auc:0.54320\n",
      "[163]\ttrain-auc:0.91596\teval-auc:0.54415\n",
      "[164]\ttrain-auc:0.91575\teval-auc:0.54413\n",
      "[165]\ttrain-auc:0.91695\teval-auc:0.54387\n",
      "[166]\ttrain-auc:0.91698\teval-auc:0.54561\n",
      "[167]\ttrain-auc:0.91675\teval-auc:0.54576\n",
      "[168]\ttrain-auc:0.91723\teval-auc:0.54711\n",
      "[169]\ttrain-auc:0.91837\teval-auc:0.54409\n",
      "[170]\ttrain-auc:0.91887\teval-auc:0.54080\n",
      "[171]\ttrain-auc:0.91944\teval-auc:0.54060\n",
      "[172]\ttrain-auc:0.91923\teval-auc:0.54032\n",
      "[173]\ttrain-auc:0.92085\teval-auc:0.53943\n",
      "[174]\ttrain-auc:0.92209\teval-auc:0.53846\n",
      "[175]\ttrain-auc:0.92166\teval-auc:0.53781\n",
      "[176]\ttrain-auc:0.92157\teval-auc:0.53870\n",
      "[177]\ttrain-auc:0.92238\teval-auc:0.53692\n",
      "[178]\ttrain-auc:0.92201\teval-auc:0.53769\n",
      "[179]\ttrain-auc:0.92402\teval-auc:0.53770\n",
      "[180]\ttrain-auc:0.92454\teval-auc:0.53496\n",
      "[181]\ttrain-auc:0.92475\teval-auc:0.53369\n",
      "[182]\ttrain-auc:0.92493\teval-auc:0.53063\n",
      "[183]\ttrain-auc:0.92413\teval-auc:0.53340\n",
      "[184]\ttrain-auc:0.92378\teval-auc:0.53343\n",
      "[185]\ttrain-auc:0.92473\teval-auc:0.53463\n",
      "[186]\ttrain-auc:0.92421\teval-auc:0.53458\n",
      "[187]\ttrain-auc:0.92573\teval-auc:0.53468\n",
      "[188]\ttrain-auc:0.92849\teval-auc:0.53606\n",
      "[189]\ttrain-auc:0.92901\teval-auc:0.53654\n",
      "[190]\ttrain-auc:0.92826\teval-auc:0.53953\n",
      "[191]\ttrain-auc:0.92848\teval-auc:0.53792\n",
      "[192]\ttrain-auc:0.93032\teval-auc:0.53625\n",
      "[193]\ttrain-auc:0.93073\teval-auc:0.53315\n",
      "[194]\ttrain-auc:0.93237\teval-auc:0.53045\n",
      "[195]\ttrain-auc:0.93241\teval-auc:0.52900\n",
      "[196]\ttrain-auc:0.93176\teval-auc:0.52808\n",
      "[197]\ttrain-auc:0.93300\teval-auc:0.53051\n",
      "[198]\ttrain-auc:0.93364\teval-auc:0.53165\n",
      "[199]\ttrain-auc:0.93292\teval-auc:0.53248\n",
      "[200]\ttrain-auc:0.93346\teval-auc:0.53331\n",
      "[201]\ttrain-auc:0.93263\teval-auc:0.53380\n",
      "[202]\ttrain-auc:0.93313\teval-auc:0.53450\n",
      "[203]\ttrain-auc:0.93280\teval-auc:0.53678\n",
      "[204]\ttrain-auc:0.93424\teval-auc:0.53497\n",
      "[205]\ttrain-auc:0.93425\teval-auc:0.53557\n",
      "[206]\ttrain-auc:0.93480\teval-auc:0.53549\n",
      "[207]\ttrain-auc:0.93510\teval-auc:0.53587\n",
      "[208]\ttrain-auc:0.93523\teval-auc:0.53467\n",
      "[209]\ttrain-auc:0.93661\teval-auc:0.53512\n",
      "[210]\ttrain-auc:0.93750\teval-auc:0.53452\n",
      "[211]\ttrain-auc:0.93710\teval-auc:0.53689\n",
      "[212]\ttrain-auc:0.93793\teval-auc:0.53777\n",
      "[213]\ttrain-auc:0.93817\teval-auc:0.53814\n",
      "[214]\ttrain-auc:0.93835\teval-auc:0.53642\n",
      "[215]\ttrain-auc:0.94031\teval-auc:0.53596\n",
      "[216]\ttrain-auc:0.94151\teval-auc:0.53778\n",
      "[217]\ttrain-auc:0.94077\teval-auc:0.53968\n",
      "[218]\ttrain-auc:0.94007\teval-auc:0.54080\n",
      "[219]\ttrain-auc:0.94003\teval-auc:0.53960\n",
      "[220]\ttrain-auc:0.93989\teval-auc:0.53930\n",
      "[221]\ttrain-auc:0.94028\teval-auc:0.53933\n",
      "[222]\ttrain-auc:0.94166\teval-auc:0.53962\n",
      "[223]\ttrain-auc:0.94196\teval-auc:0.53805\n",
      "[224]\ttrain-auc:0.94214\teval-auc:0.53933\n",
      "[225]\ttrain-auc:0.94265\teval-auc:0.53856\n",
      "[226]\ttrain-auc:0.94185\teval-auc:0.53934\n",
      "[227]\ttrain-auc:0.94248\teval-auc:0.53934\n",
      "[228]\ttrain-auc:0.94272\teval-auc:0.53690\n",
      "[229]\ttrain-auc:0.94429\teval-auc:0.53646\n",
      "[230]\ttrain-auc:0.94364\teval-auc:0.53979\n",
      "[231]\ttrain-auc:0.94422\teval-auc:0.54091\n",
      "[232]\ttrain-auc:0.94440\teval-auc:0.54323\n",
      "[233]\ttrain-auc:0.94465\teval-auc:0.54242\n",
      "[234]\ttrain-auc:0.94533\teval-auc:0.54028\n",
      "[235]\ttrain-auc:0.94515\teval-auc:0.54101\n",
      "[236]\ttrain-auc:0.94591\teval-auc:0.53986\n",
      "[237]\ttrain-auc:0.94546\teval-auc:0.54253\n",
      "[238]\ttrain-auc:0.94435\teval-auc:0.54465\n",
      "[239]\ttrain-auc:0.94532\teval-auc:0.54368\n",
      "[240]\ttrain-auc:0.94598\teval-auc:0.54314\n",
      "[241]\ttrain-auc:0.94732\teval-auc:0.54294\n",
      "[242]\ttrain-auc:0.94796\teval-auc:0.54250\n",
      "[243]\ttrain-auc:0.94746\teval-auc:0.54279\n",
      "[244]\ttrain-auc:0.94821\teval-auc:0.54125\n",
      "[245]\ttrain-auc:0.94783\teval-auc:0.54317\n",
      "[246]\ttrain-auc:0.94836\teval-auc:0.54404\n",
      "[247]\ttrain-auc:0.94870\teval-auc:0.54368\n",
      "[248]\ttrain-auc:0.94898\teval-auc:0.54387\n",
      "[249]\ttrain-auc:0.94994\teval-auc:0.54106\n",
      "[250]\ttrain-auc:0.95042\teval-auc:0.54124\n",
      "[251]\ttrain-auc:0.95038\teval-auc:0.54047\n",
      "[252]\ttrain-auc:0.95045\teval-auc:0.53846\n",
      "[253]\ttrain-auc:0.95074\teval-auc:0.53951\n",
      "[254]\ttrain-auc:0.95085\teval-auc:0.53831\n",
      "[255]\ttrain-auc:0.95052\teval-auc:0.53825\n",
      "[256]\ttrain-auc:0.95010\teval-auc:0.53750\n",
      "[257]\ttrain-auc:0.95127\teval-auc:0.53772\n",
      "[258]\ttrain-auc:0.95130\teval-auc:0.53829\n",
      "[259]\ttrain-auc:0.95221\teval-auc:0.53950\n",
      "[260]\ttrain-auc:0.95213\teval-auc:0.53966\n",
      "[261]\ttrain-auc:0.95167\teval-auc:0.53594\n",
      "[262]\ttrain-auc:0.95203\teval-auc:0.53430\n",
      "[263]\ttrain-auc:0.95204\teval-auc:0.53493\n",
      "[264]\ttrain-auc:0.95142\teval-auc:0.53552\n",
      "[265]\ttrain-auc:0.95203\teval-auc:0.53803\n",
      "[266]\ttrain-auc:0.95177\teval-auc:0.53689\n",
      "[267]\ttrain-auc:0.95129\teval-auc:0.53873\n",
      "[268]\ttrain-auc:0.95150\teval-auc:0.53668\n",
      "[269]\ttrain-auc:0.95248\teval-auc:0.53873\n",
      "[270]\ttrain-auc:0.95282\teval-auc:0.53756\n",
      "[271]\ttrain-auc:0.95430\teval-auc:0.53567\n",
      "[272]\ttrain-auc:0.95433\teval-auc:0.53631\n",
      "[273]\ttrain-auc:0.95417\teval-auc:0.53666\n",
      "[274]\ttrain-auc:0.95382\teval-auc:0.53616\n",
      "[275]\ttrain-auc:0.95428\teval-auc:0.53844\n",
      "[276]\ttrain-auc:0.95518\teval-auc:0.53834\n",
      "[277]\ttrain-auc:0.95604\teval-auc:0.53986\n",
      "[278]\ttrain-auc:0.95687\teval-auc:0.53982\n",
      "[279]\ttrain-auc:0.95675\teval-auc:0.54029\n",
      "[280]\ttrain-auc:0.95600\teval-auc:0.54143\n",
      "[281]\ttrain-auc:0.95660\teval-auc:0.54190\n",
      "[282]\ttrain-auc:0.95677\teval-auc:0.54275\n",
      "[283]\ttrain-auc:0.95718\teval-auc:0.54263\n",
      "[284]\ttrain-auc:0.95636\teval-auc:0.54266\n",
      "[285]\ttrain-auc:0.95709\teval-auc:0.54304\n",
      "[286]\ttrain-auc:0.95684\teval-auc:0.54167\n",
      "[287]\ttrain-auc:0.95783\teval-auc:0.54023\n",
      "[288]\ttrain-auc:0.95732\teval-auc:0.54147\n",
      "[289]\ttrain-auc:0.95639\teval-auc:0.54152\n",
      "[290]\ttrain-auc:0.95766\teval-auc:0.54016\n",
      "[291]\ttrain-auc:0.95707\teval-auc:0.53763\n",
      "[292]\ttrain-auc:0.95815\teval-auc:0.53672\n",
      "[293]\ttrain-auc:0.95823\teval-auc:0.53814\n",
      "[294]\ttrain-auc:0.95749\teval-auc:0.53942\n",
      "[295]\ttrain-auc:0.95732\teval-auc:0.53743\n",
      "[296]\ttrain-auc:0.95823\teval-auc:0.53683\n",
      "[297]\ttrain-auc:0.95901\teval-auc:0.53788\n",
      "[298]\ttrain-auc:0.95843\teval-auc:0.53764\n",
      "[299]\ttrain-auc:0.95854\teval-auc:0.53429\n"
     ]
    }
   ],
   "source": [
    "eval_p38 = {}\n",
    "eval_akt1 = {}\n",
    "eval_pi3k = {}\n",
    "es2 = EarlyStopping(monitor='loss',patience=15, min_delta=0)\n",
    "rlr2 = ReduceLROnPlateau(monitor='loss',factor=0.5, patience=2, verbose=1, min_lr=0.00001)\n",
    "for i in range(len(training_p38)):\n",
    "    \n",
    "        #First Target\n",
    "        X_atoms_cold_p38,X_bonds_cold_p38,X_edges_cold_p38 = dataframe_to_gcn_input(validation_p38[i])\n",
    "        Y_cold_p38 = validation_p38[i].Binary\n",
    "        Y_dummy_cold_p38 = np.empty((X_atoms_cold_p38.shape[0],int(model_params['dense_size'][2]/3)+1))\n",
    "        X_atoms_train_p38, X_bonds_train_p38, X_edges_train_p38 = dataframe_to_gcn_input(training_p38[i])\n",
    "        Y_p38 = training_p38[i].Binary\n",
    "        Y_dummy_train_p38 = np.empty((X_atoms_train_p38.shape[0],int(model_params['dense_size'][2]/3)+1))\n",
    "        smiles_list_p38 = list(training_p38[i]['rdkit'])\n",
    "        \n",
    "        #Second Target\n",
    "        X_atoms_cold_akt1, X_bonds_cold_akt1, X_edges_cold_akt1 = dataframe_to_gcn_input(validation_akt1[i])\n",
    "        Y_cold_akt1 = validation_akt1[i].Binary\n",
    "        Y_dummy_cold_akt1 = np.empty((X_atoms_cold_akt1.shape[0],int(model_params['dense_size'][2]/3)+1))\n",
    "        X_atoms_train_akt1, X_bonds_train_akt1, X_edges_train_akt1 = dataframe_to_gcn_input(training_akt1[i])\n",
    "        Y_akt1 = training_akt1[i].Binary\n",
    "        Y_dummy_train_akt1 = np.empty((X_atoms_train_akt1.shape[0],int(model_params['dense_size'][2]/3)+1))\n",
    "        smiles_list_akt1 = list(training_akt1[i]['rdkit'])\n",
    "        \n",
    "        #Third Target\n",
    "        X_atoms_cold_pi3k,X_bonds_cold_pi3k,X_edges_cold_pi3k = dataframe_to_gcn_input(validation_pi3k[i])\n",
    "        Y_cold_pi3k = validation_pi3k[i].Binary\n",
    "        Y_dummy_cold_pi3k = np.empty((X_atoms_cold_pi3k.shape[0],int(model_params['dense_size'][2]/3)+1))\n",
    "        X_atoms_train_pi3k, X_bonds_train_pi3k, X_edges_train_pi3k = dataframe_to_gcn_input(training_pi3k[i])\n",
    "        Y_pi3k = training_pi3k[i].Binary\n",
    "        Y_dummy_train_pi3k = np.empty((X_atoms_train_pi3k.shape[0],int(model_params['dense_size'][2]/3)+1))\n",
    "        smiles_list_pi3k = list(training_pi3k[i]['rdkit'])\n",
    "        \n",
    "        gcn_encoder = build_encoder(model_params)\n",
    "        gcn_model = build_model(model_params,gcn_encoder)\n",
    "        gcn_mining = build_mining(model_params,gcn_model)\n",
    "        train_GEN = csv_generator_mining(model_params['batch_size'],training_p38[i],training_akt1[i],training_pi3k[i],\n",
    "                                  Y_dummy_train_p38,Y_dummy_train_akt1,Y_dummy_train_pi3k,\n",
    "                                  smiles_list_p38,smiles_list_akt1,smiles_list_pi3k,\n",
    "                                  Y_p38,Y_akt1,Y_pi3k,\n",
    "                                  X_atoms_train_p38, X_bonds_train_p38, X_edges_train_p38,\n",
    "                                  X_atoms_train_akt1, X_bonds_train_akt1, X_edges_train_akt1,\n",
    "                                  X_atoms_train_pi3k, X_bonds_train_pi3k, X_edges_train_pi3k)\n",
    "        NUM_TRAIN = np.sum([len(training_p38[i]),len(training_akt1[i]),len(training_pi3k[i])])\n",
    "        gcn_mining.fit_generator(train_GEN,\n",
    "                      steps_per_epoch = ceil(3*NUM_TRAIN/model_params['batch_size']),\n",
    "                      epochs = model_params['n_epochs'],\n",
    "                      shuffle = True,\n",
    "                      validation_data = None,\n",
    "                      callbacks = [es2,rlr2])\n",
    "        emb_train_1,t1,t2 = gcn_model.predict([X_atoms_train_p38,X_bonds_train_p38,X_edges_train_p38,\n",
    "                                        X_atoms_train_p38,X_bonds_train_p38,X_edges_train_p38,\n",
    "                                        X_atoms_train_p38,X_bonds_train_p38,X_edges_train_p38])\n",
    "        t1,emb_train_2,t2 = gcn_model.predict([X_atoms_train_akt1,X_bonds_train_akt1,X_edges_train_akt1,\n",
    "                                        X_atoms_train_akt1,X_bonds_train_akt1,X_edges_train_akt1,\n",
    "                                        X_atoms_train_akt1,X_bonds_train_akt1,X_edges_train_akt1])\n",
    "        t1,t2,emb_train_3 = gcn_model.predict([X_atoms_train_pi3k,X_bonds_train_pi3k,X_edges_train_pi3k,\n",
    "                                        X_atoms_train_pi3k,X_bonds_train_pi3k,X_edges_train_pi3k,\n",
    "                                        X_atoms_train_pi3k,X_bonds_train_pi3k,X_edges_train_pi3k])\n",
    "\n",
    "\n",
    "        emb_val_1,t1,t2 = gcn_model.predict([X_atoms_cold_p38,X_bonds_cold_p38,X_edges_cold_p38,\n",
    "                                            X_atoms_cold_p38,X_bonds_cold_p38,X_edges_cold_p38,\n",
    "                                            X_atoms_cold_p38,X_bonds_cold_p38,X_edges_cold_p38])\n",
    "        t1,emb_val_2,t2 = gcn_model.predict([X_atoms_cold_akt1,X_bonds_cold_akt1,X_edges_cold_akt1,\n",
    "                                            X_atoms_cold_akt1,X_bonds_cold_akt1,X_edges_cold_akt1,\n",
    "                                            X_atoms_cold_akt1,X_bonds_cold_akt1,X_edges_cold_akt1])\n",
    "        t1,t2,emb_val_3 = gcn_model.predict([X_atoms_cold_pi3k,X_bonds_cold_pi3k,X_edges_cold_pi3k,\n",
    "                                            X_atoms_cold_pi3k,X_bonds_cold_pi3k,X_edges_cold_pi3k,\n",
    "                                            X_atoms_cold_pi3k,X_bonds_cold_pi3k,X_edges_cold_pi3k])\n",
    "        \n",
    "        del t1,t2, gcn_mining,gcn_encoder,gcn_model,X_atoms_cold_p38,X_bonds_cold_p38,X_edges_cold_p38\n",
    "        del X_atoms_train_p38, X_bonds_train_p38, X_edges_train_p38,X_atoms_cold_pi3k,X_bonds_cold_pi3k,X_edges_cold_pi3k\n",
    "        del X_atoms_train_pi3k, X_bonds_train_pi3k, X_edges_train_pi3k,X_atoms_cold_akt1, X_bonds_cold_akt1, X_edges_cold_akt1\n",
    "        del X_atoms_train_akt1, X_bonds_train_akt1, X_edges_train_akt1,train_GEN\n",
    "        \n",
    "        #First\n",
    "        dmatrix_train_1 = xgb.DMatrix(data = emb_train_1,label = Y_p38)\n",
    "        dmatrix_cold_1  = xgb.DMatrix(data = emb_val_1,label = Y_cold_p38)\n",
    "        evalist_1 = [(dmatrix_train_1,'train'),(dmatrix_cold_1,'eval')]\n",
    "        xgb_model_1 = xgb.train(xgb_hyper,dmatrix_train_1,300,evalist_1,verbose_eval=True)\n",
    "        xgb_pred_cold_1 = xgb_model_1.predict(dmatrix_cold_1)\n",
    "        \n",
    "        \n",
    "        #Second\n",
    "        dmatrix_train_2 = xgb.DMatrix(data = emb_train_2,label = Y_akt1)\n",
    "        dmatrix_cold_2  = xgb.DMatrix(data = emb_val_2,label = Y_cold_akt1)\n",
    "        evalist_2 = [(dmatrix_train_2,'train'),(dmatrix_cold_2,'eval')]\n",
    "        xgb_model_2 = xgb.train(xgb_hyper,dmatrix_train_2,300,evalist_2,verbose_eval=True)\n",
    "        xgb_pred_cold_2 = xgb_model_2.predict(dmatrix_cold_2)\n",
    "        \n",
    "        \n",
    "        #Third\n",
    "        dmatrix_train_3 = xgb.DMatrix(data = emb_train_3,label = Y_pi3k)\n",
    "        dmatrix_cold_3  = xgb.DMatrix(data = emb_val_3,label = Y_cold_pi3k)\n",
    "        evalist_3 = [(dmatrix_train_3,'train'),(dmatrix_cold_3,'eval')]\n",
    "        xgb_model_3 = xgb.train(xgb_hyper,dmatrix_train_3,300,evalist_3,verbose_eval=True)\n",
    "        xgb_pred_cold_3 = xgb_model_3.predict(dmatrix_cold_3)\n",
    "        \n",
    "        if i == 0:\n",
    "            eval_p38['Test'] = calculate_metrics(np.array(Y_cold_p38),xgb_pred_cold_1)\n",
    "            eval_akt1['Test'] = calculate_metrics(np.array(Y_cold_akt1),xgb_pred_cold_2)\n",
    "            eval_pi3k['Test'] = calculate_metrics(np.array(Y_cold_pi3k),xgb_pred_cold_3)\n",
    "        elif i == 1:\n",
    "            eval_p38['Random'] = calculate_metrics(np.array(Y_cold_p38),xgb_pred_cold_1)\n",
    "            eval_akt1['Random'] = calculate_metrics(np.array(Y_cold_akt1),xgb_pred_cold_2)\n",
    "            eval_pi3k['Random'] = calculate_metrics(np.array(Y_cold_pi3k),xgb_pred_cold_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_p38 = pd.DataFrame(eval_p38).T\n",
    "eval_p38.to_csv('../../../../Desktop/binding/thesis english/Results/4-Multitask/Online/p38.csv')\n",
    "\n",
    "eval_akt1 = pd.DataFrame(eval_akt1).T\n",
    "eval_akt1.to_csv('../../../../Desktop/binding/thesis english/Results/4-Multitask/Online/akt1.csv')\n",
    "\n",
    "eval_pi3k = pd.DataFrame(eval_pi3k).T\n",
    "eval_pi3k.to_csv('../../../../Desktop/binding/thesis english/Results/4-Multitask/Online/pi3k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>map</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.503775</td>\n",
       "      <td>161.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.416844</td>\n",
       "      <td>0.410569</td>\n",
       "      <td>0.497537</td>\n",
       "      <td>0.514735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.588056</td>\n",
       "      <td>182.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.522963</td>\n",
       "      <td>0.514403</td>\n",
       "      <td>0.534188</td>\n",
       "      <td>0.574906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         roc_auc     tn     fp     fn     tp       map  precision    recall  \\\n",
       "Test    0.503775  161.0  145.0  102.0  101.0  0.416844   0.410569  0.497537   \n",
       "Random  0.588056  182.0  118.0  109.0  125.0  0.522963   0.514403  0.534188   \n",
       "\n",
       "        accuracy  \n",
       "Test    0.514735  \n",
       "Random  0.574906  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_p38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>map</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.848480</td>\n",
       "      <td>170.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.786818</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.781046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.856802</td>\n",
       "      <td>158.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.839379</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.734848</td>\n",
       "      <td>0.794393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         roc_auc     tn    fp    fn    tp       map  precision    recall  \\\n",
       "Test    0.848480  170.0  20.0  47.0  69.0  0.786818   0.775281  0.594828   \n",
       "Random  0.856802  158.0  31.0  35.0  97.0  0.839379   0.757812  0.734848   \n",
       "\n",
       "        accuracy  \n",
       "Test    0.781046  \n",
       "Random  0.794393  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_akt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>map</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.641557</td>\n",
       "      <td>293.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.466434</td>\n",
       "      <td>0.492424</td>\n",
       "      <td>0.367232</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.534291</td>\n",
       "      <td>270.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.372734</td>\n",
       "      <td>0.358621</td>\n",
       "      <td>0.258706</td>\n",
       "      <td>0.570922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         roc_auc     tn    fp     fn    tp       map  precision    recall  \\\n",
       "Test    0.641557  293.0  67.0  112.0  65.0  0.466434   0.492424  0.367232   \n",
       "Random  0.534291  270.0  93.0  149.0  52.0  0.372734   0.358621  0.258706   \n",
       "\n",
       "        accuracy  \n",
       "Test    0.666667  \n",
       "Random  0.570922  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pi3k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
