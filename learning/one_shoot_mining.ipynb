{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.callbacks import History, ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "from model_builders import GCN_siam_model\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, roc_auc_score, auc, average_precision_score\n",
    "#import scikitplot as skplt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from NGF.preprocessing import tensorise_smiles\n",
    "from custom_layers.model_creator import encode_smiles, stage_creator\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, concatenate,Flatten\n",
    "from keras.models import Model, load_model\n",
    "from data_analysis import calculate_metrics\n",
    "import dill\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from distance_and_mask_fn import pairwise_distance,masked_maximum,masked_minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss_adapted_from_tf(y_true, y_pred):\n",
    "    del y_true\n",
    "    margin = 0.5\n",
    "    labels = y_pred[:, :1]\n",
    "    labels = tf.cast(labels, dtype='int32')\n",
    "    embeddings = y_pred[:, 1:]\n",
    "\n",
    "    ### Code from Tensorflow function [tf.contrib.losses.metric_learning.triplet_semihard_loss] starts here:\n",
    "    \n",
    "    # Reshape [batch_size] label tensor to a [batch_size, 1] label tensor.\n",
    "    # lshape=array_ops.shape(labels)\n",
    "    # assert lshape.shape == 1\n",
    "    # labels = array_ops.reshape(labels, [lshape[0], 1])\n",
    "\n",
    "    # Build pairwise squared distance matrix.\n",
    "    pdist_matrix = pairwise_distance(embeddings, squared=False)\n",
    "    # Build pairwise binary adjacency matrix.\n",
    "    adjacency = math_ops.equal(labels, array_ops.transpose(labels))\n",
    "    # Invert so we can select negatives only.\n",
    "    adjacency_not = math_ops.logical_not(adjacency)\n",
    "\n",
    "    # global batch_size  \n",
    "    batch_size = array_ops.size(labels) # was 'array_ops.size(labels)'\n",
    "\n",
    "    # Compute the mask.\n",
    "    pdist_matrix_tile = array_ops.tile(pdist_matrix, [batch_size, 1])\n",
    "    mask = math_ops.logical_and(\n",
    "        array_ops.tile(adjacency_not, [batch_size, 1]),\n",
    "        math_ops.greater(\n",
    "            pdist_matrix_tile, array_ops.reshape(\n",
    "                array_ops.transpose(pdist_matrix), [-1, 1])))\n",
    "    mask_final = array_ops.reshape(\n",
    "        math_ops.greater(\n",
    "            math_ops.reduce_sum(\n",
    "                math_ops.cast(mask, dtype=dtypes.float32), 1, keepdims=True),\n",
    "            0.0), [batch_size, batch_size])\n",
    "    mask_final = array_ops.transpose(mask_final)\n",
    "\n",
    "    adjacency_not = math_ops.cast(adjacency_not, dtype=dtypes.float32)\n",
    "    mask = math_ops.cast(mask, dtype=dtypes.float32)\n",
    "\n",
    "    # negatives_outside: smallest D_an where D_an > D_ap.\n",
    "    negatives_outside = array_ops.reshape(\n",
    "        masked_minimum(pdist_matrix_tile, mask), [batch_size, batch_size])\n",
    "    negatives_outside = array_ops.transpose(negatives_outside)\n",
    "\n",
    "    # negatives_inside: largest D_an.\n",
    "    negatives_inside = array_ops.tile(\n",
    "        masked_maximum(pdist_matrix, adjacency_not), [1, batch_size])\n",
    "    semi_hard_negatives = array_ops.where(\n",
    "        mask_final, negatives_outside, negatives_inside)\n",
    "\n",
    "    loss_mat = math_ops.add(margin, pdist_matrix - semi_hard_negatives)\n",
    "\n",
    "    mask_positives = math_ops.cast(\n",
    "        adjacency, dtype=dtypes.float32) - array_ops.diag(\n",
    "        array_ops.ones([batch_size]))\n",
    "\n",
    "    # In lifted-struct, the authors multiply 0.5 for upper triangular\n",
    "    #   in semihard, they take all positive pairs except the diagonal.\n",
    "    num_positives = math_ops.reduce_sum(mask_positives)\n",
    "\n",
    "    semi_hard_triplet_loss_distance = math_ops.truediv(\n",
    "        math_ops.reduce_sum(\n",
    "            math_ops.maximum(\n",
    "                math_ops.multiply(loss_mat, mask_positives), 0.0)),\n",
    "        num_positives,\n",
    "        name='triplet_semihard_loss')\n",
    "    \n",
    "    ### Code from Tensorflow function semi-hard triplet loss ENDS here.\n",
    "    return semi_hard_triplet_loss_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss',patience=8, min_delta=0)\n",
    "rlr = ReduceLROnPlateau(monitor='loss',factor=0.5, patience=4, verbose=1, min_lr=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "        \"num_layers\" : 3,\n",
    "        \"max_atoms\" : 70,\n",
    "        \"num_atom_features\" : 62,\n",
    "        \"num_atom_features_original\" : 62,\n",
    "        \"num_bond_features\" : 6,\n",
    "        \"max_degree\" : 5,\n",
    "        \"conv_width\" : [int(96), int(104), int(120)],\n",
    "        \"fp_length\" : [int(160), int(160), int(160)],\n",
    "        \"activ_enc\" : \"selu\",\n",
    "        \"activ_dec\" : \"selu\",\n",
    "        \"learning_rates\" : [0.001,0.001,0.001],\n",
    "        \"learning_rates_fp\": [0.005,0.005,0.005],\n",
    "        \"losses_conv\" : {\n",
    "                    \"neighbor_output\": \"mean_squared_error\",\n",
    "                    \"self_output\": \"mean_squared_error\",\n",
    "                    },\n",
    "        \"lossWeights\" : {\"neighbor_output\": 1.0, \"self_output\": 1.0},\n",
    "        \"metrics\" : \"mse\",\n",
    "        \"loss_fp\" : \"mean_squared_error\",\n",
    "        \"enc_layer_names\" : [\"enc_1\", \"enc_2\", \"enc_3\"],\n",
    "        'callbacks' : [es,rlr],\n",
    "        'adam_decay': 0.0005329142291371636,\n",
    "        'beta': 5,\n",
    "        'p': 0.004465204118126482,\n",
    "        'dense_size' : [int(512), int(512), int(256)], \n",
    "        'dropout_rate' : [0.1, 0.1],\n",
    "        'lr' : 1e-4,\n",
    "        'batch_size' : int(64),\n",
    "        'n_epochs' : int(35),\n",
    "        'margin' : 0.5\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_gcn_input(input_data):\n",
    "        x_atoms_cold, x_bonds_cold, x_edges_cold = tensorise_smiles(input_data,\n",
    "                                                                    max_degree=model_params['max_degree'],\n",
    "                                                                    max_atoms=model_params['max_atoms'])\n",
    "        return [x_atoms_cold, x_bonds_cold, x_edges_cold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(encoder_params):\n",
    "        model_enc_1 = stage_creator(encoder_params, 1, conv=True)[0]\n",
    "        model_enc_2 = stage_creator(encoder_params, 2, conv=True)[0]\n",
    "        model_enc_3 = stage_creator(encoder_params, 3, conv=True)[0]\n",
    "\n",
    "        model_enc_fp_1 = stage_creator(encoder_params, 1, conv=False)[1]\n",
    "        model_enc_fp_2 = stage_creator(encoder_params, 2, conv=False)[1]\n",
    "        model_enc_fp_3 = stage_creator(encoder_params, 3, conv=False)[1]\n",
    "\n",
    "        atoms, bonds, edges = encode_smiles(encoder_params[\"max_atoms\"],\n",
    "                                            encoder_params[\"num_atom_features\"],\n",
    "                                            encoder_params[\"max_degree\"],\n",
    "                                            encoder_params[\"num_bond_features\"])\n",
    "\n",
    "        graph_conv_1 = model_enc_1([atoms, bonds, edges])\n",
    "        graph_conv_2 = model_enc_2([graph_conv_1, bonds, edges])\n",
    "        graph_conv_3 = model_enc_3([graph_conv_2, bonds, edges])\n",
    "\n",
    "        fingerprint_1 = model_enc_fp_1([graph_conv_1, bonds, edges])\n",
    "        fingerprint_1 = Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0], s[2]))(fingerprint_1)\n",
    "\n",
    "        fingerprint_2 = model_enc_fp_2([graph_conv_2, bonds, edges])\n",
    "        fingerprint_2 = Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0], s[2]))(fingerprint_2)\n",
    "\n",
    "        fingerprint_3 = model_enc_fp_3([graph_conv_3, bonds, edges])\n",
    "        fingerprint_3 = Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0], s[2]))(fingerprint_3)\n",
    "\n",
    "        final_fingerprint = keras.layers.add([fingerprint_1, fingerprint_2, fingerprint_3])\n",
    "\n",
    "        return Model([atoms, bonds, edges], [final_fingerprint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_params, encoder, verbose=False):\n",
    "        atoms = Input(name='atom_inputs',\n",
    "                      shape=(model_params['max_atoms'], model_params['num_atom_features']), dtype='float32')\n",
    "        bonds = Input(name='bond_inputs', shape=(\n",
    "            model_params['max_atoms'], model_params['max_degree'], model_params['num_bond_features']),\n",
    "                      dtype='float32')\n",
    "        edges = Input(name='edge_inputs', shape=(model_params['max_atoms'], model_params['max_degree']),\n",
    "                      dtype='int32')\n",
    "        encode_drug = encoder([atoms, bonds, edges])\n",
    "\n",
    "        # Fully connected\n",
    "        FC1 = Dense(model_params[\"dense_size\"][0], activation='relu',kernel_initializer='random_normal')(encode_drug)\n",
    "        FC2 = Dropout(model_params[\"dropout_rate\"][0])(FC1)\n",
    "        FC2 = Dense(model_params[\"dense_size\"][1], activation='relu',kernel_initializer='random_normal')(FC2)\n",
    "        FC2 = Dropout(model_params[\"dropout_rate\"][1])(FC2)\n",
    "        FC2 = Dense(model_params[\"dense_size\"][2], activation = None,kernel_initializer='random_normal')(FC2)\n",
    "        \n",
    "        \n",
    "        embeddings = Lambda(lambda x: K.l2_normalize(x,axis=1),name = 'Embeddings')(FC2)\n",
    "        #predictions = Dense(1, activation='sigmoid', kernel_initializer='random_normal',name = 'Predictions')(FC2)\n",
    "        gcn_model = Model(inputs=[atoms, bonds, edges], outputs = embeddings)\n",
    "\n",
    "\n",
    "        #if verbose:\n",
    "         #   print('encoder')\n",
    "          #  encoder.summary()\n",
    "           # print('GCN_model')\n",
    "        gcn_model.summary()\n",
    "            \n",
    "        return gcn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mining(model_params,gcn_model):\n",
    "    atoms = Input(name='atom_inputs',\n",
    "                  shape=(model_params['max_atoms'], model_params['num_atom_features']), dtype='float32')\n",
    "    bonds = Input(name='bond_inputs', shape=(\n",
    "        model_params['max_atoms'], model_params['max_degree'], model_params['num_bond_features']),\n",
    "                  dtype='float32')\n",
    "    edges = Input(name='edge_inputs', shape=(model_params['max_atoms'], model_params['max_degree']),\n",
    "                  dtype='int32')\n",
    "    \n",
    "    labels = Input(name = 'labels_inputs',shape = (1,),dtype = 'float32')\n",
    "    \n",
    "    encoded = gcn_model([atoms,bonds,edges])\n",
    "    labels_plus_embeddings = concatenate([labels, encoded])\n",
    "    \n",
    "    mining_net = Model(inputs = [atoms,bonds,edges,labels],outputs = labels_plus_embeddings)\n",
    "    adam = keras.optimizers.Adam(lr = model_params[\"lr\"], \n",
    "                                 beta_1=0.9, \n",
    "                                 beta_2=0.999, \n",
    "                                 decay=0.0, \n",
    "                                 amsgrad=False)\n",
    "    \n",
    "    \n",
    "    mining_net.compile(optimizer=adam , loss = triplet_loss_adapted_from_tf)\n",
    "    mining_net.summary()\n",
    "    return mining_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Old harder splits\n",
    "train_0 = pd.read_csv(\"/Users/tomas/Documents/GitHub/kinase_binding/learning/data/p38/split_aveb/fold_0/train_0.csv\",index_col=0)\n",
    "val_0 = pd.read_csv(\"/Users/tomas/Documents/GitHub/kinase_binding/learning/data/p38/split_aveb/fold_0/val_0.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'p38'\n",
    "base_path = f'C:/Users/tomas/Documents/GitHub/kinase_binding'\n",
    "\n",
    "data_fpath = base_path+f'/data/{target}/data.csv'\n",
    "df=pd.read_csv(data_fpath).set_index('biolab_index')\n",
    "\n",
    "with open(base_path+f'/data/{target}/train_val_folds.pkl', \"rb\") as in_f:\n",
    "    train_val_folds = dill.load(in_f)\n",
    "with open(base_path+f'/data/{target}/train_test_folds.pkl', \"rb\") as in_f:\n",
    "    train_test_folds = dill.load(in_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = train_0#df.loc[train_val_folds[0][0]]\n",
    "smiles_list = list(train.rdkit)\n",
    "\n",
    "#Train to gcn_network\n",
    "train_atoms, train_bonds, train_edges = dataframe_to_gcn_input(train['rdkit'])\n",
    "\n",
    "Y_dummy = np.empty((train_atoms.shape[0],256+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = val_0#df.loc[train_val_folds[0][1]]\n",
    "val_atoms, val_bonds, val_edges = dataframe_to_gcn_input(val[\"rdkit\"])\n",
    "Y_dummy_val = np.empty((val_atoms.shape[0],256+1))\n",
    "del train_0,val_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "atom_inputs (InputLayer)        (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs (InputLayer)        (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs (InputLayer)        (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_10 (Model)                (None, 160)          241696      atom_inputs[0][0]                \n",
      "                                                                 bond_inputs[0][0]                \n",
      "                                                                 edge_inputs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          82432       model_10[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          262656      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          131328      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Embeddings (Lambda)             (None, 256)          0           dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 718,112\n",
      "Trainable params: 716,512\n",
      "Non-trainable params: 1,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = build_encoder(model_params)\n",
    "gcn_model = build_model(model_params,encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "atom_inputs (InputLayer)        (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs (InputLayer)        (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs (InputLayer)        (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "labels_inputs (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_11 (Model)                (None, 256)          718112      atom_inputs[0][0]                \n",
      "                                                                 bond_inputs[0][0]                \n",
      "                                                                 edge_inputs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 257)          0           labels_inputs[0][0]              \n",
      "                                                                 model_11[1][0]                   \n",
      "==================================================================================================\n",
      "Total params: 718,112\n",
      "Trainable params: 716,512\n",
      "Non-trainable params: 1,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mining_model = build_mining(model_params,gcn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss',patience=15, min_delta=0)\n",
    "rlr2 = ReduceLROnPlateau(monitor='loss',factor=0.5, patience=2, verbose=1, min_lr=0.000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2804 samples, validate on 382 samples\n",
      "Epoch 1/50\n",
      "2804/2804 [==============================] - 7s 2ms/step - loss: 0.4983 - val_loss: 0.4981\n",
      "Epoch 2/50\n",
      "2804/2804 [==============================] - 1s 268us/step - loss: 0.4981 - val_loss: 0.4978\n",
      "Epoch 3/50\n",
      "2804/2804 [==============================] - 1s 269us/step - loss: 0.4979 - val_loss: 0.4970\n",
      "Epoch 4/50\n",
      "2804/2804 [==============================] - 1s 269us/step - loss: 0.4977 - val_loss: 0.4949\n",
      "Epoch 5/50\n",
      "2804/2804 [==============================] - 1s 268us/step - loss: 0.4969 - val_loss: 0.4921\n",
      "Epoch 6/50\n",
      "2804/2804 [==============================] - 1s 270us/step - loss: 0.4953 - val_loss: 0.4875\n",
      "Epoch 7/50\n",
      "2804/2804 [==============================] - 1s 270us/step - loss: 0.4929 - val_loss: 0.4832\n",
      "Epoch 8/50\n",
      "2804/2804 [==============================] - 1s 269us/step - loss: 0.4902 - val_loss: 0.4769\n",
      "Epoch 9/50\n",
      "2804/2804 [==============================] - 1s 269us/step - loss: 0.4874 - val_loss: 0.4753\n",
      "Epoch 10/50\n",
      "2804/2804 [==============================] - 1s 269us/step - loss: 0.4846 - val_loss: 0.4750\n",
      "Epoch 11/50\n",
      "2804/2804 [==============================] - 1s 269us/step - loss: 0.4828 - val_loss: 0.4773\n",
      "Epoch 12/50\n",
      "2804/2804 [==============================] - 1s 269us/step - loss: 0.4799 - val_loss: 0.4755\n",
      "Epoch 13/50\n",
      "2804/2804 [==============================] - 1s 270us/step - loss: 0.4779 - val_loss: 0.4787\n",
      "Epoch 14/50\n",
      "2804/2804 [==============================] - 1s 269us/step - loss: 0.4755 - val_loss: 0.4785\n",
      "Epoch 15/50\n",
      "2804/2804 [==============================] - 1s 269us/step - loss: 0.4721 - val_loss: 0.4806\n",
      "Epoch 16/50\n",
      "2804/2804 [==============================] - 1s 269us/step - loss: 0.4706 - val_loss: 0.4780\n",
      "Epoch 17/50\n",
      "2804/2804 [==============================] - 1s 268us/step - loss: 0.4685 - val_loss: 0.4778\n",
      "Epoch 18/50\n",
      "2804/2804 [==============================] - 1s 269us/step - loss: 0.4647 - val_loss: 0.4754\n",
      "Epoch 19/50\n",
      "2804/2804 [==============================] - 1s 269us/step - loss: 0.4637 - val_loss: 0.4783\n",
      "Epoch 20/50\n",
      "2804/2804 [==============================] - 1s 270us/step - loss: 0.4627 - val_loss: 0.4789\n",
      "Epoch 21/50\n",
      "2804/2804 [==============================] - 1s 269us/step - loss: 0.4556 - val_loss: 0.4789\n",
      "Epoch 22/50\n",
      "2804/2804 [==============================] - 1s 270us/step - loss: 0.4568 - val_loss: 0.4801\n",
      "Epoch 23/50\n",
      "2804/2804 [==============================] - 1s 271us/step - loss: 0.4558 - val_loss: 0.4801\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 24/50\n",
      "2804/2804 [==============================] - 1s 271us/step - loss: 0.4467 - val_loss: 0.4784\n",
      "Epoch 25/50\n",
      "2804/2804 [==============================] - 1s 269us/step - loss: 0.4465 - val_loss: 0.4778\n",
      "Epoch 26/50\n",
      "2804/2804 [==============================] - 1s 271us/step - loss: 0.4444 - val_loss: 0.4787\n",
      "Epoch 27/50\n",
      "2804/2804 [==============================] - 1s 270us/step - loss: 0.4459 - val_loss: 0.4772\n",
      "Epoch 28/50\n",
      "2804/2804 [==============================] - 1s 272us/step - loss: 0.4410 - val_loss: 0.4786\n",
      "Epoch 29/50\n",
      "2804/2804 [==============================] - 1s 270us/step - loss: 0.4459 - val_loss: 0.4795\n",
      "Epoch 30/50\n",
      "2804/2804 [==============================] - 1s 271us/step - loss: 0.4379 - val_loss: 0.4784\n",
      "Epoch 31/50\n",
      "2804/2804 [==============================] - 1s 270us/step - loss: 0.4387 - val_loss: 0.4798\n",
      "Epoch 32/50\n",
      "2804/2804 [==============================] - 1s 271us/step - loss: 0.4351 - val_loss: 0.4792\n",
      "Epoch 33/50\n",
      "2804/2804 [==============================] - 1s 270us/step - loss: 0.4368 - val_loss: 0.4784\n",
      "Epoch 34/50\n",
      "2804/2804 [==============================] - 1s 270us/step - loss: 0.4333 - val_loss: 0.4785\n",
      "Epoch 35/50\n",
      "2804/2804 [==============================] - 1s 270us/step - loss: 0.4290 - val_loss: 0.4786\n",
      "Epoch 36/50\n",
      "2804/2804 [==============================] - 1s 272us/step - loss: 0.4211 - val_loss: 0.4781\n",
      "Epoch 37/50\n",
      "2804/2804 [==============================] - 1s 271us/step - loss: 0.4250 - val_loss: 0.4789\n",
      "Epoch 38/50\n",
      "2804/2804 [==============================] - 1s 271us/step - loss: 0.4216 - val_loss: 0.4797\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 39/50\n",
      "2804/2804 [==============================] - 1s 272us/step - loss: 0.4133 - val_loss: 0.4785\n",
      "Epoch 40/50\n",
      "2804/2804 [==============================] - 1s 271us/step - loss: 0.4152 - val_loss: 0.4793\n",
      "Epoch 41/50\n",
      "2804/2804 [==============================] - 3s 942us/step - loss: 0.4112 - val_loss: 0.4800\n",
      "Epoch 42/50\n",
      "2804/2804 [==============================] - 4s 2ms/step - loss: 0.4162 - val_loss: 0.4800\n",
      "Epoch 43/50\n",
      "2804/2804 [==============================] - 1s 385us/step - loss: 0.4063 - val_loss: 0.4781\n",
      "Epoch 44/50\n",
      "2804/2804 [==============================] - 1s 270us/step - loss: 0.4092 - val_loss: 0.4783\n",
      "Epoch 45/50\n",
      "2804/2804 [==============================] - 1s 270us/step - loss: 0.4041 - val_loss: 0.4788\n",
      "Epoch 46/50\n",
      "2804/2804 [==============================] - 1s 269us/step - loss: 0.4050 - val_loss: 0.4788\n",
      "Epoch 47/50\n",
      "2804/2804 [==============================] - 1s 270us/step - loss: 0.3993 - val_loss: 0.4785\n",
      "Epoch 48/50\n",
      "2804/2804 [==============================] - 1s 270us/step - loss: 0.4012 - val_loss: 0.4794\n",
      "Epoch 49/50\n",
      "2804/2804 [==============================] - 1s 273us/step - loss: 0.3978 - val_loss: 0.4777\n",
      "Epoch 50/50\n",
      "2804/2804 [==============================] - 2s 622us/step - loss: 0.3809 - val_loss: 0.4790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129c0bcb940>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mining_model.fit([train_atoms,train_bonds,train_edges,train.Binary],Y_dummy,\n",
    "                 epochs = 50,\n",
    "                 batch_size = 256,\n",
    "                 shuffle = True,\n",
    "                 validation_data=([val_atoms, val_bonds, val_edges,val.Binary],Y_dummy_val),\n",
    "                 callbacks=[es,rlr2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_val = gcn_model.predict([val_atoms, val_bonds, val_edges])\n",
    "df_embeddings = pd.DataFrame(embeddings_val)\n",
    "#df_embeddings.to_csv(\"/Users/tomas/Desktop/binding/p38_splits/embeddings_new_splits/fold_0/embeddings_val.csv\")\n",
    "#val.to_csv(\"/Users/tomas/Desktop/binding/p38_splits/embeddings_new_splits/fold_0/val_0.csv\")\n",
    "embeddings_train = gcn_model.predict([train_atoms, train_bonds, train_edges])\n",
    "df_embeddings_train = pd.DataFrame(embeddings_train)\n",
    "#df_embeddings_train.to_csv(\"/Users/tomas/Desktop/binding/p38_splits/embeddings_new_splits/fold_0/embeddings_train.csv\")\n",
    "#train.to_csv(\"/Users/tomas/Desktop/binding/p38_splits/embeddings_new_splits/fold_0/train_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, plots=False):\n",
    "    assert isinstance(y_true, np.ndarray), 'y_true should be np.array'\n",
    "    assert len(y_true.shape) == len(y_pred.shape) == 1, 'y_true or y_pred shapes are not 1 (probably not squeezed)'\n",
    "    y_pred_bin = y_pred > 0.5\n",
    "\n",
    "    cf = confusion_matrix(y_true, y_pred_bin)\n",
    "    tn, fp, fn, tp = cf.ravel()\n",
    "\n",
    "    metrics = {\n",
    "        'roc_auc': roc_auc_score(y_true, y_pred),\n",
    "        'tn': tn,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'tp': tp,\n",
    "        'map': average_precision_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred_bin),\n",
    "        'recall': recall_score(y_true, y_pred_bin),\n",
    "        'accuracy': accuracy_score(y_true, y_pred_bin),\n",
    "    }\n",
    "\n",
    "    if plots:\n",
    "        print('predictions histogram')\n",
    "        plt.figure()\n",
    "        plt.hist(y_pred, bins=int(len(y_pred) / 3))\n",
    "        plt.show()\n",
    "\n",
    "        print('confusion matrix')\n",
    "        plt.figure()\n",
    "        group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "        group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                        cf.flatten()]\n",
    "        group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                             cf.flatten() / np.sum(cf)]\n",
    "        labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "                  zip(group_names, group_counts, group_percentages)]\n",
    "        labels = np.asarray(labels).reshape(2, 2)\n",
    "        sns.heatmap(cf, annot=labels, fmt='', cmap='Blues')\n",
    "        plt.show()\n",
    "\n",
    "        print('roc curve')\n",
    "        random_probs = [0 for _ in range(len(y_true))]\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        print('Logistic: ROC AUC=%.3f' % (auc))\n",
    "        ns_fpr, ns_tpr, _ = roc_curve(y_true, random_probs)\n",
    "        lr_fpr, lr_tpr, _ = roc_curve(y_true, y_pred)\n",
    "        plt.plot(ns_fpr, ns_tpr, linestyle='--', label='random')\n",
    "        plt.plot(lr_fpr, lr_tpr, marker='.')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "        \"colsample_bylevel\" : 0.8252200966638428,\n",
    "        \"colsample_bytree\" : 0.6160,\n",
    "        \"gamma\" : 0.2070,\n",
    "        \"eta\" : 0.5903,\n",
    "        \"max_delta_step\" : 3,\n",
    "        \"max_depth\" : 8,\n",
    "        \"min_child_weight\" : 70,\n",
    "        \"alpha\" : 21.24299,\n",
    "        \"lambda\" : 38.191928,\n",
    "        \"subsample\" : 0.87876195660726,\n",
    "        \"eval_metric\":'auc',\n",
    "        \"objective\":'binary:logistic',\n",
    "        \"booster\":'gbtree',\n",
    "        \"tree_method\" : 'gpu_hist',\n",
    "        \"single_precision_histogram\" : True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_binary = train.Binary\n",
    "labels_val = val.Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmatrix_train = xgb.DMatrix(data = embeddings_train,label = labels_binary)\n",
    "dmatrix_val = xgb.DMatrix(data = embeddings_val,label = labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalist = [(dmatrix_val,'eval'),(dmatrix_train,'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.57050\ttrain-auc:0.91788\n",
      "[1]\teval-auc:0.57002\ttrain-auc:0.94278\n",
      "[2]\teval-auc:0.56746\ttrain-auc:0.95308\n",
      "[3]\teval-auc:0.57031\ttrain-auc:0.96209\n",
      "[4]\teval-auc:0.58003\ttrain-auc:0.96495\n",
      "[5]\teval-auc:0.57958\ttrain-auc:0.96853\n",
      "[6]\teval-auc:0.57995\ttrain-auc:0.97022\n",
      "[7]\teval-auc:0.60167\ttrain-auc:0.97102\n",
      "[8]\teval-auc:0.62346\ttrain-auc:0.97115\n",
      "[9]\teval-auc:0.61752\ttrain-auc:0.97167\n",
      "[10]\teval-auc:0.62363\ttrain-auc:0.97175\n",
      "[11]\teval-auc:0.62471\ttrain-auc:0.97206\n",
      "[12]\teval-auc:0.62252\ttrain-auc:0.97255\n",
      "[13]\teval-auc:0.62271\ttrain-auc:0.97263\n",
      "[14]\teval-auc:0.62279\ttrain-auc:0.97266\n",
      "[15]\teval-auc:0.62365\ttrain-auc:0.97273\n",
      "[16]\teval-auc:0.62511\ttrain-auc:0.97300\n",
      "[17]\teval-auc:0.63289\ttrain-auc:0.97318\n",
      "[18]\teval-auc:0.63521\ttrain-auc:0.97328\n",
      "[19]\teval-auc:0.65243\ttrain-auc:0.97350\n",
      "[20]\teval-auc:0.65237\ttrain-auc:0.97364\n",
      "[21]\teval-auc:0.65576\ttrain-auc:0.97363\n",
      "[22]\teval-auc:0.65630\ttrain-auc:0.97370\n",
      "[23]\teval-auc:0.65212\ttrain-auc:0.97373\n",
      "[24]\teval-auc:0.65202\ttrain-auc:0.97377\n",
      "[25]\teval-auc:0.65057\ttrain-auc:0.97382\n",
      "[26]\teval-auc:0.65107\ttrain-auc:0.97385\n",
      "[27]\teval-auc:0.65107\ttrain-auc:0.97385\n",
      "[28]\teval-auc:0.65100\ttrain-auc:0.97389\n",
      "[29]\teval-auc:0.64728\ttrain-auc:0.97392\n",
      "[30]\teval-auc:0.64789\ttrain-auc:0.97393\n",
      "[31]\teval-auc:0.64773\ttrain-auc:0.97394\n",
      "[32]\teval-auc:0.64916\ttrain-auc:0.97396\n",
      "[33]\teval-auc:0.64963\ttrain-auc:0.97396\n",
      "[34]\teval-auc:0.64706\ttrain-auc:0.97399\n",
      "[35]\teval-auc:0.64685\ttrain-auc:0.97401\n",
      "[36]\teval-auc:0.64569\ttrain-auc:0.97405\n",
      "[37]\teval-auc:0.64569\ttrain-auc:0.97405\n",
      "[38]\teval-auc:0.64569\ttrain-auc:0.97405\n",
      "[39]\teval-auc:0.64569\ttrain-auc:0.97405\n",
      "[40]\teval-auc:0.64575\ttrain-auc:0.97407\n",
      "[41]\teval-auc:0.64607\ttrain-auc:0.97408\n",
      "[42]\teval-auc:0.64607\ttrain-auc:0.97408\n",
      "[43]\teval-auc:0.64607\ttrain-auc:0.97408\n",
      "[44]\teval-auc:0.64607\ttrain-auc:0.97408\n",
      "[45]\teval-auc:0.64388\ttrain-auc:0.97409\n",
      "[46]\teval-auc:0.64388\ttrain-auc:0.97409\n",
      "[47]\teval-auc:0.64509\ttrain-auc:0.97411\n",
      "[48]\teval-auc:0.64486\ttrain-auc:0.97412\n",
      "[49]\teval-auc:0.65097\ttrain-auc:0.97414\n",
      "[50]\teval-auc:0.65240\ttrain-auc:0.97416\n",
      "[51]\teval-auc:0.65402\ttrain-auc:0.97421\n",
      "[52]\teval-auc:0.65402\ttrain-auc:0.97421\n",
      "[53]\teval-auc:0.65406\ttrain-auc:0.97422\n",
      "[54]\teval-auc:0.65406\ttrain-auc:0.97422\n",
      "[55]\teval-auc:0.65406\ttrain-auc:0.97422\n",
      "[56]\teval-auc:0.65406\ttrain-auc:0.97422\n",
      "[57]\teval-auc:0.65383\ttrain-auc:0.97423\n",
      "[58]\teval-auc:0.65383\ttrain-auc:0.97423\n",
      "[59]\teval-auc:0.65383\ttrain-auc:0.97423\n",
      "[60]\teval-auc:0.65383\ttrain-auc:0.97423\n",
      "[61]\teval-auc:0.65256\ttrain-auc:0.97423\n",
      "[62]\teval-auc:0.65256\ttrain-auc:0.97423\n",
      "[63]\teval-auc:0.65256\ttrain-auc:0.97423\n",
      "[64]\teval-auc:0.65256\ttrain-auc:0.97423\n",
      "[65]\teval-auc:0.65256\ttrain-auc:0.97423\n",
      "[66]\teval-auc:0.65256\ttrain-auc:0.97423\n",
      "[67]\teval-auc:0.65256\ttrain-auc:0.97423\n",
      "[68]\teval-auc:0.65064\ttrain-auc:0.97425\n",
      "[69]\teval-auc:0.65064\ttrain-auc:0.97425\n",
      "[70]\teval-auc:0.65064\ttrain-auc:0.97425\n",
      "[71]\teval-auc:0.65064\ttrain-auc:0.97425\n",
      "[72]\teval-auc:0.65064\ttrain-auc:0.97425\n",
      "[73]\teval-auc:0.65181\ttrain-auc:0.97427\n",
      "[74]\teval-auc:0.65181\ttrain-auc:0.97431\n",
      "[75]\teval-auc:0.65181\ttrain-auc:0.97431\n",
      "[76]\teval-auc:0.65264\ttrain-auc:0.97432\n",
      "[77]\teval-auc:0.65264\ttrain-auc:0.97432\n",
      "[78]\teval-auc:0.65264\ttrain-auc:0.97432\n",
      "[79]\teval-auc:0.65264\ttrain-auc:0.97432\n",
      "[80]\teval-auc:0.65264\ttrain-auc:0.97432\n",
      "[81]\teval-auc:0.65264\ttrain-auc:0.97432\n",
      "[82]\teval-auc:0.65264\ttrain-auc:0.97432\n",
      "[83]\teval-auc:0.65264\ttrain-auc:0.97432\n",
      "[84]\teval-auc:0.64928\ttrain-auc:0.97436\n",
      "[85]\teval-auc:0.64900\ttrain-auc:0.97438\n",
      "[86]\teval-auc:0.64900\ttrain-auc:0.97438\n",
      "[87]\teval-auc:0.64753\ttrain-auc:0.97437\n",
      "[88]\teval-auc:0.64753\ttrain-auc:0.97437\n",
      "[89]\teval-auc:0.64753\ttrain-auc:0.97437\n",
      "[90]\teval-auc:0.64753\ttrain-auc:0.97437\n",
      "[91]\teval-auc:0.64753\ttrain-auc:0.97437\n",
      "[92]\teval-auc:0.64753\ttrain-auc:0.97437\n",
      "[93]\teval-auc:0.64725\ttrain-auc:0.97437\n",
      "[94]\teval-auc:0.64725\ttrain-auc:0.97437\n",
      "[95]\teval-auc:0.64725\ttrain-auc:0.97437\n",
      "[96]\teval-auc:0.64725\ttrain-auc:0.97437\n",
      "[97]\teval-auc:0.64725\ttrain-auc:0.97437\n",
      "[98]\teval-auc:0.64725\ttrain-auc:0.97437\n",
      "[99]\teval-auc:0.64725\ttrain-auc:0.97437\n",
      "[100]\teval-auc:0.64661\ttrain-auc:0.97443\n",
      "[101]\teval-auc:0.64664\ttrain-auc:0.97446\n",
      "[102]\teval-auc:0.64664\ttrain-auc:0.97446\n",
      "[103]\teval-auc:0.64664\ttrain-auc:0.97446\n",
      "[104]\teval-auc:0.64664\ttrain-auc:0.97452\n",
      "[105]\teval-auc:0.64719\ttrain-auc:0.97452\n",
      "[106]\teval-auc:0.64719\ttrain-auc:0.97452\n",
      "[107]\teval-auc:0.64719\ttrain-auc:0.97452\n",
      "[108]\teval-auc:0.64715\ttrain-auc:0.97454\n",
      "[109]\teval-auc:0.64715\ttrain-auc:0.97454\n",
      "[110]\teval-auc:0.64677\ttrain-auc:0.97455\n",
      "[111]\teval-auc:0.64677\ttrain-auc:0.97455\n",
      "[112]\teval-auc:0.64677\ttrain-auc:0.97455\n",
      "[113]\teval-auc:0.64677\ttrain-auc:0.97455\n",
      "[114]\teval-auc:0.64677\ttrain-auc:0.97455\n",
      "[115]\teval-auc:0.64680\ttrain-auc:0.97455\n",
      "[116]\teval-auc:0.64680\ttrain-auc:0.97455\n",
      "[117]\teval-auc:0.64680\ttrain-auc:0.97458\n",
      "[118]\teval-auc:0.64680\ttrain-auc:0.97458\n",
      "[119]\teval-auc:0.64680\ttrain-auc:0.97458\n",
      "[120]\teval-auc:0.64680\ttrain-auc:0.97458\n",
      "[121]\teval-auc:0.64677\ttrain-auc:0.97462\n",
      "[122]\teval-auc:0.64677\ttrain-auc:0.97462\n",
      "[123]\teval-auc:0.64677\ttrain-auc:0.97462\n",
      "[124]\teval-auc:0.64703\ttrain-auc:0.97463\n",
      "[125]\teval-auc:0.64703\ttrain-auc:0.97463\n",
      "[126]\teval-auc:0.64703\ttrain-auc:0.97463\n",
      "[127]\teval-auc:0.64696\ttrain-auc:0.97465\n",
      "[128]\teval-auc:0.64696\ttrain-auc:0.97465\n",
      "[129]\teval-auc:0.64696\ttrain-auc:0.97465\n",
      "[130]\teval-auc:0.64699\ttrain-auc:0.97469\n",
      "[131]\teval-auc:0.64655\ttrain-auc:0.97471\n",
      "[132]\teval-auc:0.64655\ttrain-auc:0.97471\n",
      "[133]\teval-auc:0.64419\ttrain-auc:0.97471\n",
      "[134]\teval-auc:0.64346\ttrain-auc:0.97473\n",
      "[135]\teval-auc:0.64346\ttrain-auc:0.97473\n",
      "[136]\teval-auc:0.64342\ttrain-auc:0.97473\n",
      "[137]\teval-auc:0.64342\ttrain-auc:0.97473\n",
      "[138]\teval-auc:0.64342\ttrain-auc:0.97473\n",
      "[139]\teval-auc:0.64342\ttrain-auc:0.97473\n",
      "[140]\teval-auc:0.64342\ttrain-auc:0.97473\n",
      "[141]\teval-auc:0.64342\ttrain-auc:0.97473\n",
      "[142]\teval-auc:0.64342\ttrain-auc:0.97473\n",
      "[143]\teval-auc:0.64342\ttrain-auc:0.97473\n",
      "[144]\teval-auc:0.64342\ttrain-auc:0.97475\n",
      "[145]\teval-auc:0.64342\ttrain-auc:0.97475\n",
      "[146]\teval-auc:0.64071\ttrain-auc:0.97479\n",
      "[147]\teval-auc:0.64071\ttrain-auc:0.97479\n",
      "[148]\teval-auc:0.64071\ttrain-auc:0.97479\n",
      "[149]\teval-auc:0.64192\ttrain-auc:0.97477\n",
      "[150]\teval-auc:0.64027\ttrain-auc:0.97479\n",
      "[151]\teval-auc:0.64027\ttrain-auc:0.97479\n",
      "[152]\teval-auc:0.64027\ttrain-auc:0.97479\n",
      "[153]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[154]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[155]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[156]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[157]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[158]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[159]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[160]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[161]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[162]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[163]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[164]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[165]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[166]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[167]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[168]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[169]\teval-auc:0.63960\ttrain-auc:0.97480\n",
      "[170]\teval-auc:0.63944\ttrain-auc:0.97485\n",
      "[171]\teval-auc:0.63947\ttrain-auc:0.97486\n",
      "[172]\teval-auc:0.63947\ttrain-auc:0.97486\n",
      "[173]\teval-auc:0.63947\ttrain-auc:0.97486\n",
      "[174]\teval-auc:0.63947\ttrain-auc:0.97486\n",
      "[175]\teval-auc:0.63947\ttrain-auc:0.97486\n",
      "[176]\teval-auc:0.63947\ttrain-auc:0.97486\n",
      "[177]\teval-auc:0.63896\ttrain-auc:0.97488\n",
      "[178]\teval-auc:0.63896\ttrain-auc:0.97488\n",
      "[179]\teval-auc:0.63896\ttrain-auc:0.97488\n",
      "[180]\teval-auc:0.63896\ttrain-auc:0.97488\n",
      "[181]\teval-auc:0.63896\ttrain-auc:0.97489\n",
      "[182]\teval-auc:0.63896\ttrain-auc:0.97489\n",
      "[183]\teval-auc:0.63896\ttrain-auc:0.97489\n",
      "[184]\teval-auc:0.63896\ttrain-auc:0.97489\n",
      "[185]\teval-auc:0.63896\ttrain-auc:0.97489\n",
      "[186]\teval-auc:0.63896\ttrain-auc:0.97492\n",
      "[187]\teval-auc:0.63896\ttrain-auc:0.97492\n",
      "[188]\teval-auc:0.63896\ttrain-auc:0.97492\n",
      "[189]\teval-auc:0.63896\ttrain-auc:0.97492\n",
      "[190]\teval-auc:0.63899\ttrain-auc:0.97493\n",
      "[191]\teval-auc:0.63899\ttrain-auc:0.97493\n",
      "[192]\teval-auc:0.63899\ttrain-auc:0.97493\n",
      "[193]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[194]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[195]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[196]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[197]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[198]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[199]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[200]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[201]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[202]\teval-auc:0.63896\ttrain-auc:0.97493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[203]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[204]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[205]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[206]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[207]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[208]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[209]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[210]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[211]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[212]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[213]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[214]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[215]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[216]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[217]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[218]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[219]\teval-auc:0.63896\ttrain-auc:0.97493\n",
      "[220]\teval-auc:0.64033\ttrain-auc:0.97493\n",
      "[221]\teval-auc:0.64033\ttrain-auc:0.97493\n",
      "[222]\teval-auc:0.64033\ttrain-auc:0.97493\n",
      "[223]\teval-auc:0.64033\ttrain-auc:0.97493\n",
      "[224]\teval-auc:0.64033\ttrain-auc:0.97493\n",
      "[225]\teval-auc:0.64033\ttrain-auc:0.97493\n",
      "[226]\teval-auc:0.64033\ttrain-auc:0.97493\n",
      "[227]\teval-auc:0.64033\ttrain-auc:0.97493\n",
      "[228]\teval-auc:0.64033\ttrain-auc:0.97493\n",
      "[229]\teval-auc:0.64033\ttrain-auc:0.97493\n",
      "[230]\teval-auc:0.63992\ttrain-auc:0.97496\n",
      "[231]\teval-auc:0.63992\ttrain-auc:0.97496\n",
      "[232]\teval-auc:0.63992\ttrain-auc:0.97496\n",
      "[233]\teval-auc:0.63992\ttrain-auc:0.97496\n",
      "[234]\teval-auc:0.63992\ttrain-auc:0.97496\n",
      "[235]\teval-auc:0.63992\ttrain-auc:0.97496\n",
      "[236]\teval-auc:0.63992\ttrain-auc:0.97496\n",
      "[237]\teval-auc:0.63992\ttrain-auc:0.97496\n",
      "[238]\teval-auc:0.63992\ttrain-auc:0.97496\n",
      "[239]\teval-auc:0.63992\ttrain-auc:0.97497\n",
      "[240]\teval-auc:0.63992\ttrain-auc:0.97497\n",
      "[241]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[242]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[243]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[244]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[245]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[246]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[247]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[248]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[249]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[250]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[251]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[252]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[253]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[254]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[255]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[256]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[257]\teval-auc:0.63995\ttrain-auc:0.97497\n",
      "[258]\teval-auc:0.64014\ttrain-auc:0.97499\n",
      "[259]\teval-auc:0.64014\ttrain-auc:0.97499\n",
      "[260]\teval-auc:0.64014\ttrain-auc:0.97499\n",
      "[261]\teval-auc:0.64014\ttrain-auc:0.97499\n",
      "[262]\teval-auc:0.64014\ttrain-auc:0.97499\n",
      "[263]\teval-auc:0.64014\ttrain-auc:0.97499\n",
      "[264]\teval-auc:0.64014\ttrain-auc:0.97499\n",
      "[265]\teval-auc:0.64014\ttrain-auc:0.97499\n",
      "[266]\teval-auc:0.64014\ttrain-auc:0.97499\n",
      "[267]\teval-auc:0.64014\ttrain-auc:0.97499\n",
      "[268]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[269]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[270]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[271]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[272]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[273]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[274]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[275]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[276]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[277]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[278]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[279]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[280]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[281]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[282]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[283]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[284]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[285]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[286]\teval-auc:0.64062\ttrain-auc:0.97500\n",
      "[287]\teval-auc:0.64148\ttrain-auc:0.97499\n",
      "[288]\teval-auc:0.63868\ttrain-auc:0.97502\n",
      "[289]\teval-auc:0.63868\ttrain-auc:0.97502\n",
      "[290]\teval-auc:0.63868\ttrain-auc:0.97502\n",
      "[291]\teval-auc:0.63868\ttrain-auc:0.97502\n",
      "[292]\teval-auc:0.63868\ttrain-auc:0.97502\n",
      "[293]\teval-auc:0.63868\ttrain-auc:0.97502\n",
      "[294]\teval-auc:0.63868\ttrain-auc:0.97502\n",
      "[295]\teval-auc:0.63868\ttrain-auc:0.97502\n",
      "[296]\teval-auc:0.63868\ttrain-auc:0.97502\n",
      "[297]\teval-auc:0.63868\ttrain-auc:0.97502\n",
      "[298]\teval-auc:0.63868\ttrain-auc:0.97502\n",
      "[299]\teval-auc:0.63868\ttrain-auc:0.97502\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(hyper_params,dmatrix_train,300,evalist,verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = model.predict(dmatrix_val)\n",
    "y_pred_train = model.predict(dmatrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_metrics= calculate_metrics(np.array(labels_val),y_pred_val)\n",
    "training_metrics = calculate_metrics(np.array(labels_binary),y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.638676844783715,\n",
       " 'tn': 233,\n",
       " 'fp': 29,\n",
       " 'fn': 92,\n",
       " 'tp': 28,\n",
       " 'map': 0.47165914144497295,\n",
       " 'precision': 0.49122807017543857,\n",
       " 'recall': 0.23333333333333334,\n",
       " 'accuracy': 0.6832460732984293}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.975019210504324,\n",
       " 'tn': 1212,\n",
       " 'fp': 134,\n",
       " 'fn': 117,\n",
       " 'tp': 1341,\n",
       " 'map': 0.9780558686566379,\n",
       " 'precision': 0.9091525423728813,\n",
       " 'recall': 0.9197530864197531,\n",
       " 'accuracy': 0.9104850213980028}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
