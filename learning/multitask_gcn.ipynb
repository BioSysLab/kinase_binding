{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.callbacks import History, ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "from data_analysis import calculate_metrics, load_weights_and_evaluate\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, roc_auc_score, auc, average_precision_score\n",
    "#import scikitplot as skplt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from NGF.preprocessing import tensorise_smiles\n",
    "from custom_layers.model_creator import encode_smiles, stage_creator\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, concatenate,Flatten\n",
    "from keras.models import Model, load_model\n",
    "import dill\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1 = 'p38'\n",
    "base_path_1 = f'C:/Users/tomas/Documents/GitHub/kinase_binding'\n",
    "\n",
    "data_fpath_1 = base_path_1+f'/data/{target_1}/data.csv'\n",
    "df_p38=pd.read_csv(data_fpath_1).set_index('biolab_index')\n",
    "\n",
    "with open(base_path_1+f'/data/{target_1}/train_val_folds.pkl', \"rb\") as in_f:\n",
    "    train_val_folds_p38 = dill.load(in_f)\n",
    "\n",
    "with open(base_path_1+f'/data/{target_1}/train_test_folds.pkl', \"rb\") as in_f:\n",
    "    train_test_folds_p38 = dill.load(in_f)\n",
    "    \n",
    "target_2 = 'akt1'\n",
    "base_path_2 = f'C:/Users/tomas/Documents/GitHub/kinase_binding'\n",
    "\n",
    "data_fpath_2 = base_path_2+f'/data/{target_2}/data.csv'\n",
    "df_akt1 = pd.read_csv(data_fpath_2).set_index('biolab_index')\n",
    "\n",
    "with open(base_path_2+f'/data/{target_2}/train_val_folds.pkl', \"rb\") as in_f:\n",
    "    train_val_folds_akt1 = dill.load(in_f)\n",
    "with open(base_path_2+f'/data/{target_2}/train_test_folds.pkl', \"rb\") as in_f:\n",
    "    train_test_folds_akt1 = dill.load(in_f)\n",
    "    \n",
    "target_3 = 'pi3k'\n",
    "base_path_3 = f'C:/Users/tomas/Documents/GitHub/kinase_binding'\n",
    "\n",
    "data_fpath_3 = base_path_3+f'/data/{target_3}/data.csv'\n",
    "df_pi3k = pd.read_csv(data_fpath_3).set_index('biolab_index')\n",
    "\n",
    "with open(base_path_3+f'/data/{target_3}/train_val_folds.pkl', \"rb\") as in_f:\n",
    "    train_val_folds_pi3k = dill.load(in_f)\n",
    "with open(base_path_3+f'/data/{target_3}/train_test_folds.pkl', \"rb\") as in_f:\n",
    "    train_test_folds_pi3k = dill.load(in_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_p38 = [df_p38.loc[train_val_folds_p38[0][0]],\n",
    "                 df_p38.loc[train_val_folds_p38[1][0]],\n",
    "                 df_p38.loc[train_val_folds_p38[2][0]],\n",
    "                 df_p38.loc[train_val_folds_p38[3][0]],\n",
    "                 df_p38.loc[train_val_folds_p38[4][0]],\n",
    "                 df_p38.loc[train_val_folds_p38[5][0]],\n",
    "                 df_p38.loc[train_test_folds_p38[0]]\n",
    "                 ]\n",
    "validation_p38 = [df_p38.loc[train_val_folds_p38[0][1]],\n",
    "                   df_p38.loc[train_val_folds_p38[1][1]],\n",
    "                   df_p38.loc[train_val_folds_p38[2][1]],\n",
    "                   df_p38.loc[train_val_folds_p38[3][1]],\n",
    "                   df_p38.loc[train_val_folds_p38[4][1]],\n",
    "                   df_p38.loc[train_val_folds_p38[5][1]],\n",
    "                   df_p38.loc[train_test_folds_p38[1]]\n",
    "                   ]\n",
    "\n",
    "training_akt1 = [df_akt1.loc[train_val_folds_akt1[0][0]],\n",
    "                 df_akt1.loc[train_val_folds_akt1[1][0]],\n",
    "                 df_akt1.loc[train_val_folds_akt1[2][0]],\n",
    "                 df_akt1.loc[train_val_folds_akt1[3][0]],\n",
    "                 df_akt1.loc[train_val_folds_akt1[4][0]],\n",
    "                 df_akt1.loc[train_val_folds_akt1[5][0]],\n",
    "                 df_akt1.loc[train_test_folds_akt1[0]]\n",
    "                 ]\n",
    "validation_akt1 = [df_akt1.loc[train_val_folds_akt1[0][1]],\n",
    "                   df_akt1.loc[train_val_folds_akt1[1][1]],\n",
    "                   df_akt1.loc[train_val_folds_akt1[2][1]],\n",
    "                   df_akt1.loc[train_val_folds_akt1[3][1]],\n",
    "                   df_akt1.loc[train_val_folds_akt1[4][1]],\n",
    "                   df_akt1.loc[train_val_folds_akt1[5][1]],\n",
    "                   df_akt1.loc[train_test_folds_akt1[1]]\n",
    "                   ]\n",
    "\n",
    "training_pi3k = [df_pi3k.loc[train_val_folds_pi3k[0][0]],\n",
    "                 df_pi3k.loc[train_val_folds_pi3k[1][0]],\n",
    "                 df_pi3k.loc[train_val_folds_pi3k[2][0]],\n",
    "                 df_pi3k.loc[train_val_folds_pi3k[3][0]],\n",
    "                 df_pi3k.loc[train_val_folds_pi3k[4][0]],\n",
    "                 df_pi3k.loc[train_val_folds_pi3k[5][0]],\n",
    "                 df_pi3k.loc[train_test_folds_pi3k[0]]\n",
    "                 ]\n",
    "validation_pi3k = [df_pi3k.loc[train_val_folds_pi3k[0][1]],\n",
    "                   df_pi3k.loc[train_val_folds_pi3k[1][1]],\n",
    "                   df_pi3k.loc[train_val_folds_pi3k[2][1]],\n",
    "                   df_pi3k.loc[train_val_folds_pi3k[3][1]],\n",
    "                   df_pi3k.loc[train_val_folds_pi3k[4][1]],\n",
    "                   df_pi3k.loc[train_val_folds_pi3k[5][1]],\n",
    "                   df_pi3k.loc[train_test_folds_pi3k[1]]\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss',patience=8, min_delta=0)\n",
    "rlr = ReduceLROnPlateau(monitor='loss',factor=0.5, patience=4, verbose=1, min_lr=0.0000001)\n",
    "model_params = {\n",
    "        \"num_layers\" : 3,\n",
    "        \"max_atoms\" : 70,\n",
    "        \"num_atom_features\" : 62,\n",
    "        \"num_atom_features_original\" : 62,\n",
    "        \"num_bond_features\" : 6,\n",
    "        \"max_degree\" : 5,\n",
    "        \"conv_width\" : [int(96), int(104), int(120)],\n",
    "        \"fp_length\" : [int(160), int(160), int(160)],\n",
    "        \"activ_enc\" : \"selu\",\n",
    "        \"activ_dec\" : \"selu\",\n",
    "        \"learning_rates\" : [0.001,0.001,0.001],\n",
    "        \"learning_rates_fp\": [0.005,0.005,0.005],\n",
    "        \"losses_conv\" : {\n",
    "                    \"neighbor_output\": \"mean_squared_error\",\n",
    "                    \"self_output\": \"mean_squared_error\",\n",
    "                    },\n",
    "        \"lossWeights\" : {\"neighbor_output\": 1.0, \"self_output\": 1.0},\n",
    "        \"metrics\" : \"mse\",\n",
    "        \"loss_fp\" : \"mean_squared_error\",\n",
    "        \"enc_layer_names\" : [\"enc_1\", \"enc_2\", \"enc_3\"],\n",
    "        'callbacks' : [es,rlr],\n",
    "        'adam_decay': 0.0005329142291371636,\n",
    "        'beta': 5,\n",
    "        'p': 0.004465204118126482,\n",
    "        'dense_size' : [int(256), int(192), int(96)], \n",
    "        'dropout_rate' : [0.355453731255706, 0.355453731255706],\n",
    "        'lr' : 0.007037117031430456,\n",
    "        'batch_size' : int(64),\n",
    "        'n_epochs' : int(50),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_generator_MLT(bs,\n",
    "                      df_p1,df_p2,df_p3,\n",
    "                      smiles_list_p1,smiles_list_p2,smiles_list_p3,\n",
    "                      atoms_p1,bonds_p1,edges_p1,\n",
    "                      atoms_p2,bonds_p2,edges_p2,\n",
    "                      atoms_p3,bonds_p3,edges_p3,mode = 'train',aug = None):\n",
    "    counter=int(0)\n",
    "    #Keep looping indefinetely\n",
    "    df_p1 = df_p1.reset_index(drop=True)\n",
    "    df_p2 = df_p2.reset_index(drop=True)\n",
    "    df_p3 = df_p3.reset_index(drop=True)\n",
    "    while True:\n",
    "        \n",
    "        #Initialize batches of inputs and outputs\n",
    "        ind1 = []\n",
    "        ind2 = []\n",
    "        ind3 = []\n",
    "        \n",
    "        d_p1=[]\n",
    "        d_p2=[]\n",
    "        d_p3=[]\n",
    "        \n",
    "        #Keep looping until we reach batch size\n",
    "        while len(ind2)<=bs: #doesn't matter if it is smi1 or smi2 since they have the same len\n",
    "            \n",
    "            # check to see if you reached the end of the frame\n",
    "            if counter==len(df_p2):\n",
    "                counter=int(0)\n",
    "                df_p1 = df_p1.sample(frac=1).reset_index(drop=True)\n",
    "                df_p2 = df_p2.sample(frac=1).reset_index(drop=True)\n",
    "                df_p3 = df_p3.sample(frac=1).reset_index(drop=True)\n",
    "                # if we are evaluating we should now break from our \n",
    "                # loop to ensure we don't continue to fill up the batch from samples at the beginning of the file\n",
    "                \n",
    "                if mode==\"eval\":\n",
    "                    break\n",
    "            \n",
    "            \n",
    "\n",
    "            smi_p1 = df_p1['rdkit'][counter]\n",
    "            smi_p2 = df_p2['rdkit'][counter]\n",
    "            smi_p3 = df_p3['rdkit'][counter]\n",
    "            ind1.append(smiles_list_p1.index(smi_p1))\n",
    "            ind2.append(smiles_list_p2.index(smi_p2))\n",
    "            ind3.append(smiles_list_p3.index(smi_p3))\n",
    "            d_p1.append(df_p1['Binary'][counter])\n",
    "            d_p2.append(df_p2['Binary'][counter])\n",
    "            d_p3.append(df_p3['Binary'][counter])\n",
    "            counter+=1\n",
    "            \n",
    "        atoms_target_1 = np.array(atoms_p1[ind1],dtype = 'float32')\n",
    "        bonds_target_1 = np.array(bonds_p1[ind1],dtype = 'float32')\n",
    "        edges_target_1 = np.array(edges_p1[ind1],dtype = 'int32')\n",
    "        \n",
    "        \n",
    "        atoms_target_2 = np.array(atoms_p2[ind2],dtype = 'float32')\n",
    "        bonds_target_2 = np.array(bonds_p2[ind2],dtype = 'float32')\n",
    "        edges_target_2 = np.array(edges_p2[ind2],dtype = 'int32')\n",
    "        \n",
    "        \n",
    "        atoms_target_3 = np.array(atoms_p3[ind3],dtype = 'float32')\n",
    "        bonds_target_3 = np.array(bonds_p3[ind3],dtype = 'float32')\n",
    "        edges_target_3 = np.array(edges_p3[ind3],dtype = 'int32')\n",
    "        \n",
    "        \n",
    "        yield ({'atom_inputs_1':atoms_target_1,\n",
    "                'bond_inputs_1':bonds_target_1,\n",
    "                'edge_inputs_1':edges_target_1,\n",
    "                'atom_inputs_2':atoms_target_2,\n",
    "                'bond_inputs_2':bonds_target_2,\n",
    "                'edge_inputs_2':edges_target_2,\n",
    "                'atom_inputs_3':atoms_target_3,\n",
    "                'bond_inputs_3':bonds_target_3,\n",
    "                'edge_inputs_3':edges_target_3,},{'Protein_1':np.array(d_p1,dtype = 'float32'),\n",
    "                                                  'Protein_2':np.array(d_p2,dtype = 'float32'),\n",
    "                                                  'Protein_3':np.array(d_p3,dtype = 'float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(dimension, start, end):\n",
    "    # Crops (or slices) a Tensor on a given dimension from start to end\n",
    "    # example : to crop tensor x[:, :, 5:10]\n",
    "    # call slice(2, 5, 10) as you want to crop on the second dimension\n",
    "        def func(x):\n",
    "            if dimension == 0:\n",
    "                return x[start: end]\n",
    "            if dimension == 1:\n",
    "                return x[:, start: end]\n",
    "            if dimension == 2:\n",
    "                return x[:, :, start: end]\n",
    "            if dimension == 3:\n",
    "                return x[:, :, :, start: end]\n",
    "            if dimension == 4:\n",
    "                return x[:, :, :, :, start: end]\n",
    "        return Lambda(func)\n",
    "class GCN_MLT(object):\n",
    "\n",
    "    def __init__(self,  model_params):\n",
    "        self.model_params = model_params\n",
    "\n",
    "    def build_encoder(self):\n",
    "        model_enc_1 = stage_creator(self.model_params, 1, conv=True)[0]\n",
    "        model_enc_2 = stage_creator(self.model_params, 2, conv=True)[0]\n",
    "        model_enc_3 = stage_creator(self.model_params, 3, conv=True)[0]\n",
    "\n",
    "        model_enc_fp_1 = stage_creator(self.model_params, 1, conv=False)[1]\n",
    "        model_enc_fp_2 = stage_creator(self.model_params, 2, conv=False)[1]\n",
    "        model_enc_fp_3 = stage_creator(self.model_params, 3, conv=False)[1]\n",
    "\n",
    "        atoms, bonds, edges = encode_smiles(self.model_params[\"max_atoms\"],\n",
    "                                            self.model_params[\"num_atom_features\"],\n",
    "                                            self.model_params[\"max_degree\"],\n",
    "                                            self.model_params[\"num_bond_features\"])\n",
    "\n",
    "        graph_conv_1 = model_enc_1([atoms, bonds, edges])\n",
    "        graph_conv_2 = model_enc_2([graph_conv_1, bonds, edges])\n",
    "        graph_conv_3 = model_enc_3([graph_conv_2, bonds, edges])\n",
    "\n",
    "        fingerprint_1 = model_enc_fp_1([graph_conv_1, bonds, edges])\n",
    "        fingerprint_1 = Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0], s[2]))(fingerprint_1)\n",
    "\n",
    "        fingerprint_2 = model_enc_fp_2([graph_conv_2, bonds, edges])\n",
    "        fingerprint_2 = Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0], s[2]))(fingerprint_2)\n",
    "\n",
    "        fingerprint_3 = model_enc_fp_3([graph_conv_3, bonds, edges])\n",
    "        fingerprint_3 = Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0], s[2]))(fingerprint_3)\n",
    "\n",
    "        final_fingerprint = keras.layers.add([fingerprint_1, fingerprint_2, fingerprint_3])\n",
    "\n",
    "        return Model([atoms, bonds, edges], [final_fingerprint])\n",
    "    \n",
    "    def build_model(self, encoder, verbose=True):\n",
    "        #First Target\n",
    "        atoms_1 = Input(name='atom_inputs_1',\n",
    "                      shape=(self.model_params['max_atoms'], self.model_params['num_atom_features']), dtype='float32')\n",
    "        bonds_1 = Input(name='bond_inputs_1', shape=(\n",
    "        self.model_params['max_atoms'], self.model_params['max_degree'], self.model_params['num_bond_features']),\n",
    "                      dtype='float32')\n",
    "        edges_1 = Input(name='edge_inputs_1', shape=(self.model_params['max_atoms'], self.model_params['max_degree']),\n",
    "                      dtype='int32')\n",
    "        encode_drug_1 = encoder([atoms_1, bonds_1, edges_1])\n",
    "        \n",
    "        #Second Target\n",
    "        atoms_2 = Input(name='atom_inputs_2',\n",
    "                      shape=(self.model_params['max_atoms'], self.model_params['num_atom_features']), dtype='float32')\n",
    "        bonds_2 = Input(name='bond_inputs_2', shape=(\n",
    "        self.model_params['max_atoms'], self.model_params['max_degree'], self.model_params['num_bond_features']),\n",
    "                      dtype='float32')\n",
    "        edges_2 = Input(name='edge_inputs_2', shape=(self.model_params['max_atoms'], self.model_params['max_degree']),\n",
    "                      dtype='int32')\n",
    "        encode_drug_2 = encoder([atoms_2, bonds_2, edges_2])\n",
    "        \n",
    "        atoms_3 = Input(name='atom_inputs_3',\n",
    "                      shape=(self.model_params['max_atoms'], self.model_params['num_atom_features']), dtype='float32')\n",
    "        bonds_3 = Input(name='bond_inputs_3', shape=(\n",
    "        self.model_params['max_atoms'], self.model_params['max_degree'], self.model_params['num_bond_features']),\n",
    "                      dtype='float32')\n",
    "        edges_3 = Input(name='edge_inputs_3', shape=(self.model_params['max_atoms'], self.model_params['max_degree']),\n",
    "                      dtype='int32')\n",
    "        encode_drug_3 = encoder([atoms_3, bonds_3, edges_3])\n",
    "        \n",
    "        conc = keras.layers.Concatenate(axis = -1)([encode_drug_1,encode_drug_2,encode_drug_3])\n",
    "        # Fully connected\n",
    "        FC1 = Dense(self.model_params[\"dense_size\"][0], activation='relu',kernel_initializer='random_normal')(conc)\n",
    "        FC2 = Dropout(self.model_params[\"dropout_rate\"][0])(FC1)\n",
    "        FC2 = Dense(self.model_params[\"dense_size\"][1], activation='relu',kernel_initializer='random_normal')(FC2)\n",
    "        FC2 = Dropout(self.model_params[\"dropout_rate\"][1])(FC2)\n",
    "        FC2 = Dense(self.model_params[\"dense_size\"][2], activation='relu',kernel_initializer='random_normal')(FC2)\n",
    "        \n",
    "        prot_1 = crop(1,0,int(self.model_params['dense_size'][2]/3))(FC2)\n",
    "        prot_2 = crop(1,int(self.model_params['dense_size'][2]/3),2*int(self.model_params['dense_size'][2]/3))(FC2) \n",
    "        prot_3 = crop(1,2*int(self.model_params['dense_size'][2]/3),3*int(self.model_params['dense_size'][2]/3))(FC2)\n",
    "        \n",
    "        pred_1 = Dense(1, activation='sigmoid', kernel_initializer='random_normal',name = 'Protein_1')(prot_1)\n",
    "        pred_2 = Dense(1, activation='sigmoid', kernel_initializer='random_normal',name = 'Protein_2')(prot_2)\n",
    "        pred_3 = Dense(1, activation='sigmoid', kernel_initializer='random_normal',name = 'Protein_3')(prot_3)\n",
    "        gcn_model = Model(inputs=[atoms_1, bonds_1, edges_1,\n",
    "                                  atoms_2, bonds_2, edges_2,\n",
    "                                  atoms_3, bonds_3, edges_3], \n",
    "                                  outputs= [pred_1, pred_2, pred_3])\n",
    "\n",
    "        adam = keras.optimizers.Adam(lr=self.model_params[\"lr\"], beta_1=0.9, beta_2=0.999, decay=0.0, amsgrad=False)\n",
    "        gcn_model.compile(optimizer=adam, loss= {'Protein_1':'binary_crossentropy',\n",
    "                                                 'Protein_2':'binary_crossentropy',\n",
    "                                                 'Protein_3':'binary_crossentropy'}, \n",
    "                          metrics = {'Protein_1':'accuracy',\n",
    "                                    'Protein_2':'accuracy',\n",
    "                                    'Protein_3':'accuracy'})\n",
    "\n",
    "        if verbose:\n",
    "            #print('encoder')\n",
    "            #encoder.summary()\n",
    "            print('GCN_model')\n",
    "            gcn_model.summary()\n",
    "\n",
    "        return gcn_model\n",
    "\n",
    "    def dataframe_to_gcn_input(self, input_data):\n",
    "        x_atoms_cold, x_bonds_cold, x_edges_cold = tensorise_smiles(input_data['rdkit'],\n",
    "                                                                    max_degree=self.model_params['max_degree'],\n",
    "                                                                    max_atoms=self.model_params['max_atoms'])\n",
    "        return [x_atoms_cold, x_bonds_cold, x_edges_cold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n",
      "GCN_model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "atom_inputs_1 (InputLayer)      (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_1 (InputLayer)      (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_1 (InputLayer)      (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_inputs_2 (InputLayer)      (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_2 (InputLayer)      (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_2 (InputLayer)      (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_inputs_3 (InputLayer)      (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_3 (InputLayer)      (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_3 (InputLayer)      (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_10 (Model)                (None, 160)          241696      atom_inputs_1[0][0]              \n",
      "                                                                 bond_inputs_1[0][0]              \n",
      "                                                                 edge_inputs_1[0][0]              \n",
      "                                                                 atom_inputs_2[0][0]              \n",
      "                                                                 bond_inputs_2[0][0]              \n",
      "                                                                 edge_inputs_2[0][0]              \n",
      "                                                                 atom_inputs_3[0][0]              \n",
      "                                                                 bond_inputs_3[0][0]              \n",
      "                                                                 edge_inputs_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 480)          0           model_10[1][0]                   \n",
      "                                                                 model_10[2][0]                   \n",
      "                                                                 model_10[3][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          123136      concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 192)          49344       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 192)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 96)           18528       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Protein_1 (Dense)               (None, 1)            33          lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Protein_2 (Dense)               (None, 1)            33          lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Protein_3 (Dense)               (None, 1)            33          lambda_6[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 432,803\n",
      "Trainable params: 431,203\n",
      "Non-trainable params: 1,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "106/106 [==============================] - 18s 174ms/step - loss: 2.0378 - Protein_1_loss: 0.6986 - Protein_2_loss: 0.6687 - Protein_3_loss: 0.6705 - Protein_1_acc: 0.5113 - Protein_2_acc: 0.5997 - Protein_3_acc: 0.6279\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.8861 - Protein_1_loss: 0.6933 - Protein_2_loss: 0.5320 - Protein_3_loss: 0.6608 - Protein_1_acc: 0.5083 - Protein_2_acc: 0.7406 - Protein_3_acc: 0.6325\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 8s 72ms/step - loss: 1.8779 - Protein_1_loss: 0.6933 - Protein_2_loss: 0.5259 - Protein_3_loss: 0.6587 - Protein_1_acc: 0.5033 - Protein_2_acc: 0.7456 - Protein_3_acc: 0.6329\n",
      "Epoch 4/50\n",
      "106/106 [==============================] - 8s 72ms/step - loss: 1.8662 - Protein_1_loss: 0.6934 - Protein_2_loss: 0.5127 - Protein_3_loss: 0.6601 - Protein_1_acc: 0.5045 - Protein_2_acc: 0.7475 - Protein_3_acc: 0.6292\n",
      "Epoch 5/50\n",
      "106/106 [==============================] - 8s 72ms/step - loss: 1.8191 - Protein_1_loss: 0.6934 - Protein_2_loss: 0.4651 - Protein_3_loss: 0.6605 - Protein_1_acc: 0.5138 - Protein_2_acc: 0.7853 - Protein_3_acc: 0.6273\n",
      "Epoch 6/50\n",
      "106/106 [==============================] - 8s 72ms/step - loss: 1.8060 - Protein_1_loss: 0.6932 - Protein_2_loss: 0.4571 - Protein_3_loss: 0.6557 - Protein_1_acc: 0.5081 - Protein_2_acc: 0.7945 - Protein_3_acc: 0.6367\n",
      "Epoch 7/50\n",
      "106/106 [==============================] - 8s 72ms/step - loss: 1.7840 - Protein_1_loss: 0.6930 - Protein_2_loss: 0.4376 - Protein_3_loss: 0.6534 - Protein_1_acc: 0.5113 - Protein_2_acc: 0.8064 - Protein_3_acc: 0.6408\n",
      "Epoch 8/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.7887 - Protein_1_loss: 0.6932 - Protein_2_loss: 0.4375 - Protein_3_loss: 0.6580 - Protein_1_acc: 0.5102 - Protein_2_acc: 0.8083 - Protein_3_acc: 0.6316\n",
      "Epoch 9/50\n",
      "106/106 [==============================] - 8s 72ms/step - loss: 1.7905 - Protein_1_loss: 0.6930 - Protein_2_loss: 0.4400 - Protein_3_loss: 0.6575 - Protein_1_acc: 0.5118 - Protein_2_acc: 0.8068 - Protein_3_acc: 0.6331\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0035185585729777813.\n",
      "Epoch 10/50\n",
      "106/106 [==============================] - 8s 72ms/step - loss: 1.7407 - Protein_1_loss: 0.6932 - Protein_2_loss: 0.3928 - Protein_3_loss: 0.6546 - Protein_1_acc: 0.5054 - Protein_2_acc: 0.8300 - Protein_3_acc: 0.6382\n",
      "Epoch 11/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.7315 - Protein_1_loss: 0.6929 - Protein_2_loss: 0.3834 - Protein_3_loss: 0.6552 - Protein_1_acc: 0.5139 - Protein_2_acc: 0.8412 - Protein_3_acc: 0.6374\n",
      "Epoch 12/50\n",
      "106/106 [==============================] - 8s 72ms/step - loss: 1.7207 - Protein_1_loss: 0.6931 - Protein_2_loss: 0.3675 - Protein_3_loss: 0.6602 - Protein_1_acc: 0.5077 - Protein_2_acc: 0.8469 - Protein_3_acc: 0.6280\n",
      "Epoch 13/50\n",
      "106/106 [==============================] - 8s 72ms/step - loss: 1.7105 - Protein_1_loss: 0.6933 - Protein_2_loss: 0.3584 - Protein_3_loss: 0.6589 - Protein_1_acc: 0.4955 - Protein_2_acc: 0.8492 - Protein_3_acc: 0.6303\n",
      "Epoch 14/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.6954 - Protein_1_loss: 0.6932 - Protein_2_loss: 0.3468 - Protein_3_loss: 0.6553 - Protein_1_acc: 0.5054 - Protein_2_acc: 0.8576 - Protein_3_acc: 0.6366\n",
      "Epoch 15/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.7053 - Protein_1_loss: 0.6931 - Protein_2_loss: 0.3555 - Protein_3_loss: 0.6567 - Protein_1_acc: 0.5087 - Protein_2_acc: 0.8520 - Protein_3_acc: 0.6344\n",
      "Epoch 16/50\n",
      "106/106 [==============================] - 8s 74ms/step - loss: 1.6746 - Protein_1_loss: 0.6929 - Protein_2_loss: 0.3254 - Protein_3_loss: 0.6563 - Protein_1_acc: 0.5126 - Protein_2_acc: 0.8720 - Protein_3_acc: 0.6350\n",
      "Epoch 17/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.6787 - Protein_1_loss: 0.6930 - Protein_2_loss: 0.3254 - Protein_3_loss: 0.6603 - Protein_1_acc: 0.5097 - Protein_2_acc: 0.8657 - Protein_3_acc: 0.6276\n",
      "Epoch 18/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.6777 - Protein_1_loss: 0.6930 - Protein_2_loss: 0.3275 - Protein_3_loss: 0.6572 - Protein_1_acc: 0.5096 - Protein_2_acc: 0.8662 - Protein_3_acc: 0.6335\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0017592792864888906.\n",
      "Epoch 19/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.6367 - Protein_1_loss: 0.6930 - Protein_2_loss: 0.2870 - Protein_3_loss: 0.6567 - Protein_1_acc: 0.5094 - Protein_2_acc: 0.8907 - Protein_3_acc: 0.6343\n",
      "Epoch 20/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.6315 - Protein_1_loss: 0.6933 - Protein_2_loss: 0.2811 - Protein_3_loss: 0.6571 - Protein_1_acc: 0.5019 - Protein_2_acc: 0.8914 - Protein_3_acc: 0.6334\n",
      "Epoch 21/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.6143 - Protein_1_loss: 0.6931 - Protein_2_loss: 0.2621 - Protein_3_loss: 0.6592 - Protein_1_acc: 0.5074 - Protein_2_acc: 0.9020 - Protein_3_acc: 0.6298\n",
      "Epoch 22/50\n",
      "106/106 [==============================] - 8s 74ms/step - loss: 1.6261 - Protein_1_loss: 0.6933 - Protein_2_loss: 0.2733 - Protein_3_loss: 0.6595 - Protein_1_acc: 0.4994 - Protein_2_acc: 0.8943 - Protein_3_acc: 0.6290\n",
      "Epoch 23/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.6066 - Protein_1_loss: 0.6930 - Protein_2_loss: 0.2562 - Protein_3_loss: 0.6574 - Protein_1_acc: 0.5120 - Protein_2_acc: 0.9032 - Protein_3_acc: 0.6331\n",
      "Epoch 24/50\n",
      "106/106 [==============================] - 8s 72ms/step - loss: 1.5977 - Protein_1_loss: 0.6930 - Protein_2_loss: 0.2478 - Protein_3_loss: 0.6568 - Protein_1_acc: 0.5078 - Protein_2_acc: 0.9099 - Protein_3_acc: 0.6341\n",
      "Epoch 25/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.6010 - Protein_1_loss: 0.6931 - Protein_2_loss: 0.2493 - Protein_3_loss: 0.6586 - Protein_1_acc: 0.5060 - Protein_2_acc: 0.9096 - Protein_3_acc: 0.6308\n",
      "Epoch 26/50\n",
      "106/106 [==============================] - 8s 74ms/step - loss: 1.5948 - Protein_1_loss: 0.6929 - Protein_2_loss: 0.2473 - Protein_3_loss: 0.6546 - Protein_1_acc: 0.5126 - Protein_2_acc: 0.9055 - Protein_3_acc: 0.6380\n",
      "Epoch 27/50\n",
      "106/106 [==============================] - 8s 75ms/step - loss: 1.5912 - Protein_1_loss: 0.6931 - Protein_2_loss: 0.2401 - Protein_3_loss: 0.6580 - Protein_1_acc: 0.5077 - Protein_2_acc: 0.9116 - Protein_3_acc: 0.6318\n",
      "Epoch 28/50\n",
      "106/106 [==============================] - 8s 74ms/step - loss: 1.5787 - Protein_1_loss: 0.6931 - Protein_2_loss: 0.2309 - Protein_3_loss: 0.6547 - Protein_1_acc: 0.5062 - Protein_2_acc: 0.9161 - Protein_3_acc: 0.6379\n",
      "Epoch 29/50\n",
      "106/106 [==============================] - 8s 74ms/step - loss: 1.5780 - Protein_1_loss: 0.6927 - Protein_2_loss: 0.2282 - Protein_3_loss: 0.6571 - Protein_1_acc: 0.5161 - Protein_2_acc: 0.9186 - Protein_3_acc: 0.6335\n",
      "Epoch 30/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.5642 - Protein_1_loss: 0.6931 - Protein_2_loss: 0.2112 - Protein_3_loss: 0.6599 - Protein_1_acc: 0.5051 - Protein_2_acc: 0.9279 - Protein_3_acc: 0.6283\n",
      "Epoch 31/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.5669 - Protein_1_loss: 0.6933 - Protein_2_loss: 0.2170 - Protein_3_loss: 0.6566 - Protein_1_acc: 0.5015 - Protein_2_acc: 0.9235 - Protein_3_acc: 0.6344\n",
      "Epoch 32/50\n",
      "106/106 [==============================] - 8s 74ms/step - loss: 1.5808 - Protein_1_loss: 0.6931 - Protein_2_loss: 0.2272 - Protein_3_loss: 0.6605 - Protein_1_acc: 0.5064 - Protein_2_acc: 0.9186 - Protein_3_acc: 0.6271\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0008796396432444453.\n",
      "Epoch 33/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.5373 - Protein_1_loss: 0.6928 - Protein_2_loss: 0.1881 - Protein_3_loss: 0.6564 - Protein_1_acc: 0.5149 - Protein_2_acc: 0.9380 - Protein_3_acc: 0.6348\n",
      "Epoch 34/50\n",
      "106/106 [==============================] - 8s 76ms/step - loss: 1.5356 - Protein_1_loss: 0.6931 - Protein_2_loss: 0.1866 - Protein_3_loss: 0.6559 - Protein_1_acc: 0.5060 - Protein_2_acc: 0.9372 - Protein_3_acc: 0.6357\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 8s 74ms/step - loss: 1.5332 - Protein_1_loss: 0.6931 - Protein_2_loss: 0.1813 - Protein_3_loss: 0.6588 - Protein_1_acc: 0.5067 - Protein_2_acc: 0.9412 - Protein_3_acc: 0.6303\n",
      "Epoch 36/50\n",
      "106/106 [==============================] - 8s 72ms/step - loss: 1.5423 - Protein_1_loss: 0.6930 - Protein_2_loss: 0.1904 - Protein_3_loss: 0.6590 - Protein_1_acc: 0.5106 - Protein_2_acc: 0.9354 - Protein_3_acc: 0.6299\n",
      "Epoch 37/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.5294 - Protein_1_loss: 0.6930 - Protein_2_loss: 0.1802 - Protein_3_loss: 0.6562 - Protein_1_acc: 0.5094 - Protein_2_acc: 0.9411 - Protein_3_acc: 0.6351\n",
      "Epoch 38/50\n",
      "106/106 [==============================] - 8s 74ms/step - loss: 1.5409 - Protein_1_loss: 0.6930 - Protein_2_loss: 0.1919 - Protein_3_loss: 0.6560 - Protein_1_acc: 0.5081 - Protein_2_acc: 0.9343 - Protein_3_acc: 0.6356\n",
      "Epoch 39/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.5287 - Protein_1_loss: 0.6931 - Protein_2_loss: 0.1780 - Protein_3_loss: 0.6576 - Protein_1_acc: 0.5057 - Protein_2_acc: 0.9424 - Protein_3_acc: 0.6325\n",
      "Epoch 40/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.5267 - Protein_1_loss: 0.6932 - Protein_2_loss: 0.1770 - Protein_3_loss: 0.6566 - Protein_1_acc: 0.5041 - Protein_2_acc: 0.9406 - Protein_3_acc: 0.6344\n",
      "Epoch 41/50\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.5388 - Protein_1_loss: 0.6928 - Protein_2_loss: 0.1904 - Protein_3_loss: 0.6556 - Protein_1_acc: 0.5151 - Protein_2_acc: 0.9358 - Protein_3_acc: 0.6361\n",
      "Epoch 42/50\n",
      "106/106 [==============================] - 8s 74ms/step - loss: 1.5401 - Protein_1_loss: 0.6929 - Protein_2_loss: 0.1894 - Protein_3_loss: 0.6578 - Protein_1_acc: 0.5103 - Protein_2_acc: 0.9348 - Protein_3_acc: 0.6322\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00043981982162222266.\n",
      "Epoch 43/50\n",
      "106/106 [==============================] - 8s 74ms/step - loss: 1.5133 - Protein_1_loss: 0.6930 - Protein_2_loss: 0.1650 - Protein_3_loss: 0.6553 - Protein_1_acc: 0.5103 - Protein_2_acc: 0.9467 - Protein_3_acc: 0.6367\n",
      "Epoch 44/50\n",
      "106/106 [==============================] - 8s 74ms/step - loss: 1.5197 - Protein_1_loss: 0.6930 - Protein_2_loss: 0.1665 - Protein_3_loss: 0.6601 - Protein_1_acc: 0.5087 - Protein_2_acc: 0.9470 - Protein_3_acc: 0.6279\n",
      "Epoch 45/50\n",
      " 22/106 [=====>........................] - ETA: 6s - loss: 1.4980 - Protein_1_loss: 0.6926 - Protein_2_loss: 0.1614 - Protein_3_loss: 0.6440 - Protein_1_acc: 0.5189 - Protein_2_acc: 0.9490 - Protein_3_acc: 0.6573"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-be851fa5c802>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m                       \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                       \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                       callbacks = [es2,rlr2])\n\u001b[0m\u001b[0;32m     53\u001b[0m         Y_pred_train_p38,t1,t2 = gcn_model.predict([X_atoms_train_p38,X_bonds_train_p38,X_edges_train_p38,\n\u001b[0;32m     54\u001b[0m                                                \u001b[0mX_atoms_train_p38\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_bonds_train_p38\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_edges_train_p38\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\binding\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\binding\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\binding\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\binding\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\binding\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\binding\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val_p1 = {}\n",
    "val_p2 = {}\n",
    "val_p3 = {}\n",
    "train_p1 = {}\n",
    "train_p2 = {}\n",
    "train_p3 = {}\n",
    "gcn = GCN_MLT(model_params)\n",
    "es2 = EarlyStopping(monitor='loss',patience=15, min_delta=0)\n",
    "rlr2 = ReduceLROnPlateau(monitor='loss',factor=0.5, patience=2, verbose=1, min_lr=0.000000001)\n",
    "for i in range(len(training_p38)):\n",
    "    \n",
    "        #First Target\n",
    "        X_atoms_cold_p38,X_bonds_cold_p38,X_edges_cold_p38 = gcn.dataframe_to_gcn_input(validation_p38[i])\n",
    "        Y_cold_p38 = validation_p38[i].Binary\n",
    "        \n",
    "        X_atoms_train_p38, X_bonds_train_p38, X_edges_train_p38 = gcn.dataframe_to_gcn_input(training_p38[i])\n",
    "        Y_p38 = training_p38[i].Binary\n",
    "        smiles_list_p38 = list(training_p38[i]['rdkit'])\n",
    "        \n",
    "        #Second Target\n",
    "        X_atoms_cold_akt1, X_bonds_cold_akt1, X_edges_cold_akt1 = gcn.dataframe_to_gcn_input(validation_akt1[i])\n",
    "        Y_cold_akt1 = validation_akt1[i].Binary\n",
    "        \n",
    "        X_atoms_train_akt1, X_bonds_train_akt1, X_edges_train_akt1 = gcn.dataframe_to_gcn_input(training_akt1[i])\n",
    "        Y_akt1 = training_akt1[i].Binary\n",
    "        \n",
    "        smiles_list_akt1 = list(training_akt1[i]['rdkit'])\n",
    "        \n",
    "        #Third Target\n",
    "        X_atoms_cold_pi3k,X_bonds_cold_pi3k,X_edges_cold_pi3k = gcn.dataframe_to_gcn_input(validation_pi3k[i])\n",
    "        Y_cold_pi3k = validation_pi3k[i].Binary\n",
    "        \n",
    "        X_atoms_train_pi3k, X_bonds_train_pi3k, X_edges_train_pi3k = gcn.dataframe_to_gcn_input(training_pi3k[i])\n",
    "        Y_pi3k = training_pi3k[i].Binary\n",
    "        \n",
    "        smiles_list_pi3k = list(training_pi3k[i]['rdkit'])\n",
    "        \n",
    "        gcn_encoder = gcn.build_encoder()\n",
    "        gcn_model = gcn.build_model(gcn_encoder)\n",
    "        train_GEN = csv_generator_MLT(model_params['batch_size'],\n",
    "                                         training_p38[i],training_akt1[i],training_pi3k[i],\n",
    "                                         smiles_list_p38,smiles_list_akt1,smiles_list_pi3k,\n",
    "                                         X_atoms_train_p38, X_bonds_train_p38, X_edges_train_p38,\n",
    "                                         X_atoms_train_akt1, X_bonds_train_akt1, X_edges_train_akt1,\n",
    "                                         X_atoms_train_pi3k, X_bonds_train_pi3k, X_edges_train_pi3k)\n",
    "        NUM_TRAIN = np.sum([len(training_p38[i]),len(training_akt1[i]),len(training_pi3k[i])])\n",
    "        gcn_model.fit_generator(train_GEN,\n",
    "                      steps_per_epoch = ceil(NUM_TRAIN/model_params['batch_size']),\n",
    "                      epochs = 50,\n",
    "                      shuffle = True,\n",
    "                      validation_data = None,\n",
    "                      callbacks = [es2,rlr2])\n",
    "        Y_pred_train_p38,t1,t2 = gcn_model.predict([X_atoms_train_p38,X_bonds_train_p38,X_edges_train_p38,\n",
    "                                               X_atoms_train_p38,X_bonds_train_p38,X_edges_train_p38,\n",
    "                                               X_atoms_train_p38,X_bonds_train_p38,X_edges_train_p38])\n",
    "        t1,Y_pred_train_akt1,t2 = gcn_model.predict([X_atoms_train_akt1,X_bonds_train_akt1,X_edges_train_akt1,\n",
    "                                               X_atoms_train_akt1,X_bonds_train_akt1,X_edges_train_akt1,\n",
    "                                               X_atoms_train_akt1,X_bonds_train_akt1,X_edges_train_akt1])\n",
    "        t1,t2,Y_pred_train_pi3k = gcn_model.predict([X_atoms_train_pi3k,X_bonds_train_pi3k,X_edges_train_pi3k,\n",
    "                                               X_atoms_train_pi3k,X_bonds_train_pi3k,X_edges_train_pi3k,\n",
    "                                               X_atoms_train_pi3k,X_bonds_train_pi3k,X_edges_train_pi3k])\n",
    "\n",
    "\n",
    "        Y_pred_val_p38,t1,t2 = gcn_model.predict([X_atoms_cold_p38,X_bonds_cold_p38,X_edges_cold_p38,\n",
    "                                            X_atoms_cold_p38,X_bonds_cold_p38,X_edges_cold_p38,\n",
    "                                            X_atoms_cold_p38,X_bonds_cold_p38,X_edges_cold_p38])\n",
    "        t1,Y_pred_val_akt1,t2 = gcn_model.predict([X_atoms_cold_akt1,X_bonds_cold_akt1,X_edges_cold_akt1,\n",
    "                                            X_atoms_cold_akt1,X_bonds_cold_akt1,X_edges_cold_akt1,\n",
    "                                            X_atoms_cold_akt1,X_bonds_cold_akt1,X_edges_cold_akt1])\n",
    "        t1,t2,Y_pred_val_pi3k = gcn_model.predict([X_atoms_cold_pi3k,X_bonds_cold_pi3k,X_edges_cold_pi3k,\n",
    "                                            X_atoms_cold_pi3k,X_bonds_cold_pi3k,X_edges_cold_pi3k,\n",
    "                                            X_atoms_cold_pi3k,X_bonds_cold_pi3k,X_edges_cold_pi3k])\n",
    "        del t1,t2\n",
    "        if i < 6:\n",
    "            val_p1['Fold_%s'%i] = calculate_metrics(np.array(Y_cold_p38),Y_pred_val_p38.squeeze())\n",
    "            val_p2['Fold_%s'%i] = calculate_metrics(np.array(Y_cold_akt1),Y_pred_val_akt1.squeeze())\n",
    "            val_p3['Fold_%s'%i] = calculate_metrics(np.array(Y_cold_pi3k),Y_pred_val_pi3k.squeeze())\n",
    "        \n",
    "            train_p1['Fold_%s'%i] = calculate_metrics(np.array(Y_train_p38),Y_pred_train_p38.squeeze())\n",
    "            train_p2['Fold_%s'%i] = calculate_metrics(np.array(Y_train_akt1),Y_pred_train_akt1.squeeze())\n",
    "            train_p3['Fold_%s'%i] = calculate_metrics(np.array(Y_train_pi3k),Y_pred_train_pi3k.squeeze())\n",
    "        elif i == 6:\n",
    "            val_p1['Test'] = calculate_metrics(np.array(Y_cold_p38),Y_pred_val_p38.squeeze())\n",
    "            val_p2['Test'] = calculate_metrics(np.array(Y_cold_akt1),Y_pred_val_akt1.squeeze())\n",
    "            val_p3['Test'] = calculate_metrics(np.array(Y_cold_pi3k),Y_pred_val_pi3k.squeeze())\n",
    "        \n",
    "            train_p1['Test'] = calculate_metrics(np.array(Y_train_p38),Y_pred_train_p38.squeeze())\n",
    "            train_p2['Test'] = calculate_metrics(np.array(Y_train_akt1),Y_pred_train_akt1.squeeze())\n",
    "            train_p3['Test'] = calculate_metrics(np.array(Y_train_pi3k),Y_pred_train_pi3k.squeeze())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
