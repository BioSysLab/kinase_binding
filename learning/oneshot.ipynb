{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.callbacks import History, ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "from data_analysis import calculate_metrics, load_weights_and_evaluate\n",
    "from model_builders import GCN_siam_model\n",
    "from hyper_mining import XGB_predictor\n",
    "import pickle\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'pi3k'\n",
    "base_path = f'C:/Users/tomas/Documents/GitHub/kinase_binding'\n",
    "\n",
    "data_fpath = base_path+f'/data/{target}/data.csv'\n",
    "df = pd.read_csv(data_fpath).set_index('biolab_index')\n",
    "\n",
    "with open(base_path+f'/data/{target}/train_val_folds.pkl', \"rb\") as in_f:\n",
    "    train_val_folds = dill.load(in_f)\n",
    "\n",
    "with open(base_path+f'/data/{target}/train_test_folds.pkl', \"rb\") as in_f:\n",
    "    train_test_folds = dill.load(in_f)\n",
    "\n",
    "train_sets = [#df.loc[train_val_folds[0][0]],\n",
    "                 #df.loc[train_val_folds[1][0]],\n",
    "                 #df.loc[train_val_folds[2][0]],\n",
    "                 #df.loc[train_val_folds[3][0]],\n",
    "                 #df.loc[train_val_folds[4][0]],\n",
    "                 #df.loc[train_val_folds[5][0]],\n",
    "                 df.loc[train_test_folds[0]]\n",
    "                 ]\n",
    "val_sets = [#df.loc[train_val_folds[0][1]],\n",
    "                   #df.loc[train_val_folds[1][1]],\n",
    "                   #df.loc[train_val_folds[2][1]],\n",
    "                   #df.loc[train_val_folds[3][1]],\n",
    "                   #df.loc[train_val_folds[4][1]],\n",
    "                   #df.loc[train_val_folds[5][1]],\n",
    "                   df.loc[train_test_folds[1]]\n",
    "                   ]\n",
    "triplets_sets = [#pd.read_csv('../../../../Desktop/binding/Triplets/p38/fold_0/triplets_train.csv',index_col = 0),\n",
    "                #pd.read_csv('../../../../Desktop/binding/Triplets/p38/fold_1/triplets_train.csv',index_col = 0),\n",
    "                #pd.read_csv('../../../../Desktop/binding/Triplets/p38/fold_2/triplets_train.csv',index_col = 0),\n",
    "                #pd.read_csv('../../../../Desktop/binding/Triplets/p38/fold_3/triplets_train.csv',index_col = 0),\n",
    "                #pd.read_csv('../../../../Desktop/binding/Triplets/p38/fold_4/triplets_train.csv',index_col = 0),\n",
    "                #pd.read_csv('../../../../Desktop/binding/Triplets/p38/fold_5/triplets_train.csv',index_col = 0),\n",
    "                pd.read_csv('../../../../Desktop/binding/Triplets/pi3k/Test/triplets_train.csv',index_col = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss',patience=8, min_delta=0)\n",
    "rlr = ReduceLROnPlateau(monitor='loss',factor=0.5, patience=4, verbose=1, min_lr=0.0000001)\n",
    "es2 = EarlyStopping(monitor='loss',patience=8, min_delta=0)\n",
    "rlr2 = ReduceLROnPlateau(monitor='loss',factor=0.5, patience=2, verbose=1, min_lr=0.0000001)\n",
    "model_params = {\n",
    "        \"num_layers\" : 3,\n",
    "        \"max_atoms\" : 70,\n",
    "        \"num_atom_features\" : 62,\n",
    "        \"num_atom_features_original\" : 62,\n",
    "        \"num_bond_features\" : 6,\n",
    "        \"max_degree\" : 5,\n",
    "        \"conv_width\" : [int(96), int(104), int(120)],\n",
    "        \"fp_length\" : [int(160), int(160), int(160)],\n",
    "        \"activ_enc\" : \"selu\",\n",
    "        \"activ_dec\" : \"selu\",\n",
    "        \"learning_rates\" : [0.001,0.001,0.001],\n",
    "        \"learning_rates_fp\": [0.005,0.005,0.005],\n",
    "        \"losses_conv\" : {\n",
    "                    \"neighbor_output\": \"mean_squared_error\",\n",
    "                    \"self_output\": \"mean_squared_error\",\n",
    "                    },\n",
    "        \"lossWeights\" : {\"neighbor_output\": 1.0, \"self_output\": 1.0},\n",
    "        \"metrics\" : \"mse\",\n",
    "        \"loss_fp\" : \"mean_squared_error\",\n",
    "        \"enc_layer_names\" : [\"enc_1\", \"enc_2\", \"enc_3\"],\n",
    "        'callbacks' : [es,rlr],\n",
    "        'adam_decay': 0.0005329142291371636,\n",
    "        'beta': 5,\n",
    "        'p': 0.004465204118126482,\n",
    "        'dense_size' : [int(256), int(256), int(256)],\n",
    "        'dropout_rate' : [0.354, 0.354],\n",
    "        'lr' : 0.0005,\n",
    "        'batch_size' : int(64),\n",
    "        'n_epochs' : int(35),\n",
    "        'margin' : 0.2\n",
    "        }\n",
    "xgb_params = {\n",
    "        \"colsample_bylevel\" : 0.5612301667238877,\n",
    "        \"colsample_bytree\" : 0.788688363076523,\n",
    "        \"gamma\" : 0.35376030016117566,\n",
    "        \"eta\" : 0.4023692255888918,\n",
    "        \"max_delta_step\" : int(3),\n",
    "        \"max_depth\" : int(8),\n",
    "        \"min_child_weight\" : int(70),\n",
    "        \"alpha\" : 0.15030685758880047,\n",
    "        \"lambda\" : 15.311721955443915,\n",
    "        \"subsample\" : 0.8303923929525608,\n",
    "        \"eval_metric\":'auc',\n",
    "        \"objective\":'binary:logistic',\n",
    "        \"booster\":'gbtree'\n",
    "}\n",
    "class_XGB = XGB_predictor(xgb_params)\n",
    "gcn = GCN_siam_model(model_params)\n",
    "val_metrics = {}\n",
    "train_metrics  ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n",
      "y_pred.shape =  Tensor(\"merged_layer_3/concat:0\", shape=(?, 768), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 26s - loss: 0.5017\n",
      "Epoch 2/5\n",
      " - 16s - loss: 0.4994\n",
      "Epoch 3/5\n",
      " - 16s - loss: 0.4993\n",
      "Epoch 4/5\n",
      " - 16s - loss: 0.5003\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 5/5\n",
      " - 16s - loss: 0.4975\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_sets)):\n",
    "    anchor_atoms, anchor_bonds, anchor_edges = gcn.dataframe_to_gcn_input(triplets_sets[i][\"A\"])\n",
    "    pos_atoms, pos_bonds, pos_edges = gcn.dataframe_to_gcn_input(triplets_sets[i][\"P\"])\n",
    "    neg_atoms, neg_bonds, neg_edges = gcn.dataframe_to_gcn_input(triplets_sets[i][\"N\"])\n",
    "    \n",
    "    gcn_encoder = gcn.build_encoder()\n",
    "    gcn_model = gcn.build_model(gcn_encoder)\n",
    "    siamese = gcn.build_siam(gcn_model)\n",
    "    \n",
    "    \n",
    "    Y_dummy = np.empty((anchor_atoms.shape[0],768))\n",
    "    siamese.fit([anchor_atoms, anchor_bonds, anchor_edges,\n",
    "                 pos_atoms, pos_bonds, pos_edges,\n",
    "                 neg_atoms, neg_bonds, neg_edges],Y_dummy,\n",
    "                batch_size=256,\n",
    "                epochs=5,\n",
    "                verbose=2,\n",
    "                shuffle=True,\n",
    "                validation_data=None,\n",
    "                callbacks = [es2,rlr2])\n",
    "    \n",
    "    Y_val = val_sets[i].Binary\n",
    "    val_atoms, val_bonds, val_edges = gcn.dataframe_to_gcn_input(val_sets[i][\"rdkit\"])\n",
    "    emb_val = gcn_model.predict([val_atoms, val_bonds, val_edges])\n",
    "    \n",
    "    Y = train_sets[i].Binary\n",
    "    train_atoms, train_bonds, train_edges = gcn.dataframe_to_gcn_input(train_sets[i][\"rdkit\"])\n",
    "    emb_train = gcn_model.predict([train_atoms, train_bonds, train_edges])\n",
    "    \n",
    "    dmatrix_train = class_XGB.to_xgb_input(Y,emb_train)\n",
    "    dmatrix_cold = class_XGB.to_xgb_input(Y_val,emb_val)\n",
    "    \n",
    "    evalist = [(dmatrix_train,'train'),(dmatrix_cold,'eval')]\n",
    "    xgb_model = class_XGB.build_model(dmatrix_train,evalist,300)\n",
    "    xgb_pred_cold = xgb_model.predict(dmatrix_cold)\n",
    "    xgb_pred_train = xgb_model.predict(dmatrix_train)\n",
    "    \n",
    "\n",
    "    val_metrics['Test'] = calculate_metrics(np.array(Y_val),xgb_pred_cold)\n",
    "    train_metrics['Test'] = calculate_metrics(np.array(Y),xgb_pred_train)\n",
    "        \n",
    "    del gcn_encoder, gcn_model, siamese, anchor_atoms, anchor_bonds, anchor_edges, pos_atoms, pos_bonds, pos_edges\n",
    "    del neg_atoms, neg_bonds, neg_edges, val_atoms, val_bonds, val_edges, train_atoms, train_bonds, train_edges\n",
    "    del emb_val, emb_train, dmatrix_train, dmatrix_cold, xgb_model,  xgb_pred_cold, xgb_pred_train, evalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>map</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.943115</td>\n",
       "      <td>122.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.981899</td>\n",
       "      <td>0.94597</td>\n",
       "      <td>0.897479</td>\n",
       "      <td>0.988912</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>1068.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy     fn    fp       map  precision    recall   roc_auc      tn  \\\n",
       "Test  0.943115  122.0  61.0  0.981899    0.94597  0.897479  0.988912  1966.0   \n",
       "\n",
       "          tp  \n",
       "Test  1068.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_metrics).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>map</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.791434</td>\n",
       "      <td>65.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.707148</td>\n",
       "      <td>0.704403</td>\n",
       "      <td>0.632768</td>\n",
       "      <td>0.846281</td>\n",
       "      <td>313.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy    fn    fp       map  precision    recall   roc_auc     tn  \\\n",
       "Test  0.791434  65.0  47.0  0.707148   0.704403  0.632768  0.846281  313.0   \n",
       "\n",
       "         tp  \n",
       "Test  112.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(val_metrics).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics = pd.DataFrame(val_metrics).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics.to_csv('../../../../Desktop/binding/thesis english/Results/3-One-Shot/Offline/pi3k.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
