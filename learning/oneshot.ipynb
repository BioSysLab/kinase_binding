{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.callbacks import History, ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "from data_analysis import calculate_metrics, load_weights_and_evaluate\n",
    "from model_builders import GCN_siam_model\n",
    "from hyper_mining import XGB_predictor\n",
    "import pickle\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'pi3k'\n",
    "base_path = f'C:/Users/tomas/Documents/GitHub/kinase_binding'\n",
    "\n",
    "data_fpath = base_path+f'/data/{target}/data.csv'\n",
    "df = pd.read_csv(data_fpath).set_index('biolab_index')\n",
    "\n",
    "with open(base_path+f'/data/{target}/train_val_folds.pkl', \"rb\") as in_f:\n",
    "    train_val_folds = dill.load(in_f)\n",
    "\n",
    "with open(base_path+f'/data/{target}/train_test_folds.pkl', \"rb\") as in_f:\n",
    "    train_test_folds = dill.load(in_f)\n",
    "\n",
    "train_sets = [df.loc[train_val_folds[0][0]],\n",
    "                 df.loc[train_val_folds[1][0]],\n",
    "                 df.loc[train_val_folds[2][0]],\n",
    "                 df.loc[train_val_folds[3][0]],\n",
    "                 df.loc[train_val_folds[4][0]],\n",
    "                 df.loc[train_val_folds[5][0]],\n",
    "                 df.loc[train_test_folds[0]]\n",
    "                 ]\n",
    "val_sets = [df.loc[train_val_folds[0][1]],\n",
    "                   df.loc[train_val_folds[1][1]],\n",
    "                   df.loc[train_val_folds[2][1]],\n",
    "                   df.loc[train_val_folds[3][1]],\n",
    "                   df.loc[train_val_folds[4][1]],\n",
    "                   df.loc[train_val_folds[5][1]],\n",
    "                   df.loc[train_test_folds[1]]\n",
    "                   ]\n",
    "triplets_sets = [pd.read_csv('../../../../Desktop/binding/Triplets/p38/fold_0/triplets_train.csv',index_col = 0),\n",
    "                pd.read_csv('../../../../Desktop/binding/Triplets/p38/fold_1/triplets_train.csv',index_col = 0),\n",
    "                pd.read_csv('../../../../Desktop/binding/Triplets/p38/fold_2/triplets_train.csv',index_col = 0),\n",
    "                pd.read_csv('../../../../Desktop/binding/Triplets/p38/fold_3/triplets_train.csv',index_col = 0),\n",
    "                pd.read_csv('../../../../Desktop/binding/Triplets/p38/fold_4/triplets_train.csv',index_col = 0),\n",
    "                pd.read_csv('../../../../Desktop/binding/Triplets/p38/fold_5/triplets_train.csv',index_col = 0),\n",
    "                pd.read_csv('../../../../Desktop/binding/Triplets/p38/Test/triplets_train.csv',index_col = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss',patience=8, min_delta=0)\n",
    "rlr = ReduceLROnPlateau(monitor='loss',factor=0.5, patience=4, verbose=1, min_lr=0.0000001)\n",
    "es2 = EarlyStopping(monitor='loss',patience=8, min_delta=0)\n",
    "rlr2 = ReduceLROnPlateau(monitor='loss',factor=0.5, patience=2, verbose=1, min_lr=0.0000001)\n",
    "model_params = {\n",
    "        \"num_layers\" : 3,\n",
    "        \"max_atoms\" : 70,\n",
    "        \"num_atom_features\" : 62,\n",
    "        \"num_atom_features_original\" : 62,\n",
    "        \"num_bond_features\" : 6,\n",
    "        \"max_degree\" : 5,\n",
    "        \"conv_width\" : [int(96), int(104), int(120)],\n",
    "        \"fp_length\" : [int(160), int(160), int(160)],\n",
    "        \"activ_enc\" : \"selu\",\n",
    "        \"activ_dec\" : \"selu\",\n",
    "        \"learning_rates\" : [0.001,0.001,0.001],\n",
    "        \"learning_rates_fp\": [0.005,0.005,0.005],\n",
    "        \"losses_conv\" : {\n",
    "                    \"neighbor_output\": \"mean_squared_error\",\n",
    "                    \"self_output\": \"mean_squared_error\",\n",
    "                    },\n",
    "        \"lossWeights\" : {\"neighbor_output\": 1.0, \"self_output\": 1.0},\n",
    "        \"metrics\" : \"mse\",\n",
    "        \"loss_fp\" : \"mean_squared_error\",\n",
    "        \"enc_layer_names\" : [\"enc_1\", \"enc_2\", \"enc_3\"],\n",
    "        'callbacks' : [es,rlr],\n",
    "        'adam_decay': 0.0005329142291371636,\n",
    "        'beta': 5,\n",
    "        'p': 0.004465204118126482,\n",
    "        'dense_size' : [int(256), int(256), int(256)],\n",
    "        'dropout_rate' : [0.354, 0.354],\n",
    "        'lr' : 0.0005,\n",
    "        'batch_size' : int(64),\n",
    "        'n_epochs' : int(35),\n",
    "        'margin' : 0.2\n",
    "        }\n",
    "xgb_params = {\n",
    "        \"colsample_bylevel\" : 0.5612301667238877,\n",
    "        \"colsample_bytree\" : 0.788688363076523,\n",
    "        \"gamma\" : 0.35376030016117566,\n",
    "        \"eta\" : 0.4023692255888918,\n",
    "        \"max_delta_step\" : int(3),\n",
    "        \"max_depth\" : int(8),\n",
    "        \"min_child_weight\" : int(70),\n",
    "        \"alpha\" : 0.15030685758880047,\n",
    "        \"lambda\" : 15.311721955443915,\n",
    "        \"subsample\" : 0.8303923929525608,\n",
    "        \"eval_metric\":'auc',\n",
    "        \"objective\":'binary:logistic',\n",
    "        \"booster\":'gbtree'\n",
    "}\n",
    "class_XGB = XGB_predictor(xgb_params)\n",
    "gcn = GCN_siam_model(model_params)\n",
    "val_metrics = {}\n",
    "train_metrics  ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n",
      "y_pred.shape =  Tensor(\"merged_layer/concat:0\", shape=(?, 768), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "gcn_encoder = gcn.build_encoder()\n",
    "gcn_model = gcn.build_model(gcn_encoder)\n",
    "siamese = gcn.build_siam(gcn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "atom_inputs (InputLayer)        (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs (InputLayer)        (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs (InputLayer)        (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_10 (Model)                (None, 160)          241696      atom_inputs[0][0]                \n",
      "                                                                 bond_inputs[0][0]                \n",
      "                                                                 edge_inputs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          41216       model_10[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          65792       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 256)          0           dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 414,496\n",
      "Trainable params: 412,896\n",
      "Non-trainable params: 1,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gcn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "atom_inputs_anchor (InputLayer) (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_anchor (InputLayer) (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_anchor (InputLayer) (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_inputs_pos (InputLayer)    (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_pos (InputLayer)    (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_pos (InputLayer)    (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_inputs_neg (InputLayer)    (None, 70, 62)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond_inputs_neg (InputLayer)    (None, 70, 5, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_inputs_neg (InputLayer)    (None, 70, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_11 (Model)                (None, 256)          414496      atom_inputs_anchor[0][0]         \n",
      "                                                                 bond_inputs_anchor[0][0]         \n",
      "                                                                 edge_inputs_anchor[0][0]         \n",
      "                                                                 atom_inputs_pos[0][0]            \n",
      "                                                                 bond_inputs_pos[0][0]            \n",
      "                                                                 edge_inputs_pos[0][0]            \n",
      "                                                                 atom_inputs_neg[0][0]            \n",
      "                                                                 bond_inputs_neg[0][0]            \n",
      "                                                                 edge_inputs_neg[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merged_layer (Concatenate)      (None, 768)          0           model_11[1][0]                   \n",
      "                                                                 model_11[2][0]                   \n",
      "                                                                 model_11[3][0]                   \n",
      "==================================================================================================\n",
      "Total params: 414,496\n",
      "Trainable params: 412,896\n",
      "Non-trainable params: 1,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n",
      "y_pred.shape =  Tensor(\"merged_layer/concat:0\", shape=(?, 768), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 21s - loss: 0.5009\n",
      "Epoch 2/5\n",
      " - 12s - loss: 0.5001\n",
      "Epoch 3/5\n",
      " - 12s - loss: 0.4998\n",
      "Epoch 4/5\n",
      " - 12s - loss: 0.5003\n",
      "Epoch 5/5\n",
      " - 12s - loss: 0.4991\n",
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n",
      "y_pred.shape =  Tensor(\"merged_layer_1/concat:0\", shape=(?, 768), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 20s - loss: 0.5006\n",
      "Epoch 2/5\n",
      " - 12s - loss: 0.5012\n",
      "Epoch 3/5\n",
      " - 12s - loss: 0.4992\n",
      "Epoch 4/5\n",
      " - 12s - loss: 0.4989\n",
      "Epoch 5/5\n",
      " - 12s - loss: 0.5014\n",
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n",
      "y_pred.shape =  Tensor(\"merged_layer_2/concat:0\", shape=(?, 768), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 21s - loss: 0.5007\n",
      "Epoch 2/5\n",
      " - 12s - loss: 0.4994\n",
      "Epoch 3/5\n",
      " - 12s - loss: 0.4993\n",
      "Epoch 4/5\n",
      " - 12s - loss: 0.5003\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 5/5\n",
      " - 12s - loss: 0.4995\n",
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n",
      "y_pred.shape =  Tensor(\"merged_layer_3/concat:0\", shape=(?, 768), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 23s - loss: 0.5022\n",
      "Epoch 2/5\n",
      " - 12s - loss: 0.5011\n",
      "Epoch 3/5\n",
      " - 12s - loss: 0.5008\n",
      "Epoch 4/5\n",
      " - 12s - loss: 0.4989\n",
      "Epoch 5/5\n",
      " - 12s - loss: 0.4986\n",
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n",
      "y_pred.shape =  Tensor(\"merged_layer_4/concat:0\", shape=(?, 768), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 24s - loss: 0.5011\n",
      "Epoch 2/5\n",
      " - 12s - loss: 0.5010\n",
      "Epoch 3/5\n",
      " - 12s - loss: 0.4995\n",
      "Epoch 4/5\n",
      " - 12s - loss: 0.5001\n",
      "Epoch 5/5\n",
      " - 12s - loss: 0.5003\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n",
      "y_pred.shape =  Tensor(\"merged_layer_5/concat:0\", shape=(?, 768), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 26s - loss: 0.5022\n",
      "Epoch 2/5\n",
      " - 12s - loss: 0.4995\n",
      "Epoch 3/5\n",
      " - 12s - loss: 0.4995\n",
      "Epoch 4/5\n",
      " - 12s - loss: 0.5008\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 5/5\n",
      " - 12s - loss: 0.4999\n",
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n",
      "y_pred.shape =  Tensor(\"merged_layer_6/concat:0\", shape=(?, 768), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 31s - loss: 0.5016\n",
      "Epoch 2/5\n",
      " - 15s - loss: 0.4989\n",
      "Epoch 3/5\n",
      " - 15s - loss: 0.4996\n",
      "Epoch 4/5\n",
      " - 15s - loss: 0.4998\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 5/5\n",
      " - 16s - loss: 0.4997\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_sets)):\n",
    "    anchor_atoms, anchor_bonds, anchor_edges = gcn.dataframe_to_gcn_input(triplets_sets[i][\"A\"])\n",
    "    pos_atoms, pos_bonds, pos_edges = gcn.dataframe_to_gcn_input(triplets_sets[i][\"P\"])\n",
    "    neg_atoms, neg_bonds, neg_edges = gcn.dataframe_to_gcn_input(triplets_sets[i][\"N\"])\n",
    "    \n",
    "    gcn_encoder = gcn.build_encoder()\n",
    "    gcn_model = gcn.build_model(gcn_encoder)\n",
    "    siamese = gcn.build_siam(gcn_model)\n",
    "    \n",
    "    \n",
    "    Y_dummy = np.empty((anchor_atoms.shape[0],768))\n",
    "    siamese.fit([anchor_atoms, anchor_bonds, anchor_edges,\n",
    "                 pos_atoms, pos_bonds, pos_edges,\n",
    "                 neg_atoms, neg_bonds, neg_edges],Y_dummy,\n",
    "                batch_size=256,\n",
    "                epochs=5,\n",
    "                verbose=2,\n",
    "                shuffle=True,\n",
    "                validation_data=None,\n",
    "                callbacks = [es2,rlr2])\n",
    "    \n",
    "    Y_val = val_sets[i].Binary\n",
    "    val_atoms, val_bonds, val_edges = gcn.dataframe_to_gcn_input(val_sets[i][\"rdkit\"])\n",
    "    emb_val = gcn_model.predict([val_atoms, val_bonds, val_edges])\n",
    "    \n",
    "    Y = train_sets[i].Binary\n",
    "    train_atoms, train_bonds, train_edges = gcn.dataframe_to_gcn_input(train_sets[i][\"rdkit\"])\n",
    "    emb_train = gcn_model.predict([train_atoms, train_bonds, train_edges])\n",
    "    \n",
    "    dmatrix_train = class_XGB.to_xgb_input(Y,emb_train)\n",
    "    dmatrix_cold = class_XGB.to_xgb_input(Y_val,emb_val)\n",
    "    \n",
    "    evalist = [(dmatrix_train,'train'),(dmatrix_cold,'eval')]\n",
    "    xgb_model = class_XGB.build_model(dmatrix_train,evalist,300)\n",
    "    xgb_pred_cold = xgb_model.predict(dmatrix_cold)\n",
    "    xgb_pred_train = xgb_model.predict(dmatrix_train)\n",
    "    \n",
    "    if i<6:\n",
    "        val_metrics['Fold_%s'%i] = calculate_metrics(np.array(Y_val),xgb_pred_cold)\n",
    "        train_metrics['Fold_%s'%i] = calculate_metrics(np.array(Y),xgb_pred_train)\n",
    "    elif i == 6:\n",
    "        val_metrics['Test'] = calculate_metrics(np.array(Y_val),xgb_pred_cold)\n",
    "        train_metrics['Test'] = calculate_metrics(np.array(Y),xgb_pred_train)\n",
    "        \n",
    "    del gcn_encoder, gcn_model, siamese, anchor_atoms, anchor_bonds, anchor_edges, pos_atoms, pos_bonds, pos_edges\n",
    "    del neg_atoms, neg_bonds, neg_edges, val_atoms, val_bonds, val_edges, train_atoms, train_bonds, train_edges\n",
    "    del emb_val, emb_train, dmatrix_train, dmatrix_cold, xgb_model,  xgb_pred_cold, xgb_pred_train, evalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>map</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold_0</th>\n",
       "      <td>0.985606</td>\n",
       "      <td>1639.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>0.976783</td>\n",
       "      <td>0.936147</td>\n",
       "      <td>0.880855</td>\n",
       "      <td>0.934328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_1</th>\n",
       "      <td>0.987879</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>0.981513</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.945522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_2</th>\n",
       "      <td>0.987779</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>0.982071</td>\n",
       "      <td>0.956616</td>\n",
       "      <td>0.889113</td>\n",
       "      <td>0.944030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_3</th>\n",
       "      <td>0.986052</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>0.979248</td>\n",
       "      <td>0.951194</td>\n",
       "      <td>0.891918</td>\n",
       "      <td>0.941045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_4</th>\n",
       "      <td>0.984481</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>0.977128</td>\n",
       "      <td>0.943844</td>\n",
       "      <td>0.878392</td>\n",
       "      <td>0.935448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_5</th>\n",
       "      <td>0.985932</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>811.0</td>\n",
       "      <td>0.975712</td>\n",
       "      <td>0.950762</td>\n",
       "      <td>0.868308</td>\n",
       "      <td>0.938547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.988069</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>0.981317</td>\n",
       "      <td>0.947935</td>\n",
       "      <td>0.887395</td>\n",
       "      <td>0.940317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         roc_auc      tn    fp     fn      tp       map  precision    recall  \\\n",
       "Fold_0  0.985606  1639.0  59.0  117.0   865.0  0.976783   0.936147  0.880855   \n",
       "Fold_1  0.987879  1614.0  46.0  100.0   920.0  0.981513   0.952381  0.901961   \n",
       "Fold_2  0.987779  1648.0  40.0  110.0   882.0  0.982071   0.956616  0.889113   \n",
       "Fold_3  0.986052  1606.0  47.0  111.0   916.0  0.979248   0.951194  0.891918   \n",
       "Fold_4  0.984481  1633.0  52.0  121.0   874.0  0.977128   0.943844  0.878392   \n",
       "Fold_5  0.985932  1709.0  42.0  123.0   811.0  0.975712   0.950762  0.868308   \n",
       "Test    0.988069  1969.0  58.0  134.0  1056.0  0.981317   0.947935  0.887395   \n",
       "\n",
       "        accuracy  \n",
       "Fold_0  0.934328  \n",
       "Fold_1  0.945522  \n",
       "Fold_2  0.944030  \n",
       "Fold_3  0.941045  \n",
       "Fold_4  0.935448  \n",
       "Fold_5  0.938547  \n",
       "Test    0.940317  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_metrics).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>map</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold_0</th>\n",
       "      <td>0.688611</td>\n",
       "      <td>274.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.609218</td>\n",
       "      <td>0.598540</td>\n",
       "      <td>0.394231</td>\n",
       "      <td>0.662942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_1</th>\n",
       "      <td>0.800737</td>\n",
       "      <td>317.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.694000</td>\n",
       "      <td>0.645390</td>\n",
       "      <td>0.535294</td>\n",
       "      <td>0.759777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_2</th>\n",
       "      <td>0.796013</td>\n",
       "      <td>289.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.723568</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.739292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_3</th>\n",
       "      <td>0.783029</td>\n",
       "      <td>298.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.620218</td>\n",
       "      <td>0.563218</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>0.737430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_4</th>\n",
       "      <td>0.830679</td>\n",
       "      <td>308.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.757691</td>\n",
       "      <td>0.758865</td>\n",
       "      <td>0.548718</td>\n",
       "      <td>0.772812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold_5</th>\n",
       "      <td>0.816548</td>\n",
       "      <td>221.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.785769</td>\n",
       "      <td>0.759825</td>\n",
       "      <td>0.679688</td>\n",
       "      <td>0.742481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.791290</td>\n",
       "      <td>307.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.674192</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>0.536723</td>\n",
       "      <td>0.748603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         roc_auc     tn    fp     fn     tp       map  precision    recall  \\\n",
       "Fold_0  0.688611  274.0  55.0  126.0   82.0  0.609218   0.598540  0.394231   \n",
       "Fold_1  0.800737  317.0  50.0   79.0   91.0  0.694000   0.645390  0.535294   \n",
       "Fold_2  0.796013  289.0  50.0   90.0  108.0  0.723568   0.683544  0.545455   \n",
       "Fold_3  0.783029  298.0  76.0   65.0   98.0  0.620218   0.563218  0.601227   \n",
       "Fold_4  0.830679  308.0  34.0   88.0  107.0  0.757691   0.758865  0.548718   \n",
       "Fold_5  0.816548  221.0  55.0   82.0  174.0  0.785769   0.759825  0.679688   \n",
       "Test    0.791290  307.0  53.0   82.0   95.0  0.674192   0.641892  0.536723   \n",
       "\n",
       "        accuracy  \n",
       "Fold_0  0.662942  \n",
       "Fold_1  0.759777  \n",
       "Fold_2  0.739292  \n",
       "Fold_3  0.737430  \n",
       "Fold_4  0.772812  \n",
       "Fold_5  0.742481  \n",
       "Test    0.748603  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(val_metrics).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
