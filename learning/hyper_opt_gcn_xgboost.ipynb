{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.callbacks import History, ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "from data_analysis import calculate_metrics, load_weights_and_evaluate\n",
    "from model_builders import GCN_pretraining\n",
    "from hyperparameter_tuning_GCN import objective\n",
    "from functools import partial\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import pickle\n",
    "import dill\n",
    "from hyper_mining import objective_fn\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fspace = {\n",
    "    'conv1' : hp.quniform('conv1', 32, 64, 8),\n",
    "    'conv2' : hp.quniform('conv2', 64, 128, 8),\n",
    "    'conv3' : hp.quniform('conv3', 128, 168, 8),\n",
    "    'fp' : hp.quniform('fp', 96, 196, 8),\n",
    "    'dense1' : hp.quniform('dense1',96,512,32),\n",
    "    'dense2' : hp.quniform('dense2',96,512,32),\n",
    "    'dense3' : hp.quniform('dense3',64,512,32),\n",
    "    'dropout_rate' : hp.uniform('dropout_rate',0.1,0.5),\n",
    "    'lr' : hp.uniform('lr',0.00001,0.01),\n",
    "    'n_epochs' : hp.quniform('n_epochs',15,60,5),\n",
    "    'batch_size' : hp.quniform('batch_size',64,256,16),\n",
    "    'colsample_bylevel' : hp.uniform('colsample_bylevel', 0.1, 1), \n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.1, 1), \n",
    "    'gamma' : hp.uniform('gamma', 0.1, 1), \n",
    "    'learning_rate' : hp.uniform('learning_rate', 0.1, 1),\n",
    "    'max_delta_step' : hp.quniform('max_delta_step',1,10,1),\n",
    "    'max_depth' : hp.quniform('max_depth',6, 12, 1),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight',10 ,500 ,5),\n",
    "    'reg_alpha' : hp.uniform('reg_alpha',0.1,100),\n",
    "    'reg_lambda' : hp.uniform('reg_lambda',0.1,100),\n",
    "    'subsample' : hp.uniform('subsample',0.1,1.0),\n",
    "    'max_bin' : hp.quniform('max_bin',16,256,16),\n",
    "    'margin' : hp.uniform('margin',0.2,2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'p38'\n",
    "base_path = f'C:/Users/tomas/Documents/GitHub/kinase_binding'\n",
    "\n",
    "data_fpath = base_path+f'/data/{target}/data.csv'\n",
    "df=pd.read_csv(data_fpath).set_index('biolab_index')\n",
    "\n",
    "with open(base_path+f'/data/{target}/train_val_folds.pkl', \"rb\") as in_f:\n",
    "    train_val_folds = dill.load(in_f)\n",
    "with open(base_path+f'/data/{target}/train_test_folds.pkl', \"rb\") as in_f:\n",
    "    train_test_folds = dill.load(in_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_list = [df.loc[train_val_folds[0][0]],\n",
    "                 df.loc[train_val_folds[1][0]],\n",
    "                 df.loc[train_val_folds[2][0]],\n",
    "                 df.loc[train_val_folds[3][0]],\n",
    "                 df.loc[train_val_folds[4][0]],\n",
    "                 df.loc[train_val_folds[5][0]],\n",
    "                 ]\n",
    "validation_list = [df.loc[train_val_folds[0][1]],\n",
    "                   df.loc[train_val_folds[1][1]],\n",
    "                   df.loc[train_val_folds[2][1]],\n",
    "                   df.loc[train_val_folds[3][1]],\n",
    "                   df.loc[train_val_folds[4][1]],\n",
    "                   df.loc[train_val_folds[5][1]],\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin_objective = partial(objective, train_sets = training_list, val_sets = validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trials():\n",
    "\n",
    "    trials_step = 1  # how many additional trials to do after loading saved trials. 1 = save after iteration\n",
    "    max_trials = 2  # initial max_trials. put something small to not have to wait\n",
    "\n",
    "    \n",
    "    try:  # try to load an already saved trials object, and increase the max\n",
    "        trials = pickle.load(open(\"gcn_xgb.hyperopt\", \"rb\"))\n",
    "        print(\"Found saved Trials! Loading...\")\n",
    "        max_trials = len(trials.trials) + trials_step\n",
    "        print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n",
    "    except:  # create a new trials object and start searching\n",
    "        trials = Trials()\n",
    "\n",
    "    best = fmin(fn = fmin_objective, space = fspace, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n",
    "\n",
    "    print(\"Best:\", best)\n",
    "    \n",
    "    # save the trials object\n",
    "    with open(\"gcn_xgb.hyperopt\", \"wb\") as f:\n",
    "        pickle.dump(trials, f)\n",
    "    return(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found saved Trials! Loading...\n",
      "Rerunning from 2 trials to 3 (+1) trials\n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      " 67%|█████████████████████████████████████████████▎                      | 2/3 [00:05<00:02,  2.72s/trial, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "100%|█████████████████████████████████████████████████| 3/3 [06:03<00:00, 121.22s/trial, best loss: -0.880932711114237]\n",
      "Best: {'colsample_bylevel': 0.7123342985374396, 'colsample_bytree': 0.9455012808813511, 'conv1': 48.0, 'conv2': 80.0, 'conv3': 152.0, 'dense1': 256.0, 'dense2': 448.0, 'dense3': 160.0, 'dropout_rate': 0.3560048819669964, 'fp': 144.0, 'gamma': 0.3014935659014918, 'learning_rate': 0.8150263751648756, 'lr': 0.0011837712270375551, 'margin': 0.7809169116604946, 'max_bin': 96.0, 'max_delta_step': 4.0, 'max_depth': 12.0, 'min_child_weight': 15.0, 'n_epochs': 40.0, 'reg_alpha': 56.661393667866655, 'reg_lambda': 60.169893877252335, 'subsample': 0.4971284915555839}\n"
     ]
    }
   ],
   "source": [
    "trials = run_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'state': 2,\n",
       "  'tid': 0,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.880932711114237, 'status': 'ok'},\n",
       "  'misc': {'tid': 0,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bylevel': [0],\n",
       "    'colsample_bytree': [0],\n",
       "    'conv1': [0],\n",
       "    'conv2': [0],\n",
       "    'conv3': [0],\n",
       "    'dense1': [0],\n",
       "    'dense2': [0],\n",
       "    'dense3': [0],\n",
       "    'dropout_rate': [0],\n",
       "    'fp': [0],\n",
       "    'gamma': [0],\n",
       "    'learning_rate': [0],\n",
       "    'lr': [0],\n",
       "    'margin': [0],\n",
       "    'max_bin': [0],\n",
       "    'max_delta_step': [0],\n",
       "    'max_depth': [0],\n",
       "    'min_child_weight': [0],\n",
       "    'n_epochs': [0],\n",
       "    'reg_alpha': [0],\n",
       "    'reg_lambda': [0],\n",
       "    'subsample': [0]},\n",
       "   'vals': {'colsample_bylevel': [0.7123342985374396],\n",
       "    'colsample_bytree': [0.9455012808813511],\n",
       "    'conv1': [48.0],\n",
       "    'conv2': [80.0],\n",
       "    'conv3': [152.0],\n",
       "    'dense1': [256.0],\n",
       "    'dense2': [448.0],\n",
       "    'dense3': [160.0],\n",
       "    'dropout_rate': [0.3560048819669964],\n",
       "    'fp': [144.0],\n",
       "    'gamma': [0.3014935659014918],\n",
       "    'learning_rate': [0.8150263751648756],\n",
       "    'lr': [0.0011837712270375551],\n",
       "    'margin': [0.7809169116604946],\n",
       "    'max_bin': [96.0],\n",
       "    'max_delta_step': [4.0],\n",
       "    'max_depth': [12.0],\n",
       "    'min_child_weight': [15.0],\n",
       "    'n_epochs': [40.0],\n",
       "    'reg_alpha': [56.661393667866655],\n",
       "    'reg_lambda': [60.169893877252335],\n",
       "    'subsample': [0.4971284915555839]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2020, 7, 8, 15, 24, 18, 598000),\n",
       "  'refresh_time': datetime.datetime(2020, 7, 8, 15, 33, 41, 632000)},\n",
       " {'state': 2,\n",
       "  'tid': 1,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.8766703640818555, 'status': 'ok'},\n",
       "  'misc': {'tid': 1,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bylevel': [1],\n",
       "    'colsample_bytree': [1],\n",
       "    'conv1': [1],\n",
       "    'conv2': [1],\n",
       "    'conv3': [1],\n",
       "    'dense1': [1],\n",
       "    'dense2': [1],\n",
       "    'dense3': [1],\n",
       "    'dropout_rate': [1],\n",
       "    'fp': [1],\n",
       "    'gamma': [1],\n",
       "    'learning_rate': [1],\n",
       "    'lr': [1],\n",
       "    'margin': [1],\n",
       "    'max_bin': [1],\n",
       "    'max_delta_step': [1],\n",
       "    'max_depth': [1],\n",
       "    'min_child_weight': [1],\n",
       "    'n_epochs': [1],\n",
       "    'reg_alpha': [1],\n",
       "    'reg_lambda': [1],\n",
       "    'subsample': [1]},\n",
       "   'vals': {'colsample_bylevel': [0.13950713368844814],\n",
       "    'colsample_bytree': [0.9373102526453849],\n",
       "    'conv1': [48.0],\n",
       "    'conv2': [120.0],\n",
       "    'conv3': [152.0],\n",
       "    'dense1': [288.0],\n",
       "    'dense2': [224.0],\n",
       "    'dense3': [416.0],\n",
       "    'dropout_rate': [0.12520777652340118],\n",
       "    'fp': [128.0],\n",
       "    'gamma': [0.2209843454018004],\n",
       "    'learning_rate': [0.2750601111653692],\n",
       "    'lr': [0.0030130173973054145],\n",
       "    'margin': [1.7386367746531188],\n",
       "    'max_bin': [96.0],\n",
       "    'max_delta_step': [9.0],\n",
       "    'max_depth': [7.0],\n",
       "    'min_child_weight': [430.0],\n",
       "    'n_epochs': [50.0],\n",
       "    'reg_alpha': [96.78711678968585],\n",
       "    'reg_lambda': [94.35209288298041],\n",
       "    'subsample': [0.8808751334827449]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2020, 7, 8, 15, 33, 41, 640000),\n",
       "  'refresh_time': datetime.datetime(2020, 7, 8, 15, 48, 6, 945000)},\n",
       " {'state': 2,\n",
       "  'tid': 2,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.8735422277492204, 'status': 'ok'},\n",
       "  'misc': {'tid': 2,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'batch_size': [2],\n",
       "    'colsample_bylevel': [2],\n",
       "    'colsample_bytree': [2],\n",
       "    'conv1': [2],\n",
       "    'conv2': [2],\n",
       "    'conv3': [2],\n",
       "    'dense1': [2],\n",
       "    'dense2': [2],\n",
       "    'dense3': [2],\n",
       "    'dropout_rate': [2],\n",
       "    'fp': [2],\n",
       "    'gamma': [2],\n",
       "    'learning_rate': [2],\n",
       "    'lr': [2],\n",
       "    'margin': [2],\n",
       "    'max_bin': [2],\n",
       "    'max_delta_step': [2],\n",
       "    'max_depth': [2],\n",
       "    'min_child_weight': [2],\n",
       "    'n_epochs': [2],\n",
       "    'reg_alpha': [2],\n",
       "    'reg_lambda': [2],\n",
       "    'subsample': [2]},\n",
       "   'vals': {'batch_size': [160.0],\n",
       "    'colsample_bylevel': [0.7745057755137178],\n",
       "    'colsample_bytree': [0.3786041169361566],\n",
       "    'conv1': [48.0],\n",
       "    'conv2': [112.0],\n",
       "    'conv3': [152.0],\n",
       "    'dense1': [416.0],\n",
       "    'dense2': [480.0],\n",
       "    'dense3': [64.0],\n",
       "    'dropout_rate': [0.1772996568822024],\n",
       "    'fp': [128.0],\n",
       "    'gamma': [0.22322127185911134],\n",
       "    'learning_rate': [0.1464319446573148],\n",
       "    'lr': [0.004680244566735545],\n",
       "    'margin': [1.435138273051016],\n",
       "    'max_bin': [80.0],\n",
       "    'max_delta_step': [9.0],\n",
       "    'max_depth': [11.0],\n",
       "    'min_child_weight': [495.0],\n",
       "    'n_epochs': [35.0],\n",
       "    'reg_alpha': [31.202425036677546],\n",
       "    'reg_lambda': [4.6169407433707335],\n",
       "    'subsample': [0.5678684523202147]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2020, 7, 8, 16, 42, 17, 875000),\n",
       "  'refresh_time': datetime.datetime(2020, 7, 8, 16, 48, 21, 513000)}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-119984bec48e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mbest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'misc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vals'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "best_loss = trials.trials[0]['result']['loss']\n",
    "for i in range(1,len(trials.trials)):\n",
    "    if (trials.trials[i]['result']['loss'] <=  best_loss):\n",
    "        best_loss = trials.trials[i]['result']['loss']\n",
    "        index = i\n",
    "best_params = trials.trials[index]['misc']['vals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyper_mining import XGB_predictor,GCN_online_mining\n",
    "from data_analysis import calculate_metrics\n",
    "es = EarlyStopping(monitor='loss',patience=8, min_delta=0)\n",
    "rlr = ReduceLROnPlateau(monitor='loss',factor=0.5, patience=4, verbose=1, min_lr=0.0000001)\n",
    "gcn_params = {\n",
    "        \"num_layers\" : 3,\n",
    "        \"max_atoms\" : 70,\n",
    "        \"num_atom_features\" : 62,\n",
    "        \"num_atom_features_original\" : 62,\n",
    "        \"num_bond_features\" : 6,\n",
    "        \"max_degree\" : 5,\n",
    "        \"conv_width\" : [int(best_params['conv1'][0]), int(best_params['conv2'][0]), int(best_params['conv3'][0])],\n",
    "        \"fp_length\" : [int(best_params['fp'][0]), int(best_params['fp'][0]), int(best_params['fp'][0])],\n",
    "        \"activ_enc\" : \"selu\",\n",
    "        \"activ_dec\" : \"selu\",\n",
    "        \"learning_rates\" : [0.001,0.001,0.001],\n",
    "        \"learning_rates_fp\": [0.005,0.005,0.005],\n",
    "        \"losses_conv\" : {\n",
    "                    \"neighbor_output\": \"mean_squared_error\",\n",
    "                    \"self_output\": \"mean_squared_error\",\n",
    "                    },\n",
    "        \"lossWeights\" : {\"neighbor_output\": 1.0, \"self_output\": 1.0},\n",
    "        \"metrics\" : \"mse\",\n",
    "        \"loss_fp\" : \"mean_squared_error\",\n",
    "        \"enc_layer_names\" : [\"enc_1\", \"enc_2\", \"enc_3\"],\n",
    "        'callbacks' : [es,rlr],\n",
    "        'adam_decay': 0.0005329142291371636,\n",
    "        'beta': 5,\n",
    "        'p': 0.004465204118126482,\n",
    "        'dense_size' : [int(best_params['dense1'][0]), int(best_params['dense2'][0]), int(best_params['dense3'][0])],\n",
    "        'dropout_rate' : [best_params['dropout_rate'][0], best_params['dropout_rate'][0]],\n",
    "        'lr' : best_params['lr'][0],\n",
    "        'batch_size' : int(best_params['batch_size'][0]),\n",
    "        'n_epochs' : int(best_params['n_epochs'][0]),\n",
    "        'margin' : best_params['margin'][0]\n",
    "        }\n",
    "xgb_params = {\n",
    "        \"colsample_bylevel\" : best_params['colsample_bylevel'][0],\n",
    "        \"colsample_bytree\" : best_params['colsample_bytree'][0],\n",
    "        \"gamma\" : best_params['gamma'][0],\n",
    "        \"eta\" : best_params['learning_rate'][0],\n",
    "        \"max_delta_step\" : int(best_params['max_delta_step'][0]),\n",
    "        \"max_depth\" : int(best_params['max_depth'][0]),\n",
    "        \"min_child_weight\" : int(best_params['min_child_weight'][0]),\n",
    "        \"alpha\" : best_params['reg_alpha'][0],\n",
    "        \"lambda\" : best_params['reg_lambda'][0],\n",
    "        \"subsample\" : best_params['subsample'][0],\n",
    "        \"max_bin\" : int(best_params['max_bin'][0]),\n",
    "        \"eval_metric\":'auc',\n",
    "        \"objective\":'binary:logistic',\n",
    "        \"booster\":'gbtree',\n",
    "        \"single_precision_histogram\" : True\n",
    "        }\n",
    "class_XGB = XGB_predictor(xgb_params)\n",
    "class_GCN = GCN_online_mining(gcn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for_test = train_test_folds[0] \n",
    "val_for_test = train_test_folds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_GCN.dataframe_to_gcn_input(training_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.clear_session()\n",
    "training_metrics = {}\n",
    "validation_metrics = {}\n",
    "for i in range(len(training_list)):\n",
    "        X_atoms_cold,X_bonds_cold,X_edges_cold = class_GCN.dataframe_to_gcn_input(validation_list[i])\n",
    "        Y_cold = val_sets[i].Binary \n",
    "        Y_dummy_cold = np.empty((X_atoms_cold.shape[0],gcn_params['dense_size'][2]+1))\n",
    "        X_atoms_train, X_bonds_train, X_edges_train = class_GCN.dataframe_to_gcn_input(training_list[i])\n",
    "        Y = train_sets[i].Binary\n",
    "        Y_dummy_train = np.empty((X_atoms_train.shape[0],gcn_params['dense_size'][2]+1))\n",
    "        \n",
    "        gcn_encoder = class_GCN.build_encoder()\n",
    "        gcn_model = class_GCN.build_model(gcn_encoder)\n",
    "        gcn_mining = class_GCN.build_mining(gcn_model)\n",
    "        \n",
    "        gcn_mining.fit([X_atoms_train,X_bonds_train,X_edges_train,Y],\n",
    "                       Y_dummy_train,\n",
    "                       epochs = gcn_params['epochs'],\n",
    "                       batch_size = gcn_params['batch_size'],\n",
    "                       shuffle = True,\n",
    "                       validation_data = ([X_atoms_cold,X_bonds_cold,X_edges_cold,Y_cold],Y_dummy_cold)\n",
    "                      )\n",
    "        #Predict Embeddings\n",
    "        embeddings_cold = gcn_model.predict([X_atoms_cold,X_bonds_cold,X_edges_cold])\n",
    "        embeddings_train = gcn_model.predict([X_atoms_train, X_bonds_train, X_edges_train])\n",
    "        \n",
    "        #Prepare data for XGBoost\n",
    "        dmatrix_train = class_XGB.to_xgb_input(Y,embeddings_train)\n",
    "        dmatrix_cold = class_XGB.to_xgb_input(Y_cold,embeddings_cold)\n",
    "        \n",
    "        evalist = [(dmatrix_train,'train'),(dmatrix_cold,'eval')]\n",
    "        xgb_model = class_XGB.build_model(dmatrix_train,evalist,300)\n",
    "        \n",
    "        xgb_pred_cold = xgb_model.predict(dmatrix_cold)\n",
    "        validation_metrics['Val_%s'%i] = calculate_metrics(np.array(Y_cold),xgb_pred_cold)\n",
    "        \n",
    "        xgb_pred_train = xgb_model.predict(dmatrix_train)\n",
    "        training_metrics['Train_%s'%i] = calculate_metrics(np.array(Y,xgb_pred_train))\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
