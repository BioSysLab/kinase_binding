{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras_applications' has no attribute 'set_keras_submodules'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-705630a95708>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdata_analysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcalculate_metrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_weights_and_evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\binding\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\binding\\lib\\site-packages\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_applications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m keras_applications.set_keras_submodules(\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras_applications' has no attribute 'set_keras_submodules'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.callbacks import History, ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "from data_analysis import calculate_metrics, load_weights_and_evaluate\n",
    "from model_builders import GCN_pretraining\n",
    "from hyperparameter_tuning_GCN import objective\n",
    "from functools import partial\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import pickle\n",
    "import dill\n",
    "from hyper_mining import objective_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fspace = {\n",
    "    'conv1' : hp.quniform('conv1', 32, 64, 8),\n",
    "    'conv2' : hp.quniform('conv2', 64, 128, 8),\n",
    "    'conv3' : hp.quniform('conv3', 128, 168, 8),\n",
    "    'fp' : hp.quniform('fp', 96, 196, 8),\n",
    "    'dense1' : hp.quniform('dense1',96,512,32),\n",
    "    'dense2' : hp.quniform('dense2',96,512,32),\n",
    "    'dense3' : hp.quniform('dense3',64,512,32),\n",
    "    'dropout_rate' : hp.uniform('dropout_rate',0.1,0.5),\n",
    "    'lr' : hp.uniform('lr',0.00001,0.01),\n",
    "    'n_epochs' : hp.quniform('n_epochs',15,60,5),\n",
    "    'colsample_bylevel' : hp.uniform('colsample_bylevel', 0.1, 1), \n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.1, 1), \n",
    "    'gamma' : hp.uniform('gamma', 0.1, 1), \n",
    "    'learning_rate' : hp.uniform('learning_rate', 0.1, 1),\n",
    "    'max_delta_step' : hp.quniform('max_delta_step',1,10,1),\n",
    "    'max_depth' : hp.quniform('max_depth',6, 12, 1),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight',10 ,500 ,5),\n",
    "    'reg_alpha' : hp.uniform('reg_alpha',0.1,100),\n",
    "    'reg_lambda' : hp.uniform('reg_lambda',0.1,100),\n",
    "    'subsample' : hp.uniform('subsample',0.1,1.0),\n",
    "    'max_bin' : hp.quniform('max_bin',16,256,16),\n",
    "    'margin' : hp.uniform('margin',0.2,2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'p38'\n",
    "base_path = f'C:/Users/tomas/Documents/GitHub/kinase_binding'\n",
    "\n",
    "data_fpath = base_path+f'/data/{target}/data.csv'\n",
    "df=pd.read_csv(data_fpath).set_index('biolab_index')\n",
    "\n",
    "with open(base_path+f'/data/{target}/train_val_folds.pkl', \"rb\") as in_f:\n",
    "    train_val_folds = dill.load(in_f)\n",
    "with open(base_path+f'/data/{target}/train_test_folds.pkl', \"rb\") as in_f:\n",
    "    train_test_folds = dill.load(in_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_list = [df.loc[train_val_folds[0][0]],\n",
    "                 df.loc[train_val_folds[1][0]],\n",
    "                 df.loc[train_val_folds[2][0]],\n",
    "                 df.loc[train_val_folds[3][0]],\n",
    "                 df.loc[train_val_folds[4][0]],\n",
    "                 df.loc[train_val_folds[5][0]],\n",
    "                 ]\n",
    "validation_list = [df.loc[train_val_folds[0][1]],\n",
    "                   df.loc[train_val_folds[1][1]],\n",
    "                   df.loc[train_val_folds[2][1]],\n",
    "                   df.loc[train_val_folds[3][1]],\n",
    "                   df.loc[train_val_folds[4][1]],\n",
    "                   df.loc[train_val_folds[5][1]],\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin_objective = partial(objective, train_sets = training_list, val_sets = validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trials():\n",
    "\n",
    "    trials_step = 2  # how many additional trials to do after loading saved trials. 1 = save after iteration\n",
    "    max_trials = 3  # initial max_trials. put something small to not have to wait\n",
    "\n",
    "    \n",
    "    try:  # try to load an already saved trials object, and increase the max\n",
    "        trials = pickle.load(open(\"gcn_xgb.hyperopt\", \"rb\"))\n",
    "        print(\"Found saved Trials! Loading...\")\n",
    "        max_trials = len(trials.trials) + trials_step\n",
    "        print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n",
    "    except:  # create a new trials object and start searching\n",
    "        trials = Trials()\n",
    "\n",
    "    best = fmin(fn = fmin_objective, space = fspace, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n",
    "\n",
    "    print(\"Best:\", best)\n",
    "    \n",
    "    # save the trials object\n",
    "    with open(\"gcn_xgb.hyperopt\", \"wb\") as f:\n",
    "        pickle.dump(trials, f)\n",
    "    return(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found saved Trials! Loading...\n",
      "Rerunning from 4 trials to 6 (+2) trials\n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      " 67%|█████████████████████████████████████████████▎                      | 4/6 [00:05<00:02,  1.41s/trial, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "LAYER 0                                                                                                                \n",
      "LAYER 1                                                                                                                \n",
      "LAYER 2                                                                                                                \n",
      "100%|█████████████████████████████████████████████████| 6/6 [12:37<00:00, 126.29s/trial, best loss: -0.874581524908728]\n",
      "Best: {'colsample_bylevel': 0.5294899581185151, 'colsample_bytree': 0.7858150978048407, 'conv1': 56.0, 'conv2': 120.0, 'conv3': 112.0, 'dense1': 384.0, 'dense2': 224.0, 'dense3': 160.0, 'dropout_rate': 0.11415324180353657, 'fp': 160.0, 'gamma': 0.6324817835594707, 'learning_rate': 0.9768050920176441, 'lr': 0.004495277476954444, 'margin': 0.8571777831497982, 'max_bin': 96.0, 'max_delta_step': 5.0, 'max_depth': 8.0, 'min_child_weight': 495.0, 'n_epochs': 45.0, 'reg_alpha': 94.60018261752123, 'reg_lambda': 68.43669717710421, 'subsample': 0.46305532887435397}\n"
     ]
    }
   ],
   "source": [
    "trials = run_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
