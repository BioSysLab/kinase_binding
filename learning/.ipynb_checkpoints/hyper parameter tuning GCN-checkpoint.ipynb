{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.callbacks import History, ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "from data_analysis import calculate_metrics, load_weights_and_evaluate\n",
    "from model_builders import GCN_pretraining\n",
    "from hyperparameter_tuning_GCN import objective\n",
    "from functools import partial\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import pickle\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model callbacks on training\n",
    "es = EarlyStopping(monitor='loss',patience=8, min_delta=0)\n",
    "rlr = ReduceLROnPlateau(monitor='loss',factor=0.5, patience=4, verbose=1, min_lr=0.0000001)\n",
    "\n",
    "model_params = {\n",
    "        \"num_layers\" : 3,\n",
    "        \"max_atoms\" : 70,\n",
    "        \"num_atom_features\" : 62,\n",
    "        \"num_atom_features_original\" : 62,\n",
    "        \"num_bond_features\" : 6,\n",
    "        \"max_degree\" : 5,\n",
    "        \"conv_width\" : [32,64,96],\n",
    "        \"fp_length\" : [96,96,96],\n",
    "        \"activ_enc\" : \"selu\",\n",
    "        \"activ_dec\" : \"selu\",\n",
    "        \"learning_rates\" : [0.001,0.001,0.001],\n",
    "        \"learning_rates_fp\": [0.005,0.005,0.005],\n",
    "        \"losses_conv\" : {\n",
    "                    \"neighbor_output\": \"mean_squared_error\",\n",
    "                    \"self_output\": \"mean_squared_error\",\n",
    "                    },\n",
    "        \"lossWeights\" : {\"neighbor_output\": 1.0, \"self_output\": 1.0},\n",
    "        \"metrics\" : \"mse\",\n",
    "        \"loss_fp\" : \"mean_squared_error\",\n",
    "        \"enc_layer_names\" : [\"enc_1\", \"enc_2\", \"enc_3\"],\n",
    "        'callbacks' : [es,rlr],\n",
    "        'adam_decay': 0.0005329142291371636,\n",
    "        'beta': 5,\n",
    "        'p': 0.004465204118126482,\n",
    "        'dense_size' : [96,96,48],\n",
    "        'dropout_rate' : [0.1,0.1],\n",
    "        'lr' : 0.001,\n",
    "        'batch_size' : int(64),\n",
    "        'n_epochs' : int(5)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fspace = {\n",
    "    'conv1' : hp.quniform('conv1', 32, 96, 8),\n",
    "    'conv2' : hp.quniform('conv2', 48, 128, 8),\n",
    "    'conv3' : hp.quniform('conv3', 64, 168, 8),\n",
    "    'fp' : hp.quniform('fp', 64, 196, 8),\n",
    "    'dense1' : hp.quniform('dense1',96,256,32),\n",
    "    'dense2' : hp.quniform('dense2',96,256,32),\n",
    "    'dense3' : hp.quniform('dense3',48,128,32),\n",
    "    'dropout_rate' : hp.uniform('dropout_rate',0.1,0.5),\n",
    "    'lr' : hp.uniform('lr',0.0005,0.01),\n",
    "    'n_epochs' : hp.quniform('n_epochs',15,40,5) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1 = 'p38'\n",
    "base_path_1 = f'C:/Users/tomas/Documents/GitHub/kinase_binding'\n",
    "\n",
    "data_fpath_1 = base_path_1+f'/data/{target_1}/data.csv'\n",
    "df_p38=pd.read_csv(data_fpath_1).set_index('biolab_index')\n",
    "\n",
    "with open(base_path_1+f'/data/{target_1}/train_val_folds.pkl', \"rb\") as in_f:\n",
    "    train_val_folds_p38 = dill.load(in_f)\n",
    "\n",
    "with open(base_path_1+f'/data/{target_1}/train_test_folds.pkl', \"rb\") as in_f:\n",
    "    train_test_folds_p38 = dill.load(in_f)\n",
    "\n",
    "training_p38 = [df_p38.loc[train_val_folds_p38[0][0]],\n",
    "                 df_p38.loc[train_val_folds_p38[1][0]],\n",
    "                 df_p38.loc[train_val_folds_p38[2][0]],\n",
    "                 df_p38.loc[train_val_folds_p38[3][0]],\n",
    "                 df_p38.loc[train_val_folds_p38[4][0]],\n",
    "                 df_p38.loc[train_val_folds_p38[5][0]],\n",
    "                 df_p38.loc[train_test_folds_p38[0]]\n",
    "                 ]\n",
    "validation_p38 = [df_p38.loc[train_val_folds_p38[0][1]],\n",
    "                   df_p38.loc[train_val_folds_p38[1][1]],\n",
    "                   df_p38.loc[train_val_folds_p38[2][1]],\n",
    "                   df_p38.loc[train_val_folds_p38[3][1]],\n",
    "                   df_p38.loc[train_val_folds_p38[4][1]],\n",
    "                   df_p38.loc[train_val_folds_p38[5][1]],\n",
    "                   df_p38.loc[train_test_folds_p38[1]]\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin_objective = partial(objective, train_sets = training_p38, val_sets = validation_p38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trials():\n",
    "\n",
    "    trials_step = 0  # how many additional trials to do after loading saved trials. 1 = save after iteration\n",
    "    max_trials = 0  # initial max_trials. put something small to not have to wait\n",
    "\n",
    "    \n",
    "    try:  # try to load an already saved trials object, and increase the max\n",
    "        trials = pickle.load(open(\"gcn.hyperopt\", \"rb\"))\n",
    "        print(\"Found saved Trials! Loading...\")\n",
    "        max_trials = len(trials.trials) + trials_step\n",
    "        print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n",
    "    except:  # create a new trials object and start searching\n",
    "        trials = Trials()\n",
    "\n",
    "    best = fmin(fn = fmin_objective, space = fspace, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n",
    "\n",
    "    print(\"Best:\", best)\n",
    "    \n",
    "    # save the trials object\n",
    "    with open(\"gcn.hyperopt\", \"wb\") as f:\n",
    "        pickle.dump(trials, f)\n",
    "    return(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found saved Trials! Loading...\n",
      "Rerunning from 555 trials to 555 (+0) trials\n",
      "100%|████████████████████████████████████████████████████████████████████████| 555/555 [00:00<?, ?trial/s, best loss=?]\n",
      "Best: {'conv1': 96.0, 'conv2': 104.0, 'conv3': 120.0, 'dense1': 256.0, 'dense2': 192.0, 'dense3': 96.0, 'dropout_rate': 0.3554537312557061, 'fp': 160.0, 'lr': 0.007037117031430456, 'n_epochs': 35.0}\n"
     ]
    }
   ],
   "source": [
    "trials = run_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = trials.trials[0]['result']['loss']\n",
    "for i in range(1,len(trials.trials)):\n",
    "    if (trials.trials[i]['result']['loss'] <=  best_loss):\n",
    "        best_loss = trials.trials[i]['result']['loss']\n",
    "        index = i\n",
    "best_params = trials.trials[index]['misc']['vals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperparameter_tuning_GCN import GCN_hyper\n",
    "es = EarlyStopping(monitor='loss',patience=8, min_delta=0)\n",
    "rlr = ReduceLROnPlateau(monitor='loss',factor=0.5, patience=4, verbose=1, min_lr=0.0000001)\n",
    "gcn_best = {\n",
    "        \"num_layers\" : 3,\n",
    "        \"max_atoms\" : 70,\n",
    "        \"num_atom_features\" : 62,\n",
    "        \"num_atom_features_original\" : 62,\n",
    "        \"num_bond_features\" : 6,\n",
    "        \"max_degree\" : 5,\n",
    "        \"conv_width\" : [int(best_params['conv1'][0]), int(best_params['conv2'][0]), int(best_params['conv3'][0])],\n",
    "        \"fp_length\" : [int(best_params['fp'][0]), int(best_params['fp'][0]), int(best_params['fp'][0])],\n",
    "        \"activ_enc\" : \"selu\",\n",
    "        \"activ_dec\" : \"selu\",\n",
    "        \"learning_rates\" : [0.001,0.001,0.001],\n",
    "        \"learning_rates_fp\": [0.005,0.005,0.005],\n",
    "        \"losses_conv\" : {\n",
    "                    \"neighbor_output\": \"mean_squared_error\",\n",
    "                    \"self_output\": \"mean_squared_error\",\n",
    "                    },\n",
    "        \"lossWeights\" : {\"neighbor_output\": 1.0, \"self_output\": 1.0},\n",
    "        \"metrics\" : \"mse\",\n",
    "        \"loss_fp\" : \"mean_squared_error\",\n",
    "        \"enc_layer_names\" : [\"enc_1\", \"enc_2\", \"enc_3\"],\n",
    "        'callbacks' : [es,rlr],\n",
    "        'adam_decay': 0.0005329142291371636,\n",
    "        'beta': 5,\n",
    "        'p': 0.004465204118126482,\n",
    "        'dense_size' : [int(best_params['dense1'][0]), int(best_params['dense2'][0]), int(best_params['dense3'][0])],\n",
    "        'dropout_rate' : [best_params['dropout_rate'][0], best_params['dropout_rate'][0]],\n",
    "        'lr' : best_params['lr'][0],\n",
    "        'batch_size' : int(64),\n",
    "        'n_epochs' : int(best_params['n_epochs'][0])\n",
    "        }\n",
    "gcn = GCN_hyper(gcn_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2541 samples, validate on 509 samples\n",
      "Epoch 1/35\n",
      "2541/2541 [==============================] - 6s 2ms/step - loss: 0.6986 - acc: 0.5321 - val_loss: 0.6253 - val_acc: 0.6739\n",
      "Epoch 2/35\n",
      "2541/2541 [==============================] - 1s 531us/step - loss: 0.6351 - acc: 0.6478 - val_loss: 0.7989 - val_acc: 0.4892\n",
      "Epoch 3/35\n",
      "2541/2541 [==============================] - 1s 536us/step - loss: 0.5687 - acc: 0.7111 - val_loss: 0.5472 - val_acc: 0.7014\n",
      "Epoch 4/35\n",
      "2541/2541 [==============================] - 1s 522us/step - loss: 0.5401 - acc: 0.7285 - val_loss: 0.5372 - val_acc: 0.7387\n",
      "Epoch 5/35\n",
      "2541/2541 [==============================] - 1s 534us/step - loss: 0.5299 - acc: 0.7434 - val_loss: 0.5312 - val_acc: 0.7033\n",
      "Epoch 6/35\n",
      "2541/2541 [==============================] - 1s 514us/step - loss: 0.5058 - acc: 0.7568 - val_loss: 0.5271 - val_acc: 0.7269\n",
      "Epoch 7/35\n",
      "2541/2541 [==============================] - 1s 552us/step - loss: 0.4920 - acc: 0.7572 - val_loss: 0.5227 - val_acc: 0.7721\n",
      "Epoch 8/35\n",
      "2541/2541 [==============================] - 1s 548us/step - loss: 0.4867 - acc: 0.7662 - val_loss: 0.5268 - val_acc: 0.7308\n",
      "Epoch 9/35\n",
      "2541/2541 [==============================] - 1s 564us/step - loss: 0.4571 - acc: 0.7887 - val_loss: 0.5331 - val_acc: 0.7092\n",
      "Epoch 10/35\n",
      "2541/2541 [==============================] - 1s 540us/step - loss: 0.4662 - acc: 0.7828 - val_loss: 0.4524 - val_acc: 0.7878\n",
      "Epoch 11/35\n",
      "2541/2541 [==============================] - 1s 535us/step - loss: 0.4515 - acc: 0.7891 - val_loss: 0.4469 - val_acc: 0.8016\n",
      "Epoch 12/35\n",
      "2541/2541 [==============================] - 1s 527us/step - loss: 0.4568 - acc: 0.7694 - val_loss: 0.4953 - val_acc: 0.7289\n",
      "Epoch 13/35\n",
      "2541/2541 [==============================] - 1s 523us/step - loss: 0.4333 - acc: 0.7898 - val_loss: 0.4843 - val_acc: 0.7544\n",
      "Epoch 14/35\n",
      "2541/2541 [==============================] - 1s 552us/step - loss: 0.4734 - acc: 0.7721 - val_loss: 0.4634 - val_acc: 0.7898\n",
      "Epoch 15/35\n",
      "2541/2541 [==============================] - 1s 525us/step - loss: 0.4428 - acc: 0.7867 - val_loss: 0.4528 - val_acc: 0.7937\n",
      "Epoch 16/35\n",
      "2541/2541 [==============================] - 1s 512us/step - loss: 0.4435 - acc: 0.7969 - val_loss: 0.4825 - val_acc: 0.7701\n",
      "Epoch 17/35\n",
      "2541/2541 [==============================] - 1s 523us/step - loss: 0.4368 - acc: 0.7808 - val_loss: 0.4395 - val_acc: 0.7937\n",
      "Epoch 18/35\n",
      "2541/2541 [==============================] - 1s 569us/step - loss: 0.4304 - acc: 0.7710 - val_loss: 0.4359 - val_acc: 0.7819\n",
      "Epoch 19/35\n",
      "2541/2541 [==============================] - 1s 548us/step - loss: 0.4265 - acc: 0.7938 - val_loss: 0.4709 - val_acc: 0.7917\n",
      "Epoch 20/35\n",
      "2541/2541 [==============================] - 1s 539us/step - loss: 0.4312 - acc: 0.8091 - val_loss: 0.4463 - val_acc: 0.8016\n",
      "Epoch 21/35\n",
      "2541/2541 [==============================] - 1s 541us/step - loss: 0.4098 - acc: 0.8044 - val_loss: 0.4665 - val_acc: 0.7996\n",
      "Epoch 22/35\n",
      "2541/2541 [==============================] - 1s 565us/step - loss: 0.3974 - acc: 0.8154 - val_loss: 0.4386 - val_acc: 0.8035\n",
      "Epoch 23/35\n",
      "2541/2541 [==============================] - 1s 536us/step - loss: 0.4139 - acc: 0.8020 - val_loss: 0.4367 - val_acc: 0.8153\n",
      "Epoch 24/35\n",
      "2541/2541 [==============================] - 1s 539us/step - loss: 0.3965 - acc: 0.8060 - val_loss: 0.4318 - val_acc: 0.8055\n",
      "Epoch 25/35\n",
      "2541/2541 [==============================] - 1s 553us/step - loss: 0.3873 - acc: 0.8166 - val_loss: 0.4106 - val_acc: 0.8232\n",
      "Epoch 26/35\n",
      "2541/2541 [==============================] - 1s 532us/step - loss: 0.3615 - acc: 0.8327 - val_loss: 0.4393 - val_acc: 0.8134\n",
      "Epoch 27/35\n",
      "2541/2541 [==============================] - 1s 530us/step - loss: 0.3579 - acc: 0.8430 - val_loss: 0.4547 - val_acc: 0.7662\n",
      "Epoch 28/35\n",
      "2541/2541 [==============================] - 2s 697us/step - loss: 0.3639 - acc: 0.8355 - val_loss: 0.4476 - val_acc: 0.8035\n",
      "Epoch 29/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3569 - acc: 0.8442 - val_loss: 0.4435 - val_acc: 0.7937\n",
      "Epoch 30/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3742 - acc: 0.8284 - val_loss: 0.4521 - val_acc: 0.7917\n",
      "Epoch 31/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3650 - acc: 0.8398 - val_loss: 0.4398 - val_acc: 0.7976\n",
      "Epoch 32/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3713 - acc: 0.8261 - val_loss: 0.4370 - val_acc: 0.8094\n",
      "Epoch 33/35\n",
      "2541/2541 [==============================] - 1s 546us/step - loss: 0.3628 - acc: 0.8331 - val_loss: 0.4642 - val_acc: 0.7976\n",
      "Epoch 34/35\n",
      "2541/2541 [==============================] - 1s 537us/step - loss: 0.3617 - acc: 0.8398 - val_loss: 0.4634 - val_acc: 0.7819\n",
      "Epoch 35/35\n",
      "2541/2541 [==============================] - 1s 535us/step - loss: 0.3474 - acc: 0.8418 - val_loss: 0.4421 - val_acc: 0.8153\n",
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2541 samples, validate on 509 samples\n",
      "Epoch 1/35\n",
      "2541/2541 [==============================] - 6s 2ms/step - loss: 0.6839 - acc: 0.5474 - val_loss: 0.6336 - val_acc: 0.6326\n",
      "Epoch 2/35\n",
      "2541/2541 [==============================] - 1s 532us/step - loss: 0.6055 - acc: 0.6938 - val_loss: 0.5952 - val_acc: 0.7014\n",
      "Epoch 3/35\n",
      "2541/2541 [==============================] - 1s 547us/step - loss: 0.5665 - acc: 0.7166 - val_loss: 0.4940 - val_acc: 0.7682\n",
      "Epoch 4/35\n",
      "2541/2541 [==============================] - 1s 545us/step - loss: 0.5248 - acc: 0.7489 - val_loss: 0.5462 - val_acc: 0.6699\n",
      "Epoch 5/35\n",
      "2541/2541 [==============================] - 1s 546us/step - loss: 0.5404 - acc: 0.7434 - val_loss: 0.5624 - val_acc: 0.7053\n",
      "Epoch 6/35\n",
      "2541/2541 [==============================] - 1s 547us/step - loss: 0.5056 - acc: 0.7580 - val_loss: 0.4487 - val_acc: 0.7819\n",
      "Epoch 7/35\n",
      "2541/2541 [==============================] - 2s 625us/step - loss: 0.4922 - acc: 0.7623 - val_loss: 0.4275 - val_acc: 0.8016\n",
      "Epoch 8/35\n",
      "2541/2541 [==============================] - 2s 606us/step - loss: 0.4891 - acc: 0.7717 - val_loss: 0.4986 - val_acc: 0.7544\n",
      "Epoch 9/35\n",
      "2541/2541 [==============================] - 1s 566us/step - loss: 0.4903 - acc: 0.7666 - val_loss: 0.4731 - val_acc: 0.7623\n",
      "Epoch 10/35\n",
      "2541/2541 [==============================] - 1s 585us/step - loss: 0.4662 - acc: 0.7784 - val_loss: 0.4744 - val_acc: 0.7662\n",
      "Epoch 11/35\n",
      "2541/2541 [==============================] - 2s 874us/step - loss: 0.4767 - acc: 0.7804 - val_loss: 0.4408 - val_acc: 0.7957\n",
      "Epoch 12/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4677 - acc: 0.7741 - val_loss: 0.4499 - val_acc: 0.7682\n",
      "Epoch 13/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4662 - acc: 0.7702 - val_loss: 0.4341 - val_acc: 0.7682\n",
      "Epoch 14/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4489 - acc: 0.7922 - val_loss: 0.4634 - val_acc: 0.7800\n",
      "Epoch 15/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4382 - acc: 0.7961 - val_loss: 0.4417 - val_acc: 0.7996\n",
      "Epoch 16/35\n",
      "2541/2541 [==============================] - 2s 611us/step - loss: 0.4358 - acc: 0.7981 - val_loss: 0.4299 - val_acc: 0.7839\n",
      "Epoch 17/35\n",
      "2541/2541 [==============================] - 1s 580us/step - loss: 0.4283 - acc: 0.7843 - val_loss: 0.4081 - val_acc: 0.8153\n",
      "Epoch 18/35\n",
      "2541/2541 [==============================] - 2s 601us/step - loss: 0.4543 - acc: 0.7619 - val_loss: 0.4484 - val_acc: 0.7701\n",
      "Epoch 19/35\n",
      "2541/2541 [==============================] - 1s 561us/step - loss: 0.4425 - acc: 0.7863 - val_loss: 0.4235 - val_acc: 0.7878\n",
      "Epoch 20/35\n",
      "2541/2541 [==============================] - 1s 583us/step - loss: 0.4056 - acc: 0.8056 - val_loss: 0.3918 - val_acc: 0.8173\n",
      "Epoch 21/35\n",
      "2541/2541 [==============================] - 1s 550us/step - loss: 0.4012 - acc: 0.8056 - val_loss: 0.4398 - val_acc: 0.7976\n",
      "Epoch 22/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4033 - acc: 0.8083 - val_loss: 0.4464 - val_acc: 0.7839\n",
      "Epoch 23/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4288 - acc: 0.7879 - val_loss: 0.4078 - val_acc: 0.7957\n",
      "Epoch 24/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4112 - acc: 0.7973 - val_loss: 0.3990 - val_acc: 0.8035\n",
      "Epoch 25/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3761 - acc: 0.8221 - val_loss: 0.3958 - val_acc: 0.8134\n",
      "Epoch 26/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3763 - acc: 0.8276 - val_loss: 0.4066 - val_acc: 0.7976\n",
      "Epoch 27/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3780 - acc: 0.8237 - val_loss: 0.4599 - val_acc: 0.7780\n",
      "Epoch 28/35\n",
      "2541/2541 [==============================] - 2s 825us/step - loss: 0.3658 - acc: 0.8241 - val_loss: 0.4155 - val_acc: 0.8134\n",
      "Epoch 29/35\n",
      "2541/2541 [==============================] - 1s 536us/step - loss: 0.3805 - acc: 0.8079 - val_loss: 0.3814 - val_acc: 0.8153\n",
      "Epoch 30/35\n",
      "2541/2541 [==============================] - 1s 558us/step - loss: 0.3842 - acc: 0.8182 - val_loss: 0.3999 - val_acc: 0.8094\n",
      "Epoch 31/35\n",
      "2541/2541 [==============================] - 1s 569us/step - loss: 0.3623 - acc: 0.8300 - val_loss: 0.3856 - val_acc: 0.8369\n",
      "Epoch 32/35\n",
      "2541/2541 [==============================] - 1s 579us/step - loss: 0.3540 - acc: 0.8284 - val_loss: 0.4042 - val_acc: 0.7957\n",
      "Epoch 33/35\n",
      "2541/2541 [==============================] - 1s 566us/step - loss: 0.3563 - acc: 0.8213 - val_loss: 0.3978 - val_acc: 0.8114\n",
      "Epoch 34/35\n",
      "2541/2541 [==============================] - 1s 585us/step - loss: 0.3608 - acc: 0.8300 - val_loss: 0.3970 - val_acc: 0.8153\n",
      "Epoch 35/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3467 - acc: 0.8335 - val_loss: 0.3855 - val_acc: 0.8389\n",
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2541 samples, validate on 509 samples\n",
      "Epoch 1/35\n",
      "2541/2541 [==============================] - 7s 3ms/step - loss: 0.6970 - acc: 0.5352 - val_loss: 0.6671 - val_acc: 0.5972\n",
      "Epoch 2/35\n",
      "2541/2541 [==============================] - 1s 533us/step - loss: 0.6101 - acc: 0.6726 - val_loss: 0.6162 - val_acc: 0.6562\n",
      "Epoch 3/35\n",
      "2541/2541 [==============================] - 1s 555us/step - loss: 0.5554 - acc: 0.7320 - val_loss: 0.6299 - val_acc: 0.6385\n",
      "Epoch 4/35\n",
      "2541/2541 [==============================] - 1s 564us/step - loss: 0.5270 - acc: 0.7442 - val_loss: 0.5678 - val_acc: 0.6994\n",
      "Epoch 5/35\n",
      "2541/2541 [==============================] - 1s 551us/step - loss: 0.4765 - acc: 0.7721 - val_loss: 0.5905 - val_acc: 0.6896\n",
      "Epoch 6/35\n",
      "2541/2541 [==============================] - 1s 560us/step - loss: 0.4798 - acc: 0.7749 - val_loss: 0.5769 - val_acc: 0.7014\n",
      "Epoch 7/35\n",
      "2541/2541 [==============================] - 1s 535us/step - loss: 0.4780 - acc: 0.7713 - val_loss: 0.5532 - val_acc: 0.7132\n",
      "Epoch 8/35\n",
      "2541/2541 [==============================] - 1s 551us/step - loss: 0.4701 - acc: 0.7867 - val_loss: 0.5684 - val_acc: 0.6896\n",
      "Epoch 9/35\n",
      "2541/2541 [==============================] - 2s 952us/step - loss: 0.4550 - acc: 0.7835 - val_loss: 0.5505 - val_acc: 0.7171\n",
      "Epoch 10/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4347 - acc: 0.8005 - val_loss: 0.5394 - val_acc: 0.7407\n",
      "Epoch 11/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4244 - acc: 0.7989 - val_loss: 0.5236 - val_acc: 0.7387\n",
      "Epoch 12/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4280 - acc: 0.7910 - val_loss: 0.5575 - val_acc: 0.7033\n",
      "Epoch 13/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4377 - acc: 0.8013 - val_loss: 0.5185 - val_acc: 0.7505\n",
      "Epoch 14/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4173 - acc: 0.8072 - val_loss: 0.5306 - val_acc: 0.7191\n",
      "Epoch 15/35\n",
      "2541/2541 [==============================] - 2s 661us/step - loss: 0.4072 - acc: 0.8170 - val_loss: 0.5511 - val_acc: 0.7191\n",
      "Epoch 16/35\n",
      "2541/2541 [==============================] - 1s 550us/step - loss: 0.4110 - acc: 0.8123 - val_loss: 0.5045 - val_acc: 0.7544\n",
      "Epoch 17/35\n",
      "2541/2541 [==============================] - 1s 575us/step - loss: 0.4087 - acc: 0.8068 - val_loss: 0.4811 - val_acc: 0.7564\n",
      "Epoch 18/35\n",
      "2541/2541 [==============================] - 1s 539us/step - loss: 0.4059 - acc: 0.8142 - val_loss: 0.5000 - val_acc: 0.7525\n",
      "Epoch 19/35\n",
      "2541/2541 [==============================] - 1s 534us/step - loss: 0.3946 - acc: 0.8174 - val_loss: 0.4871 - val_acc: 0.7741\n",
      "Epoch 20/35\n",
      "2541/2541 [==============================] - 2s 774us/step - loss: 0.3823 - acc: 0.8213 - val_loss: 0.5195 - val_acc: 0.7682\n",
      "Epoch 21/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3803 - acc: 0.8268 - val_loss: 0.4871 - val_acc: 0.7583\n",
      "Epoch 22/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3796 - acc: 0.8205 - val_loss: 0.5558 - val_acc: 0.7701\n",
      "Epoch 23/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3687 - acc: 0.8312 - val_loss: 0.4669 - val_acc: 0.7642\n",
      "Epoch 24/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3597 - acc: 0.8308 - val_loss: 0.5082 - val_acc: 0.7564\n",
      "Epoch 25/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3650 - acc: 0.8363 - val_loss: 0.4663 - val_acc: 0.7859\n",
      "Epoch 26/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3558 - acc: 0.8379 - val_loss: 0.4715 - val_acc: 0.7623\n",
      "Epoch 27/35\n",
      "2541/2541 [==============================] - 2s 725us/step - loss: 0.3600 - acc: 0.8438 - val_loss: 0.4320 - val_acc: 0.7859\n",
      "Epoch 28/35\n",
      "2541/2541 [==============================] - 1s 554us/step - loss: 0.3586 - acc: 0.8327 - val_loss: 0.4757 - val_acc: 0.7760\n",
      "Epoch 29/35\n",
      "2541/2541 [==============================] - 1s 540us/step - loss: 0.3548 - acc: 0.8445 - val_loss: 0.4325 - val_acc: 0.7839\n",
      "Epoch 30/35\n",
      "2541/2541 [==============================] - 1s 542us/step - loss: 0.3595 - acc: 0.8304 - val_loss: 0.4913 - val_acc: 0.7642\n",
      "Epoch 31/35\n",
      "2541/2541 [==============================] - 1s 542us/step - loss: 0.3422 - acc: 0.8434 - val_loss: 0.4441 - val_acc: 0.7859\n",
      "Epoch 32/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3491 - acc: 0.8363 - val_loss: 0.4433 - val_acc: 0.7839\n",
      "Epoch 33/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3335 - acc: 0.8414 - val_loss: 0.4876 - val_acc: 0.7525\n",
      "Epoch 34/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3219 - acc: 0.8520 - val_loss: 0.4542 - val_acc: 0.7760\n",
      "Epoch 35/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3209 - acc: 0.8512 - val_loss: 0.4384 - val_acc: 0.7701\n",
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2541 samples, validate on 509 samples\n",
      "Epoch 1/35\n",
      "2541/2541 [==============================] - 8s 3ms/step - loss: 0.7037 - acc: 0.4978 - val_loss: 0.6800 - val_acc: 0.5815\n",
      "Epoch 2/35\n",
      "2541/2541 [==============================] - 1s 570us/step - loss: 0.6592 - acc: 0.6171 - val_loss: 0.5982 - val_acc: 0.6837\n",
      "Epoch 3/35\n",
      "2541/2541 [==============================] - 1s 542us/step - loss: 0.5753 - acc: 0.7025 - val_loss: 0.6519 - val_acc: 0.5953\n",
      "Epoch 4/35\n",
      "2541/2541 [==============================] - 1s 559us/step - loss: 0.5903 - acc: 0.6985 - val_loss: 0.6076 - val_acc: 0.7073\n",
      "Epoch 5/35\n",
      "2541/2541 [==============================] - 1s 561us/step - loss: 0.5339 - acc: 0.7316 - val_loss: 0.5542 - val_acc: 0.7348\n",
      "Epoch 6/35\n",
      "2541/2541 [==============================] - 1s 536us/step - loss: 0.5232 - acc: 0.7418 - val_loss: 0.5542 - val_acc: 0.7289\n",
      "Epoch 7/35\n",
      "2541/2541 [==============================] - 1s 562us/step - loss: 0.5013 - acc: 0.7521 - val_loss: 0.5504 - val_acc: 0.7250\n",
      "Epoch 8/35\n",
      "2541/2541 [==============================] - 1s 557us/step - loss: 0.4835 - acc: 0.7588 - val_loss: 0.5586 - val_acc: 0.6955\n",
      "Epoch 9/35\n",
      "2541/2541 [==============================] - 1s 577us/step - loss: 0.4817 - acc: 0.7580 - val_loss: 0.5380 - val_acc: 0.7446\n",
      "Epoch 10/35\n",
      "2541/2541 [==============================] - 2s 910us/step - loss: 0.4602 - acc: 0.7745 - val_loss: 0.5340 - val_acc: 0.7583\n",
      "Epoch 11/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4374 - acc: 0.7875 - val_loss: 0.5228 - val_acc: 0.7230\n",
      "Epoch 12/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4359 - acc: 0.7895 - val_loss: 0.5095 - val_acc: 0.7446\n",
      "Epoch 13/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4504 - acc: 0.7792 - val_loss: 0.4932 - val_acc: 0.7505\n",
      "Epoch 14/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4353 - acc: 0.7914 - val_loss: 0.4829 - val_acc: 0.7859\n",
      "Epoch 15/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4164 - acc: 0.7997 - val_loss: 0.4801 - val_acc: 0.7564\n",
      "Epoch 16/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4139 - acc: 0.7989 - val_loss: 0.4746 - val_acc: 0.7682\n",
      "Epoch 17/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4055 - acc: 0.8099 - val_loss: 0.4880 - val_acc: 0.7721\n",
      "Epoch 18/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4191 - acc: 0.8064 - val_loss: 0.5127 - val_acc: 0.7642\n",
      "Epoch 19/35\n",
      "2541/2541 [==============================] - 1s 548us/step - loss: 0.4148 - acc: 0.8095 - val_loss: 0.4696 - val_acc: 0.7780\n",
      "Epoch 20/35\n",
      "2541/2541 [==============================] - 1s 553us/step - loss: 0.4016 - acc: 0.8087 - val_loss: 0.5047 - val_acc: 0.7721\n",
      "Epoch 21/35\n",
      "2541/2541 [==============================] - 1s 556us/step - loss: 0.3954 - acc: 0.8233 - val_loss: 0.5043 - val_acc: 0.7662\n",
      "Epoch 22/35\n",
      "2541/2541 [==============================] - 1s 540us/step - loss: 0.3809 - acc: 0.8300 - val_loss: 0.4913 - val_acc: 0.7583\n",
      "Epoch 23/35\n",
      "2541/2541 [==============================] - 1s 539us/step - loss: 0.3976 - acc: 0.8186 - val_loss: 0.4732 - val_acc: 0.7721\n",
      "Epoch 24/35\n",
      "2541/2541 [==============================] - 2s 961us/step - loss: 0.3817 - acc: 0.8288 - val_loss: 0.5490 - val_acc: 0.7525\n",
      "Epoch 25/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3868 - acc: 0.8245 - val_loss: 0.4920 - val_acc: 0.7485\n",
      "Epoch 26/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3752 - acc: 0.8257 - val_loss: 0.4636 - val_acc: 0.7800\n",
      "Epoch 27/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3709 - acc: 0.8331 - val_loss: 0.4651 - val_acc: 0.7642\n",
      "Epoch 28/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3733 - acc: 0.8229 - val_loss: 0.5252 - val_acc: 0.7819\n",
      "Epoch 29/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3712 - acc: 0.8323 - val_loss: 0.5351 - val_acc: 0.7525\n",
      "Epoch 30/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3725 - acc: 0.8221 - val_loss: 0.5184 - val_acc: 0.7485\n",
      "Epoch 31/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3915 - acc: 0.8190 - val_loss: 0.4731 - val_acc: 0.7839\n",
      "Epoch 32/35\n",
      "2541/2541 [==============================] - 2s 882us/step - loss: 0.3530 - acc: 0.8351 - val_loss: 0.5196 - val_acc: 0.7564\n",
      "Epoch 33/35\n",
      "2541/2541 [==============================] - 1s 573us/step - loss: 0.3354 - acc: 0.8548 - val_loss: 0.4792 - val_acc: 0.7976\n",
      "Epoch 34/35\n",
      "2541/2541 [==============================] - 1s 553us/step - loss: 0.3738 - acc: 0.8174 - val_loss: 0.4611 - val_acc: 0.7937\n",
      "Epoch 35/35\n",
      "2541/2541 [==============================] - 1s 570us/step - loss: 0.3391 - acc: 0.8430 - val_loss: 0.4836 - val_acc: 0.7859\n",
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2541 samples, validate on 509 samples\n",
      "Epoch 1/35\n",
      "2541/2541 [==============================] - 8s 3ms/step - loss: 0.6781 - acc: 0.5734 - val_loss: 0.6118 - val_acc: 0.7014\n",
      "Epoch 2/35\n",
      "2541/2541 [==============================] - 1s 564us/step - loss: 0.6086 - acc: 0.6797 - val_loss: 0.8355 - val_acc: 0.5481\n",
      "Epoch 3/35\n",
      "2541/2541 [==============================] - 1s 568us/step - loss: 0.5689 - acc: 0.7009 - val_loss: 0.5468 - val_acc: 0.7250\n",
      "Epoch 4/35\n",
      "2541/2541 [==============================] - 1s 542us/step - loss: 0.5404 - acc: 0.7281 - val_loss: 0.5256 - val_acc: 0.7250\n",
      "Epoch 5/35\n",
      "2541/2541 [==============================] - 2s 591us/step - loss: 0.5124 - acc: 0.7584 - val_loss: 0.5744 - val_acc: 0.7328\n",
      "Epoch 6/35\n",
      "2541/2541 [==============================] - 1s 563us/step - loss: 0.5127 - acc: 0.7481 - val_loss: 0.4928 - val_acc: 0.7407\n",
      "Epoch 7/35\n",
      "2541/2541 [==============================] - 1s 574us/step - loss: 0.4946 - acc: 0.7619 - val_loss: 0.4888 - val_acc: 0.7328\n",
      "Epoch 8/35\n",
      "2541/2541 [==============================] - 1s 571us/step - loss: 0.4948 - acc: 0.7599 - val_loss: 0.5230 - val_acc: 0.7701\n",
      "Epoch 9/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4898 - acc: 0.7485 - val_loss: 0.4877 - val_acc: 0.7721\n",
      "Epoch 10/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4642 - acc: 0.7800 - val_loss: 0.4983 - val_acc: 0.7308\n",
      "Epoch 11/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4472 - acc: 0.7914 - val_loss: 0.4665 - val_acc: 0.7701\n",
      "Epoch 12/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4501 - acc: 0.7788 - val_loss: 0.4473 - val_acc: 0.7996\n",
      "Epoch 13/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4266 - acc: 0.7926 - val_loss: 0.4427 - val_acc: 0.7996\n",
      "Epoch 14/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4366 - acc: 0.7957 - val_loss: 0.4608 - val_acc: 0.7878\n",
      "Epoch 15/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4136 - acc: 0.8009 - val_loss: 0.4422 - val_acc: 0.8016\n",
      "Epoch 16/35\n",
      "2541/2541 [==============================] - 4s 1ms/step - loss: 0.4149 - acc: 0.8064 - val_loss: 0.4804 - val_acc: 0.7741\n",
      "Epoch 17/35\n",
      "2541/2541 [==============================] - 4s 1ms/step - loss: 0.3970 - acc: 0.8182 - val_loss: 0.4757 - val_acc: 0.7603\n",
      "Epoch 18/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.4018 - acc: 0.8036 - val_loss: 0.4486 - val_acc: 0.7976\n",
      "Epoch 19/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3922 - acc: 0.8221 - val_loss: 0.4059 - val_acc: 0.8094\n",
      "Epoch 20/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3729 - acc: 0.8162 - val_loss: 0.4317 - val_acc: 0.7996\n",
      "Epoch 21/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3850 - acc: 0.8150 - val_loss: 0.4713 - val_acc: 0.7957\n",
      "Epoch 22/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3749 - acc: 0.8225 - val_loss: 0.4585 - val_acc: 0.7839\n",
      "Epoch 23/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3662 - acc: 0.8213 - val_loss: 0.4371 - val_acc: 0.7957\n",
      "Epoch 24/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3683 - acc: 0.8225 - val_loss: 0.4155 - val_acc: 0.8035\n",
      "Epoch 25/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3488 - acc: 0.8312 - val_loss: 0.4509 - val_acc: 0.8134\n",
      "Epoch 26/35\n",
      "2541/2541 [==============================] - 1s 583us/step - loss: 0.3564 - acc: 0.8438 - val_loss: 0.4118 - val_acc: 0.8094\n",
      "Epoch 27/35\n",
      "2541/2541 [==============================] - 1s 568us/step - loss: 0.3859 - acc: 0.8166 - val_loss: 0.4343 - val_acc: 0.8016\n",
      "Epoch 28/35\n",
      "2541/2541 [==============================] - 1s 564us/step - loss: 0.4155 - acc: 0.7918 - val_loss: 0.4110 - val_acc: 0.8114\n",
      "Epoch 29/35\n",
      "2541/2541 [==============================] - 1s 564us/step - loss: 0.3562 - acc: 0.8272 - val_loss: 0.4269 - val_acc: 0.7957\n",
      "Epoch 30/35\n",
      "2541/2541 [==============================] - 1s 543us/step - loss: 0.3504 - acc: 0.8194 - val_loss: 0.4293 - val_acc: 0.7996\n",
      "Epoch 31/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3581 - acc: 0.8166 - val_loss: 0.4637 - val_acc: 0.7976\n",
      "Epoch 32/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3467 - acc: 0.8327 - val_loss: 0.4077 - val_acc: 0.8173\n",
      "Epoch 33/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3403 - acc: 0.8465 - val_loss: 0.4134 - val_acc: 0.8212\n",
      "Epoch 34/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3329 - acc: 0.8422 - val_loss: 0.4165 - val_acc: 0.8055\n",
      "Epoch 35/35\n",
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3344 - acc: 0.8512 - val_loss: 0.3976 - val_acc: 0.8055\n",
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2545 samples, validate on 505 samples\n",
      "Epoch 1/35\n",
      "2545/2545 [==============================] - 9s 4ms/step - loss: 0.6888 - acc: 0.5434 - val_loss: 0.7971 - val_acc: 0.5861\n",
      "Epoch 2/35\n",
      "2545/2545 [==============================] - 1s 569us/step - loss: 0.6181 - acc: 0.6703 - val_loss: 0.7579 - val_acc: 0.6297\n",
      "Epoch 3/35\n",
      "2545/2545 [==============================] - 1s 577us/step - loss: 0.5960 - acc: 0.6994 - val_loss: 0.6402 - val_acc: 0.6713\n",
      "Epoch 4/35\n",
      "2545/2545 [==============================] - 1s 582us/step - loss: 0.5375 - acc: 0.7352 - val_loss: 0.6042 - val_acc: 0.6733\n",
      "Epoch 5/35\n",
      "2545/2545 [==============================] - 1s 555us/step - loss: 0.5544 - acc: 0.7128 - val_loss: 0.5815 - val_acc: 0.6871\n",
      "Epoch 6/35\n",
      "2545/2545 [==============================] - 1s 581us/step - loss: 0.5007 - acc: 0.7477 - val_loss: 0.6107 - val_acc: 0.6931\n",
      "Epoch 7/35\n",
      "2545/2545 [==============================] - 1s 567us/step - loss: 0.4940 - acc: 0.7650 - val_loss: 0.6074 - val_acc: 0.6455\n",
      "Epoch 8/35\n",
      "2545/2545 [==============================] - 1s 556us/step - loss: 0.4869 - acc: 0.7639 - val_loss: 0.5841 - val_acc: 0.6634\n",
      "Epoch 9/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.4695 - acc: 0.7800 - val_loss: 0.5651 - val_acc: 0.7050\n",
      "Epoch 10/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.4555 - acc: 0.7815 - val_loss: 0.5338 - val_acc: 0.7267\n",
      "Epoch 11/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.4405 - acc: 0.7917 - val_loss: 0.5787 - val_acc: 0.6950\n",
      "Epoch 12/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.4530 - acc: 0.7768 - val_loss: 0.5262 - val_acc: 0.7386\n",
      "Epoch 13/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.4250 - acc: 0.7917 - val_loss: 0.5031 - val_acc: 0.7228\n",
      "Epoch 14/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.4139 - acc: 0.8086 - val_loss: 0.5871 - val_acc: 0.7347\n",
      "Epoch 15/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.4199 - acc: 0.8051 - val_loss: 0.5615 - val_acc: 0.7188\n",
      "Epoch 16/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.3941 - acc: 0.8090 - val_loss: 0.5691 - val_acc: 0.7208\n",
      "Epoch 17/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.4031 - acc: 0.8114 - val_loss: 0.5519 - val_acc: 0.7010\n",
      "Epoch 18/35\n",
      "2545/2545 [==============================] - 1s 576us/step - loss: 0.3932 - acc: 0.8244 - val_loss: 0.5359 - val_acc: 0.7426\n",
      "Epoch 19/35\n",
      "2545/2545 [==============================] - 1s 566us/step - loss: 0.3919 - acc: 0.8193 - val_loss: 0.5343 - val_acc: 0.7426\n",
      "Epoch 20/35\n",
      "2545/2545 [==============================] - 1s 565us/step - loss: 0.4139 - acc: 0.8181 - val_loss: 0.4995 - val_acc: 0.7525\n",
      "Epoch 21/35\n",
      "2545/2545 [==============================] - 1s 556us/step - loss: 0.3880 - acc: 0.8189 - val_loss: 0.4946 - val_acc: 0.7228\n",
      "Epoch 22/35\n",
      "2545/2545 [==============================] - 1s 570us/step - loss: 0.3883 - acc: 0.8228 - val_loss: 0.5540 - val_acc: 0.7188\n",
      "Epoch 23/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.4008 - acc: 0.8193 - val_loss: 0.6576 - val_acc: 0.7248\n",
      "Epoch 24/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.3931 - acc: 0.8141 - val_loss: 0.4818 - val_acc: 0.7723\n",
      "Epoch 25/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.3952 - acc: 0.8138 - val_loss: 0.5348 - val_acc: 0.7366\n",
      "Epoch 26/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.3835 - acc: 0.8189 - val_loss: 0.5559 - val_acc: 0.7208\n",
      "Epoch 27/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.3627 - acc: 0.8365 - val_loss: 0.4665 - val_acc: 0.7564\n",
      "Epoch 28/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.3700 - acc: 0.8358 - val_loss: 0.5109 - val_acc: 0.7426\n",
      "Epoch 29/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.3718 - acc: 0.8306 - val_loss: 0.4898 - val_acc: 0.7624\n",
      "Epoch 30/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.3540 - acc: 0.8432 - val_loss: 0.4765 - val_acc: 0.7644\n",
      "Epoch 31/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.3321 - acc: 0.8468 - val_loss: 0.5129 - val_acc: 0.7525\n",
      "Epoch 32/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.3263 - acc: 0.8487 - val_loss: 0.5384 - val_acc: 0.7386\n",
      "Epoch 33/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.3359 - acc: 0.8456 - val_loss: 0.6633 - val_acc: 0.7386\n",
      "Epoch 34/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.3427 - acc: 0.8499 - val_loss: 0.5108 - val_acc: 0.7663\n",
      "Epoch 35/35\n",
      "2545/2545 [==============================] - 3s 1ms/step - loss: 0.3349 - acc: 0.8542 - val_loss: 0.5024 - val_acc: 0.7505\n",
      "LAYER 0\n",
      "LAYER 1\n",
      "LAYER 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\miniconda3\\envs\\binding\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3050 samples, validate on 509 samples\n",
      "Epoch 1/35\n",
      "3050/3050 [==============================] - 11s 4ms/step - loss: 0.7004 - acc: 0.5213 - val_loss: 0.6590 - val_acc: 0.6012\n",
      "Epoch 2/35\n",
      "3050/3050 [==============================] - 2s 576us/step - loss: 0.6096 - acc: 0.6708 - val_loss: 0.6651 - val_acc: 0.6739\n",
      "Epoch 3/35\n",
      "3050/3050 [==============================] - 2s 562us/step - loss: 0.5733 - acc: 0.6987 - val_loss: 0.6926 - val_acc: 0.4912\n",
      "Epoch 4/35\n",
      "3050/3050 [==============================] - 2s 590us/step - loss: 0.5521 - acc: 0.7341 - val_loss: 0.6634 - val_acc: 0.6778\n",
      "Epoch 5/35\n",
      "3050/3050 [==============================] - 2s 589us/step - loss: 0.5160 - acc: 0.7416 - val_loss: 0.6154 - val_acc: 0.6483\n",
      "Epoch 6/35\n",
      "3050/3050 [==============================] - 2s 588us/step - loss: 0.5176 - acc: 0.7534 - val_loss: 0.5882 - val_acc: 0.6974\n",
      "Epoch 7/35\n",
      "3050/3050 [==============================] - 2s 571us/step - loss: 0.4930 - acc: 0.7675 - val_loss: 0.5934 - val_acc: 0.6798\n",
      "Epoch 8/35\n",
      "3050/3050 [==============================] - 2s 740us/step - loss: 0.4962 - acc: 0.7692 - val_loss: 0.5688 - val_acc: 0.6935\n",
      "Epoch 9/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.4941 - acc: 0.7626 - val_loss: 0.5754 - val_acc: 0.7014\n",
      "Epoch 10/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.4652 - acc: 0.7849 - val_loss: 0.5824 - val_acc: 0.6798\n",
      "Epoch 11/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.4624 - acc: 0.7803 - val_loss: 0.5685 - val_acc: 0.7053\n",
      "Epoch 12/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.4538 - acc: 0.7931 - val_loss: 0.5759 - val_acc: 0.6916\n",
      "Epoch 13/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.4305 - acc: 0.8016 - val_loss: 0.6248 - val_acc: 0.6896\n",
      "Epoch 14/35\n",
      "3050/3050 [==============================] - 3s 1ms/step - loss: 0.4420 - acc: 0.7961 - val_loss: 0.6129 - val_acc: 0.6876\n",
      "Epoch 15/35\n",
      "3050/3050 [==============================] - 2s 620us/step - loss: 0.4381 - acc: 0.7997 - val_loss: 0.5860 - val_acc: 0.6798\n",
      "Epoch 16/35\n",
      "3050/3050 [==============================] - 2s 589us/step - loss: 0.4255 - acc: 0.7941 - val_loss: 0.5659 - val_acc: 0.7151\n",
      "Epoch 17/35\n",
      "3050/3050 [==============================] - 2s 596us/step - loss: 0.4276 - acc: 0.7980 - val_loss: 0.5956 - val_acc: 0.7053\n",
      "Epoch 18/35\n",
      "3050/3050 [==============================] - 3s 1ms/step - loss: 0.4461 - acc: 0.7852 - val_loss: 0.5433 - val_acc: 0.7230\n",
      "Epoch 19/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.4272 - acc: 0.7987 - val_loss: 0.6251 - val_acc: 0.6778\n",
      "Epoch 20/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.4137 - acc: 0.7990 - val_loss: 0.5576 - val_acc: 0.6974\n",
      "Epoch 21/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.4042 - acc: 0.8111 - val_loss: 0.5592 - val_acc: 0.6974\n",
      "Epoch 22/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.4050 - acc: 0.8089 - val_loss: 0.5258 - val_acc: 0.7308\n",
      "Epoch 23/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.3755 - acc: 0.8230 - val_loss: 0.5639 - val_acc: 0.6994\n",
      "Epoch 24/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.3713 - acc: 0.8236 - val_loss: 0.5783 - val_acc: 0.6601\n",
      "Epoch 25/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.3667 - acc: 0.8325 - val_loss: 0.5908 - val_acc: 0.6935\n",
      "Epoch 26/35\n",
      "3050/3050 [==============================] - 2s 573us/step - loss: 0.3868 - acc: 0.8128 - val_loss: 0.5572 - val_acc: 0.7387\n",
      "Epoch 27/35\n",
      "3050/3050 [==============================] - 2s 575us/step - loss: 0.3666 - acc: 0.8292 - val_loss: 0.5841 - val_acc: 0.6739\n",
      "Epoch 28/35\n",
      "3050/3050 [==============================] - 2s 576us/step - loss: 0.3767 - acc: 0.8236 - val_loss: 0.5510 - val_acc: 0.7112\n",
      "Epoch 29/35\n",
      "3050/3050 [==============================] - 2s 694us/step - loss: 0.3939 - acc: 0.8151 - val_loss: 0.5731 - val_acc: 0.7191\n",
      "Epoch 30/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.3646 - acc: 0.8272 - val_loss: 0.5383 - val_acc: 0.7210\n",
      "Epoch 31/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.3552 - acc: 0.8338 - val_loss: 0.5938 - val_acc: 0.6857\n",
      "Epoch 32/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.3624 - acc: 0.8367 - val_loss: 0.5800 - val_acc: 0.6621\n",
      "Epoch 33/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.3539 - acc: 0.8331 - val_loss: 0.5492 - val_acc: 0.7289\n",
      "Epoch 34/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.3528 - acc: 0.8462 - val_loss: 0.5371 - val_acc: 0.7132\n",
      "Epoch 35/35\n",
      "3050/3050 [==============================] - 4s 1ms/step - loss: 0.3619 - acc: 0.8357 - val_loss: 0.5561 - val_acc: 0.7171\n"
     ]
    }
   ],
   "source": [
    "results_val = {}\n",
    "results_train = {}\n",
    "for i in range(len(training_p38)):\n",
    "        X_atoms_cold,X_bonds_cold,X_edges_cold = gcn.dataframe_to_gcn_input(validation_p38[i])\n",
    "        Y_cold = validation_p38[i].Binary\n",
    "        X_atoms_train, X_bonds_train, X_edges_train = gcn.dataframe_to_gcn_input(training_p38[i])\n",
    "        Y = training_p38[i].Binary\n",
    "        gcn_encoder = gcn.build_encoder()\n",
    "        gcn_model = gcn.build_model(gcn_encoder)\n",
    "        gcn_model.fit([X_atoms_train,X_bonds_train,X_edges_train],Y,\n",
    "                    batch_size = gcn_best['batch_size'],\n",
    "                    epochs = gcn_best['n_epochs'],\n",
    "                    verbose = 1,\n",
    "                    shuffle=True,\n",
    "                    validation_data = ([X_atoms_cold,X_bonds_cold,X_edges_cold],Y_cold))\n",
    "        y_pred_val = gcn_model.predict([X_atoms_cold,X_bonds_cold,X_edges_cold])\n",
    "        y_pred_train = gcn_model.predict([X_atoms_train,X_bonds_train,X_edges_train])\n",
    "        if i < 6:\n",
    "            results_val['Fold %s'%i] = calculate_metrics(np.array(Y_cold), y_pred_val.squeeze())\n",
    "            results_train['Fold %s'%i] = calculate_metrics(np.array(Y),y_pred_train.squeeze())\n",
    "        elif i == 6:\n",
    "            results_val['Test'] = calculate_metrics(np.array(Y_cold), y_pred_val.squeeze())\n",
    "            results_train['Test'] = calculate_metrics(np.array(Y),y_pred_train.squeeze())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>map</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold 0</th>\n",
       "      <td>0.950408</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>0.945362</td>\n",
       "      <td>0.833094</td>\n",
       "      <td>0.927142</td>\n",
       "      <td>0.872885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 1</th>\n",
       "      <td>0.947933</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>0.945379</td>\n",
       "      <td>0.841914</td>\n",
       "      <td>0.914173</td>\n",
       "      <td>0.871311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 2</th>\n",
       "      <td>0.957210</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>0.953127</td>\n",
       "      <td>0.861586</td>\n",
       "      <td>0.894992</td>\n",
       "      <td>0.878788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 3</th>\n",
       "      <td>0.953121</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>0.949350</td>\n",
       "      <td>0.890505</td>\n",
       "      <td>0.841552</td>\n",
       "      <td>0.872491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 4</th>\n",
       "      <td>0.949830</td>\n",
       "      <td>1114.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>0.941381</td>\n",
       "      <td>0.832084</td>\n",
       "      <td>0.922693</td>\n",
       "      <td>0.875246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 5</th>\n",
       "      <td>0.950540</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>0.946065</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.926410</td>\n",
       "      <td>0.869548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.940400</td>\n",
       "      <td>1375.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>0.933095</td>\n",
       "      <td>0.864347</td>\n",
       "      <td>0.820081</td>\n",
       "      <td>0.849836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         roc_auc      tn     fp     fn      tp       map  precision    recall  \\\n",
       "Fold 0  0.950408  1060.0  232.0   91.0  1158.0  0.945362   0.833094  0.927142   \n",
       "Fold 1  0.947933  1053.0  218.0  109.0  1161.0  0.945379   0.841914  0.914173   \n",
       "Fold 2  0.957210  1125.0  178.0  130.0  1108.0  0.953127   0.861586  0.894992   \n",
       "Fold 3  0.953121  1176.0  128.0  196.0  1041.0  0.949350   0.890505  0.841552   \n",
       "Fold 4  0.949830  1114.0  224.0   93.0  1110.0  0.941381   0.832084  0.922693   \n",
       "Fold 5  0.950540  1080.0  242.0   90.0  1133.0  0.946065   0.824000  0.926410   \n",
       "Test    0.940400  1375.0  191.0  267.0  1217.0  0.933095   0.864347  0.820081   \n",
       "\n",
       "        accuracy  \n",
       "Fold 0  0.872885  \n",
       "Fold 1  0.871311  \n",
       "Fold 2  0.878788  \n",
       "Fold 3  0.872491  \n",
       "Fold 4  0.875246  \n",
       "Fold 5  0.869548  \n",
       "Test    0.849836  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_train).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>map</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold 0</th>\n",
       "      <td>0.895147</td>\n",
       "      <td>205.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.847540</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.815324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 1</th>\n",
       "      <td>0.906811</td>\n",
       "      <td>248.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.870437</td>\n",
       "      <td>0.792035</td>\n",
       "      <td>0.836449</td>\n",
       "      <td>0.838900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 2</th>\n",
       "      <td>0.882748</td>\n",
       "      <td>190.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.873950</td>\n",
       "      <td>0.734545</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.770138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 3</th>\n",
       "      <td>0.866428</td>\n",
       "      <td>213.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.833247</td>\n",
       "      <td>0.792373</td>\n",
       "      <td>0.757085</td>\n",
       "      <td>0.785855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 4</th>\n",
       "      <td>0.897102</td>\n",
       "      <td>171.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>0.906437</td>\n",
       "      <td>0.807432</td>\n",
       "      <td>0.850534</td>\n",
       "      <td>0.805501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 5</th>\n",
       "      <td>0.845817</td>\n",
       "      <td>166.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>0.852169</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.816092</td>\n",
       "      <td>0.750495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.785513</td>\n",
       "      <td>258.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.700677</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.527094</td>\n",
       "      <td>0.717092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         roc_auc     tn    fp    fn     tp       map  precision    recall  \\\n",
       "Fold 0  0.895147  205.0  69.0  25.0  210.0  0.847540   0.752688  0.893617   \n",
       "Fold 1  0.906811  248.0  47.0  35.0  179.0  0.870437   0.792035  0.836449   \n",
       "Fold 2  0.882748  190.0  73.0  44.0  202.0  0.873950   0.734545  0.821138   \n",
       "Fold 3  0.866428  213.0  49.0  60.0  187.0  0.833247   0.792373  0.757085   \n",
       "Fold 4  0.897102  171.0  57.0  42.0  239.0  0.906437   0.807432  0.850534   \n",
       "Fold 5  0.845817  166.0  78.0  48.0  213.0  0.852169   0.731959  0.816092   \n",
       "Test    0.785513  258.0  48.0  96.0  107.0  0.700677   0.690323  0.527094   \n",
       "\n",
       "        accuracy  \n",
       "Fold 0  0.815324  \n",
       "Fold 1  0.838900  \n",
       "Fold 2  0.770138  \n",
       "Fold 3  0.785855  \n",
       "Fold 4  0.805501  \n",
       "Fold 5  0.750495  \n",
       "Test    0.717092  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_val).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(gcn_model, to_file='../../../../Desktop/latex report intern/DeepGCNN.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
